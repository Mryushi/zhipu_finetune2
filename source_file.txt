让机器像人一样思考
打造超越图灵测试的机器认知智能，实现SaaS、PaaS到MaaS的升级，模型化服务时代的引领者
专注中文认知大模型，赋能应用
自主创新的算法、领先的中文认知大模型企业
关于智谱
北京智谱华章科技有限公司（简称“智谱AI”）致力于打造新一代认知智能大模型，专注于做大模型的中国创新。公司合作研发了中英双语千亿级超大规模预训练模型GLM-130B，并基于此推出对话模型ChatGLM，开源单卡版模型ChatGLM-6B。同时，团队还打造了AIGC模型及产品矩阵，包括AI提效助手智谱清言（[访问链接](https://chatglm.cn/)）、高效率代码模型CodeGeeX、多模态理解模型CogVLM和文生图模型CogView等。公司践行Model as a Service（MaaS）的市场理念，推出大模型MaaS开放平台（[访问链接](https://open.bigmodel.cn/)），打造高效率、通用化的“模型即服务”AI开发新范式。通过认知大模型链接物理世界的亿级用户，智谱AI基于完整的模型生态和全流程技术支持，为千行百业带来持续创新与变革，加速迈向通用人工智能的时代。

发展历程
2024.01
新一代基座大模型GLM-4正式推出，整体性能相比上一代大幅提升，比肩世界先进水平
2023.10
推出新一代多模态大模型CogVLM
发布全面升级的ChatGLM3模型及相关系列产品
2023.06
发布全面升级的ChatGLM2模型矩阵，多样尺寸，丰富场景，模型能力登顶C-Eval榜单
2023.08
作为国内首批通过备案的大模型产品，AI生成式助手“智谱清言”正式上线
2023.05
开源多模态对话模型VisualGLM-6B（CogVLM）
2023.03
发布千亿基座的对话模型ChatGLM及其单卡开源版本ChatGLM-6B，全球下载量超过800万
2022.09
发布代码生成模型CodeGeeX，每天帮助程序员编写1000万行代码
2022.10
发布开源的100+语言预训练模型mGLM-1B
2022.08
发布高精度千亿大模型GLM-130B并开源，效果对标GPT-3 175B，收到70余个国家1000余个研究机构的使用需求
2021.09
设计GLM算法，发布拥有自主知识产权的开源百亿大模型GLM-10B
2019.06
智谱AI成立，源自清华技术成果
2020.01
专注大模型算法研究

我们的团队
智谱AI汇集了行业领先的人才、算力和数据，我们的愿景是实现“让机器像人一样思考”，让技术更好地服务社会，打造支持不同场景、不同方向的智能应用程序的底层人工智能架构，不断开拓努力实现人工智能的行业普惠。
加入我们

大模型列表
- GLM-4 ([访问链接](https://github.com/THUDM/GLM-4))
- ChatGLM ([访问链接](https://github.com/THUDM/ChatGLM3))
- GLM-130B ([访问链接](https://github.com/THUDM/GLM-130B))
- CodeGeeX ([访问链接](https://github.com/THUDM/CodeGeeX))
- CogView ([访问链接](https://github.com/THUDM/CogView))
- CogVLM ([访问链接](https://github.com/THUDM/CogVLM))

大模型产品
- 智谱AI开放平台 ([访问链接](https://bigmodel.ai))
- 智谱清言 ([访问链接](https://chatglm.cn))
- CodeGeeX ([访问链接](https://codegeex.cn))
- 写作蛙 ([访问链接](https://littlefrog.ai))
- 小呆对话 ([访问链接](https://xdai.aminer.cn/login))
- CogView ([访问链接](https://github.com/THUDM/CogView))

AMiner产品
- AMiner ([访问链接](https://www.aminer.cn/))
- 塔尖人才 ([访问链接](https://vip.aminer.cn/talent/index/))
- 知因分析 ([访问链接](https://vip.aminer.cn/analysis/))
- 小科问答 ([访问链接](https://vip.aminer.cn/sign/xiaoke/))
- 至远推送 ([访问链接](https://vip.aminer.cn/reco/))
- 若邻画像 ([访问链接](https://vip.aminer.cn/friend/))

数字人产品
- 有时
- 智慧手语 ([访问链接](https://vip.aminer.cn/sign/))
- 手语词典

联系方式
- 智谱公众号
- 企微客服
商务合作：service@zhipuai.cn
公司地址：北京市海淀区中关村东路1号院9号楼10层

版权信息
Copyright © 2023 北京智谱华章科技有限公司
京ICP备20011824号-24 ([访问链接](https://beian.miit.gov.cn/))

<end>
产品价格
按量计费，简单灵活，提供满足不同业务规模的产品方案
联系销售

最新模型
提供多种型号，不同功能、不同价位的模型API产品。文生图模型按请求次数计费，其它模型均按照每千 tokens 为单位计费。Token 是指模型推理过程中文本的最小意义单位，通常指一个单词、汉语词语/短句、标点符号或数字等。通常，GLM系列模型词表 token 和汉字换算比例约为 1:1.6 。

语言模型
- GLM-4-Plus
  - 简介：高智能旗舰
  - 上下文：128K
  - 单价：0.05 元 / 千tokens
  - Batch API 定价：不支持
- GLM-4-0520
  - 简介：高智能模型
  - 上下文：128K
  - 单价：0.1 元 / 千tokens
  - Batch API 定价：0.05元 / 千tokens
- GLM-4-AirX
  - 简介：极速推理
  - 上下文：8K
  - 单价：0.01 元 / 千tokens
  - Batch API 定价：不支持
- GLM-4-Air
  - 简介：高性价比
  - 上下文：128K
  - 单价：0.001 元 / 千tokens
  - Batch API 定价：0.0005元 / 千tokens
- GLM-4-Long
  - 简介：超长输入
  - 上下文：1M
  - 单价：0.001 元 / 千tokens
  - Batch API 定价：不支持
- GLM-4-Flash
  - 简介：免费调用
  - 上下文：128K
  - 单价：免费
  - Batch API 定价：免费

了解更多信息

多模态模型
- GLM-4V-Plus
  - 简介：视觉能力
  - 分辨率：-
  - 单价：0.01 元 / 千tokens
  - Batch API 定价：不支持
- GLM-4V
  - 简介：视觉能力
  - 分辨率：-
  - 单价：0.05 元 / 千tokens
  - Batch API 定价：0.025元 / 千tokens
- CogView-3-Plus
  - 简介：文生图
  - 分辨率：1024*1024,768*1344,864*1152等
  - 单价：0.06 元 / 次
  - Batch API 定价：不支持
- CogView-3
  - 简介：文生图
  - 分辨率：1024*1024
  - 单价：0.1 元 / 次
  - Batch API 定价：0.05 元 / 次
- CogVideoX
  - 简介：文生视频
  - 分辨率：1440*960
  - 单价：0.5 元 / 次
  - Batch API 定价：0.25 元 / 次

了解更多信息

向量模型
- Embedding-3
  - 简介：向量模型V3版本
  - 上下文：8K
  - 单价：0.0005 元 / 千tokens
  - Batch API 定价：0.00025 元 / 千tokens
- Embedding-2
  - 简介：向量模型V2版本
  - 上下文：8K
  - 单价：0.0005 元 / 千tokens
  - Batch API 定价：0.00025 元 / 千tokens

了解更多信息

其他模型
- CharGLM-3
  - 简介：角色扮演
  - 上下文：4K
  - 单价：0.015 元 / 千tokens
  - Batch API 定价：不支持
- Emohaa
  - 简介：心理陪伴
  - 上下文：8K
  - 单价：0.015 元 / 千tokens
  - Batch API 定价：不支持
- CodeGeeX-4
  - 简介：代码生成
  - 上下文：128K
  - 单价：0.0001 元 / 千tokens
  - Batch API 定价：不支持

查看历史模型

模型微调
开放GLM系列模型训练工具，支持一键微调定制私有的个性化模型，帮助企业针对业务场景打造独特极致的AI体验。

模型训练
- GLM-4-Flash
  - 训练版本：8k
  - LoRA微调单价：0.025 元 / 千tokens
  - 全参微调单价：0.04 元 / 千tokens
- GLM-4-9B
  - 训练版本：8k
  - LoRA微调单价：0.025 元 / 千tokens
  - 全参微调单价：0.04 元 / 千tokens
- ChatGLM3-6B
  - 训练版本：8k
  - LoRA微调单价：0.025 元 / 千tokens
  - 全参微调单价：不支持

模型推理
- GLM-4-Flash
  - 部署版本：8k-int8
  - 公共实例：0.002 元 / 千tokens
  - 私有实例定价：100 元 / 算力单元 / 天
- GLM-4-9B
  - 部署版本：8k-int8
  - 公共实例：0.002 元 / 千tokens
  - 私有实例定价：100 元 / 算力单元 / 天
- ChatGLM3-6B
  - 部署版本：8k-int8
  - 公共实例：0.002 元 / 千tokens
  - 私有实例定价：不支持

AllTools API 及 工具组件
AllTools 模型通过对用户提问进行规划，选择合适的工具，逐步分析并采取下一步行动，最终完成一个复杂任务。Alltools API 为开发者提供了一套强大的工具，包括代码解释器、绘图和搜索等工具，能够在应用程序中构建具有高度专业化的AI助手。

AllTools API
- GLM-4-AllTools
  - 简介：Agent能力模型
  - 公有池单价：0.1 元 / 千tokens
  - 私有实例定价：低至数十万 / 年

工具组件
- 文件存储
  - 简介：知识库、微调、Batch文件存储
  - 免费额度：1G
  - 单价：0.6 元 / 天 / GB
- Code Interpreter
  - 简介：代码解释器
  - 免费额度：100次
  - 单价：限时免费
- Web_search
  - 简介：标准联网搜索
  - 免费额度：无限量
  - 单价：限时免费
- Web_search_pro
  - 简介：专业版联网搜索
  - 免费额度：100次
  - 单价：限时免费

私有化解决方案
为满足企业对数据的完全掌控和模型的安全运行的诉求，我们提供从模型到应用的本地私有化解决方案，帮助客户实现数据的完全掌控和模型的绝对安全运行。

模型及一体机
- GLM-4-0520
  - 简介：语言模型
  - 刊例价：数千万
- GLM-4-Air
  - 简介：语言模型
  - 刊例价：数百万
- GLM-4-Flash
  - 简介：语言模型
  - 刊例价：数十万
- GLM-4V
  - 简介：视觉理解
  - 刊例价：数百万
- CogView-3
  - 简介：文生图
  - 刊例价：数十万

知识库应用
- 专业版
  - 简介：专业版检索增强
  - 刊例价：数十万

使用 BigModel 平台强大模型打造AI产品
开始使用
联系销售

联系方式
联系电话：400-6883-991
商务合作：service@zhipuai.cn
公司地址：北京市海淀区中关村东路1号院9号楼10层

版权信息
京ICP备20011824号-14
Copyright © 2024 北京智谱华章科技有限公司

<end>
介绍
智谱AI 开放平台提供一系列具有不同功能和定价的大模型，包括通用大模型、超拟人大模型、图像大模型、向量大模型等，并且支持使用您的私有数据对模型进行微调。

2024年01月16日，我们在「智谱AI技术开放日(ZHIPU DevDay)」推出新一代基座大模型 GLM-4。

查看模型接口文档
体验模型能力体验中心
查看您的API Keys
构建知识库
创建大模型应用应用中心

关键概念
GLM
GLM 全名 General Language Model ，是一款基于自回归填空的预训练语言模型。ChatGLM 系列模型，支持相对复杂的自然语言指令，并且能够解决困难的推理类问题。该模型配备了易于使用的 API 接口，允许开发者轻松将其融入各类应用，广泛应用于智能客服、虚拟主播、聊天机器人等诸多领域。

Embedding
Embedding 是一种将数据（如文本）转化为向量形式的表示方法，这种表示方式确保了在某些特定方面相似的数据在向量空间中彼此接近，而与之不相关的数据则相距较远。通过将文本字符串转换为向量，使得数据能够有效用于搜索、聚类、推荐系统、异常检测和分类等应用场景。

Token
Token 是模型用来表示自然语言文本的基本单位，可以直观的理解为“字”或“词”；通常 1 个中文词语、1 个英文单词、1 个数字或 1 个符号计为 1 个token。 一般情况下 ChatGLM 系列模型中 token 和字数的换算比例约为 1:1.6 ，但因为不同模型的分词不同，所以换算比例也存在差异，每一次实际处理 token 数量以模型返回为准，您可以从返回结果的 usage 中查看。

图片链接：https://cdn.bigmodel.cn/static/platform/images/usage-guide/gpc-cover.jpg
视频链接：https://cdn.bigmodel.cn/static/platform/videos/usage-guide/GLM4-press-conference.mp4


<end>
模型
概述
智谱AI 开放平台提供了包括通用大模型、图像大模型、超拟人大模型、向量大模型等多种模型。

语言模型
模型 | 描述 | 上下文 | 最大输出
--- | --- | --- | ---
GLM-4-Plus | 高智能旗舰：性能全面提升，长文本和复杂任务能力显著增强 | 128K | 4K
GLM-4-0520 | 高智能模型：适用于处理高度复杂和多样化的任务 | 128K | 4K
GLM-4-Long | 超长输入：专为处理超长文本和记忆型任务设计 | 1M | 4K
GLM-4-AirX | 极速推理：具有超快的推理速度和强大的推理效果 | 8K | 4K
GLM-4-Air | 高性价比：推理能力和价格之间最平衡的模型 | 128K | 4K
GLM-4-Flash | 免费调用：智谱AI首个免费API，零成本调用大模型。 | 128K | 4K
GLM-4-AllTools | Agent模型：自主规划和执行复杂任务 | 128K | 4K
GLM-4 | 旧版旗舰：发布于2024年1月16日，目前已被GLM-4-0520取代 | 128K | 4K

多模态模型
模型 | 描述 | 最大输入 | 输出分辨率
--- | --- | --- | ---
GLM-4V-Plus | 视频和图像理解：具备视频内容和多图片的理解能力 | 8K | -
GLM-4V | 图像理解：具备图像理解能力和推理能力 | 2K | -
CogVideoX | 视频生成：输入文本或图片即可轻松制作视频 | 0.5K | 1440x960
CogView-3-Plus | 图片生成：根据用户文字描述生成高质量图像，支持多图片尺寸 | 1K | 1024x1024 768x1344 864x1152等
CogView-3 | 图片生成：根据用户文字描述快速、精准生成图像 | 1K | 1024x1024

向量模型
模型 | 描述 | 最大输入 | 向量维度
--- | --- | --- | ---
Embedding-3 | 最新模型：支持自定义向量维度 | 8K | 2048
Embedding-2 | 旧版模型：目前已被Embedding-3取代 | 8K | 1024

其他模型
模型 | 描述 | 上下文 | 最大输出
--- | --- | --- | ---
CharGLM-3 | 拟人模型：适用于情感陪伴和虚拟角色 | 4K | 2K
Emohaa | 心理模型：具备专业咨询能力，帮助用户理解情感并应对情绪问题 | 8K | 4K
CodeGeeX-4 | 代码模型：适用于代码自动补全任务 | 128K | 4K

即将弃用的模型
我们已经宣布了以下模型的弃用日期。在这些模型弃用后，我们会将它们自动路由至新的模型。请用户注意在弃用日期之前，将您的模型编码更新为最新版本，以确保服务的顺畅过渡。

模型 | 弃用日期 | 指向模型
--- | --- | ---
GLM-3-Turbo | 2025年6月30日 | GLM-4-Air
ChatGLM_Turbo | 2024年9月30日 | GLM-4-Air
ChatGLM_Pro | 2024年9月30日 | GLM-4-Air
ChatGLM_Std | 2024年9月30日 | GLM-4-Air
ChatGLM_Lite | 2024年7月31日 | GLM-4-Air

<end>
GLM-4-Plus
介绍
在 KDD 国际数据挖掘与知识发现大会上，智谱 GLM 团队发布了新一代基座大模型——GLM-4-Plus。作为智谱全自研 GLM 大模型的最新版本，GLM-4-Plus 标志着智谱AI在通用人工智能领域的持续深耕，推进大模型技术的独立自主创新。

语言能力
GLM-4-Plus 使用了大量模型辅助构造高质量合成数据以提升模型性能，利用PPO有效有效提升模型推理（数学、代码算法题等）表现，更好反映人类偏好。在各项性能指标上，GLM-4-Plus 已达到与 GPT-4o 等第一梯队模型持平的水平。

模型 | AlignBench | MMLU | MATH | GPQA | LCB | IFEval | IFEval
--- | --- | --- | --- | --- | --- | --- | ---
Claude 3.5 Sonnet | 80.7 | 88.3 | 71.1 | *56.4 | 49.8 | 53.1 | 80.6
Llama 3.1 405B | 60.7 | 88.6 | 73.8 | *50.1 | *39.4 | 50 | 83.9
Gemini 1.5Pro | 74.7 | 85.9 | 67.7 | 46.2 | 33.6 | 42.3 | 74.4
GPT-4o | 83.8 | 88.7 | 76.6 | *51.0 | *45.5 | 52.3 | 81.9
GLM-4-Plus | 83.2 | 86.8 | 74.2 | 50.7 | *45.8 | 50.4 | 79.5
GLM-4-Plus/GPT-4o | 99% | 98% | 97% | 99% | 101% | 96% | 97%
GLM-4-Plus/Claude 3.5 Sonnet | 103% | 98% | 104% | 85% | 92% | 95% | 99%

LCB (LiveCodeBench)、NCB (NaturalCodeBench)、* represents reproduced results

长文本能力
GLM-4-Plus 在长文本处理能力上比肩国际先进水平。通过更精准的长短文本数据混合策略，显著增强了长文本的推理效果。

模型 | LongBench-Chat | InfiniteBench/EN.MC | Ruler
--- | --- | --- | ---
Mistral-123B | 8.2 | 38.9 | 80.5
Llama 405B | 8.6 | 83.4 | 91.5
Claude Sonnet 3.5 | 8.6 | 79.5 | -
Gemini 1.5 Pro | 8.6 | 80.9 | 95.8
GPT-4o | 9 | 82.5 | -
GLM-4-Plus | 8.8 | 85.1 | 93
GLM-4-Plus/GPT-4o | 98% | 103% | -
GLM-4-Plus/Claude 3.5 Sonnet | 102% | 107% | -

调用示例
以下是一个完整的调用示例，帮助您快速上手 GLM-4-Plus 模型。
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-plus",  # 填写需要调用的模型编码
    messages=[
        {"role": "system", "content": "你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。"},
        {"role": "user", "content": "农夫需要把狼、羊和白菜都带过河，但每次只能带一样物品，而且狼和羊不能单独相处，羊和白菜也不能单独相处，问农夫该如何过河。"}
    ],
)
print(response.choices[0].message)
```

支持与反馈
如有任何使用问题或建议，欢迎联系智谱技术支持团队，我们将竭诚为您提供帮助。

<end>
GLM-4V-Plus
介绍
基于CogVLM系列模型的研究经验，我们成功研发了GLM-4V-Plus，集图像理解与视频理解能力于一体的多模态模型。GLM-4V-Plus在图像和视频理解领域均展现出领先水平，稳居行业前列。

视觉能力

模型	OCRBench	MME	MMBench-V1.1-Avg	MMStar	MMVet	MMMU-Val	AI2D	SEEDBench-IMG
Claude 3.5 Sonnet	788	1920	78.5	62.2	66	65.9	80.2	72.2
Gemini 1.5 Pro	754	2110.6	73.9	59.1	64	60.6	79.1	-
GPT-4V-1106	516	1771.5	73.8	49.7	63.6	53.8	75.9	72.3
GPT-4V-0409	656	2070.2	79.8	56	67.5	61.7	78.6	73
GPT-4o	736	2310.3	80.5	63.9	69.1	69.2	84.6	77.1
GLM-4V-Plus	833	2274.7	82.4	62.5	69.9	53.3	83.6	77.4
GLM-4V-Plus/GPT-4o	113%	99%	102%	98%	101%	77%	99%	100%
GLM-4V-Plus/Claude 3.5 Sonnet	106%	118%	105%	100%	106%	81%	104%	107%
视频分析
GLM-4V-Plus 能够理解并分析复杂的视频内容，同时具备时间感知能力。

模型	MVBench	LVBench	时序问答	多轮对话	中英文支持
LLaVA-NeXT-Video	50.6	32.2	❌	❌	❌
PLLaVA	58.1	26.1	❌	❌	❌
LLaVA-OneVision	59.4	27	❌	✅	✅
GPT-4o	47.8	34.7	❌	✅	✅
Gemini 1.5 Pro	52.6	33.1	✅	✅	✅
GLM-4V-Plus	71.2	38.3	✅	✅	✅
GLM-4V-Plus/GPT-4o	149%	110%	-	-	-
GLM-4V-Plus/Gemini 1.5 Pro	135%	116%	-	-	-
视频理解调用示例
上传视频URL

python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="YOUR API KEY") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写需要调用的模型名称
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "video_url",
            "video_url": {
                "url" : "https://sfile.chatglm.cn/testpath/video/b844f8f1-5df9-556c-a515-3d3bfaa736e8_0.mp4"
            }
          },
          {
            "type": "text",
            "text": "请仔细描述这个视频"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
上传视频 Base64

python
import base64
from zhipuai import ZhipuAI

video_path = "/Users/YourCompluter/xxxx.mp4"
with open(video_path, 'rb') as video_file:
    video_base = base64.b64encode(video_file.read()).decode('utf-8')

client = ZhipuAI(api_key="YOUR API KEY") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写需要调用的模型名称
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "video_url",
            "video_url": {
                "url" : video_base
            }
          },
          {
            "type": "text",
            "text": "请仔细描述这个视频"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
图片理解示例
上传图片URL

python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写需要调用的模型名称
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
                "url" : "https://www.zhipuai.cn/assets/images/aboutus/company.jpeg"
            }
          },
          {
            "type": "text",
            "text": "图里有什么"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
上传图片 Base64

python
import base64
from zhipuai import ZhipuAI

img_path = "/Users/YourCompluter/xxxx.jpeg"
with open(img_path, 'rb') as img_file:
    img_base = base64.b64encode(img_file.read()).decode('utf-8')

client = ZhipuAI(api_key="YOUR API KEY") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写需要调用的模型名称
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
                "url": img_base
            }
          },
          {
            "type": "text",
            "text": "请描述这个图片"
          }
        ]
      }
    ]
)
print(response.choices[0].message)

<end>
CogView-3-Plus
介绍
CogView-3-Plus使用Transformer架构训练扩散模型，优化了效果并验证了参数量提升的效益。我们还构建了高质量图像微调数据集，使模型生成更符合指令且美学评分更高的图像，效果接近MJ-V6和FLUX等一流模型。

模型名称 | Clip Score | Aes Score | HPSV2 | ImageReward | PickScore | MPS
--- | --- | --- | --- | --- | --- | ---
SD3-Medium | 0.2655 | 5.52 | 0.2774 | 0.2144 | 21.31 | 10.57
Kolors | 0.2726 | 6.14 | 0.2833 | 0.5482 | 22.14 | 11.86
DALLE-3 | 0.3237 | 5.95 | 0.2904 | 0.9734 | 22.51 | 11.95
MidJourney-V5.2 | 0.3144 | 6.12 | 0.2813 | 0.8169 | 22.74 | 12.4
MidJourney-V6 | 0.3276 | 5.95 | 0.2798 | 0.8351 | 22.78 | 12.34
Flux-dev | 0.3155 | 6.04 | 0.2881 | 1.0333 | 22.96 | 10.12
CogView-3-Plus | 0.3177 | 5.9 | 0.2963 | 0.9797 | 22.53 | 12.55

用法
CogView-3-Plus能够根据文本提示生成高质量的图像。支持的图像尺寸包括1024x1024、768x1344、864x1152、1344x768、1152x864、1440x720以及720x1440，默认的图像尺寸为1024x1024。

调用示例：

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
response = client.images.generations(
    model="cogView-3-plus", #填写需要调用的模型编码
    prompt="在干燥的沙漠环境中，一棵孤独的仙人掌在夕阳的余晖中显得格外醒目。这幅油画捕捉了仙人掌坚韧的生命力和沙漠中的壮丽景色，色彩饱满且表现力强烈。",
    size="1440x720"
)
print(response.data[0].url)
```

提示词
明确、清晰的结构化提示词可以帮助 CogView 创造出更高质量的图像。

[图像生成模型 Prompt 工程指南](/dev/howuse/prompt)

示例
Prompt: 在干燥的沙漠环境中，一棵孤独的仙人掌在夕阳的余晖中显得格外醒目。这幅油画捕捉了仙人掌坚韧的生命力和沙漠中的壮丽景色，色彩饱满且表现力强烈。
生成结果: ![结果图片](/img/cogView.584821fb.png)

<end>
CogView-3-Plus
介绍
CogView-3-Plus使用Transformer架构训练扩散模型，优化了效果并验证了参数量提升的效益。我们还构建了高质量图像微调数据集，使模型生成更符合指令且美学评分更高的图像，效果接近MJ-V6和FLUX等一流模型。

模型名称 | Clip Score | Aes Score | HPSV2 | ImageReward | PickScore | MPS
--- | --- | --- | --- | --- | --- | ---
SD3-Medium | 0.2655 | 5.52 | 0.2774 | 0.2144 | 21.31 | 10.57
Kolors | 0.2726 | 6.14 | 0.2833 | 0.5482 | 22.14 | 11.86
DALLE-3 | 0.3237 | 5.95 | 0.2904 | 0.9734 | 22.51 | 11.95
MidJourney-V5.2 | 0.3144 | 6.12 | 0.2813 | 0.8169 | 22.74 | 12.4
MidJourney-V6 | 0.3276 | 5.95 | 0.2798 | 0.8351 | 22.78 | 12.34
Flux-dev | 0.3155 | 6.04 | 0.2881 | 1.0333 | 22.96 | 10.12
CogView-3-Plus | 0.3177 | 5.9 | 0.2963 | 0.9797 | 22.53 | 12.55

用法
CogView-3-Plus能够根据文本提示生成高质量的图像。支持的图像尺寸包括1024x1024、768x1344、864x1152、1344x768、1152x864、1440x720以及720x1440，默认的图像尺寸为1024x1024。

调用示例：

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
response = client.images.generations(
    model="cogView-3-plus", #填写需要调用的模型编码
    prompt="在干燥的沙漠环境中，一棵孤独的仙人掌在夕阳的余晖中显得格外醒目。这幅油画捕捉了仙人掌坚韧的生命力和沙漠中的壮丽景色，色彩饱满且表现力强烈。",
    size="1440x720"
)
print(response.data[0].url)
```

提示词
明确、清晰的结构化提示词可以帮助 CogView 创造出更高质量的图像。

[图像生成模型 Prompt 工程指南](/dev/howuse/prompt)

示例
Prompt: 在干燥的沙漠环境中，一棵孤独的仙人掌在夕阳的余晖中显得格外醒目。这幅油画捕捉了仙人掌坚韧的生命力和沙漠中的壮丽景色，色彩饱满且表现力强烈。
生成结果: ![结果图片](/img/cogView.584821fb.png)

<end>
CogVideoX
CogVideoX是由智谱AI开发的视频生成大模型，具备强大的视频生成能力，只需输入文本或图片就可以轻松完成视频制作。本指南将教您如何系统地构建提示词，从而生成专业级别的视频作品。

资源链接：
- 立即生成请前往[体验中心](/console/trialcenter?modelCode=cogvideox)
- 接口调用请参阅[接口文档](/dev/api#cogvideox)
- 价格：标准价格为0.5元/次
- 购买资源包：
  - [体验包（9.9元/30次）](/tokenspropay?productIds=product-016)
  - [优享包（399元/1000次）](/tokenspropay?productIds=product-017)
  - [超大包（2499元/10000次）](/tokenspropay?productIds=product-018)

文生视频
提示词的精确度与细节水平直接影响视频内容的质量。采用结构化提示词可以极大提升视频内容的符合度和专业性。以下是构建提示词的关键组成部分：

提示词 = (镜头语言 +景别角度+ 光影) + 主体 (主体描述) + 主体运动 +场景 (场景描述) + (氛围)

镜头语言、景别角度、光影、主体、主体描述、主体运动、场景、场景描述、氛围是构建提示词的关键要素。

其它技巧：
- 关键词重复：在提示的不同部分重复或强化关键词有助于提高输出的一致性。
- 聚焦内容：提示词应集中在视频中应有的内容上。
- 使用智能体：使用[提示词智能体](https://chatglm.cn/main/gdetail/669911fe0bef38883947d3c6)帮助你生成专业提示词。

文生视频示例：
- Prompt: 比得兔（主体）开小汽车（主体描述），游走在马路上（环境描述），脸上的表情充满开心喜悦（氛围设定）。
- Prompt: 一个金发碧眼的女人（主体）站在水里（环境描述），一群粉红色的水母从水里游向天空（动作）。
- Prompt: 夜晚的丛林中，一只猫头鹰（主体）站在枯树枝上（环境描述），猫头鹰的眼睛在月光下闪闪发亮（动作）。背景是一片寂静的森林。
- Prompt: 深海里（环境描述）的一艘沉船（主体），电影质感，由远到近（镜头语言)。
- Prompt: 特写镜头（镜头描述），傍晚的微光（光线运用），一只鹦鹉站在阳台的栏杆上，鹦鹉有着紫色的羽毛和粉色的喙（主体描述），背景是都市的高楼大厦（环境描述）。

图生视频
CogVideoX 可以将用户提供的静态图像转化为6秒的动态视频。为达到最佳效果，推荐上传比例为3:2的图片，并且文件格式为 PNG 或 JPEG，文件大小不超过5MB。提示词建议使用“主体（背景）+ 运动描述”的表达方式。

图生视频示例：
- Prompt: 星空缓慢旋转
- Prompt: 鸭子在游动
- Prompt: 风吹动她的头发

请注意，由于网络原因，部分视频和图片资源可能无法直接访问。如果遇到问题，建议检查网页链接的合法性或稍后重试。如果您有其他问题或需要进一步的帮助，请随时告知。

<end>
GLM-4-AllTools 是专门为支持智能体和相关任务而进一步优化的模型版本。它能够自主理解用户的意图，规划复杂的指令，并能够调用一个或多个工具（例如网络浏览器、代码解释器和文本生图像）以完成复杂的任务。

GLM-4-AllTools 在解决数学问题的Python解释器、信息检索浏览器方面的性能与ChatGPT-4 相当。

工具类型 | 对比项 | GLM-4-AllTools | GPT-4
--- | --- | --- | ---
Python Interpreter | GSM8K, MATH, Math23K | 91.59, 63.60, 88.50 | 92.72, 65.00, 88.40
Browser | Information Seeking | 78.08 | 67.12

GLM-4-AllTools 模型支持了多种工具，并且持续更新中。

工具 | 介绍
--- | ---
智能编程助手 | 智能编程助手（Code Interpreter）能够准确理解自然语言描述的编程需求，自动生成代码片段来解决实际问题。
安全代码沙盒 | 安全代码沙盒（Sandbox）提供了一个安全的执行和测试环境，可以在其中模拟真实环境中的代码执行结果。
实时联网搜索 | 实时联网搜索（Web Search）能够在互联网上实时搜索信息，基于全网的搜索结果进行分析，提供更实时更全面的答案。
绘图设计工具 | 绘图设计工具（Drawing tool）根据文本描述能够生成高质量、高分辨率的图片，支持多种图像风格，满足各类绘图需求。
函数调用能力 | 函数调用能力（Function Call）允许AI助手调用外部函数，以执行特定任务或获取必要数据，实现与外部系统的无缝集成。

GLM-4-AllTools模型仅支持 SSE 流式输出，请求示例如下，具体请参考接口文档。

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"帮我查询2018年至2024年，每年五一假期全国旅游出行数据，并绘制成柱状图展示数据趋势。"
                }
            ]
        }
    ],
    stream=True,
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_tourist_data_by_year",
                "description": "用于查询每一年的全国出行数据，输入年份范围(from_year,to_year)，返回对应的出行数据，包括总出行人次、分交通方式的人次等。",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "type": {
                            "description": "交通方式，默认为by_all，火车=by_train，飞机=by_plane，自驾=by_car",
                            "type": "string"
                        },
                        "from_year": {
                            "description": "开始年份，格式为yyyy",
                            "type": "string"
                        },
                        "to_year": {
                            "description": "结束年份，格式为yyyy",
                            "type": "string"
                        }
                    },
                    "required": ["from_year","to_year"]
                }
            }
        },
        {
            "type": "code_interpreter"
        }
    ]
)

for chunk in response:
    print(chunk)
```

<end>
通用搜索

介绍
`web_search`工具通过网络搜索获取信息，以增强语言模型输出的质量和时效性。

用法
启用与禁用 web_search
网络搜索功能默认为关闭状态（False）。当启用搜索（设置为 True）时，系统会自动判断是否需要进行网络检索，并调用搜索引擎获取相关信息。检索成功后，搜索结果将作为背景信息输入给大模型进行进一步处理。每次网络搜索大约会增加1000个 tokens 的消耗。

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="您的APIKey")

tools = [
    {
        "type": "web_search",
        "web_search": {
            "enable": True #默认为关闭状态（False） 禁用：False，启用：True。
        }
    }
]

messages = [
    {
        "role": "user",
        "content": "中国 2024 年一季度的GDP是多少 "
    }
]

response = client.chat.completions.create(
    model="glm-4",
    messages=messages,
    tools=tools
)
print(response.choices[0].message)
```

自定义搜索内容
使用`search_query`参数可以自定义搜索内容，提升搜索结果的相关性和精确度。 如果不传`search_query`参数，系统将根据用户的消息自动进行网页检索。

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="您的APIKey")

tools = [
    {
        "type": "web_search",
        "web_search": {
            "enable": True,
            "search_query": "自定义搜索的关键词"
        }
    }
]

messages = [
    {
        "role": "user",
        "content": "中国 2024 年一季度的GDP是多少"
    }
]

response = client.chat.completions.create(
    model="glm-4",
    messages=messages,
    tools=tools
)
print(response.choices[0].message)
```

检索指定网页
访问指定网址以检索网页内容，将作为背景知识输入给模型。注意：由于某些网站的访问限制，可能无法读取页面内容。

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey

messages = [
    {
        "role": "user",
        "content": "总结文中的内容：https://news.sciencenet.cn/htmlnews/2024/3/519107.shtm"
    }
]
response = client.chat.completions.create(
    model="glm-4", # 填写需要调用的模型名称
    messages=messages,
)
print(response.choices[0].message)
```

返回搜索来源
启用`search_result`参数允许用户获取详细的网页搜索来源信息，包括来源网站的图标、标题、链接、来源名称以及引用的文本内容。

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="您的APIKey")

tools = [
    {
        "type": "web_search",
        "web_search": {
            "enable": True,
            "search_result": True       # 禁用False，启用：True，默认为禁用
        }
    }
]

messages = [
    {
        "role": "user",
        "content": "最新的AI发展趋势"
    }
]

response = client.chat.completions.create(
    model="glm-4",
    messages=messages,
    tools=tools
)
print(response)
```

使用 Prompt 添加搜索角标
使用`search_prompt`允许用户自定义模型引用搜索结果的方式，prompt 必须包含`{search_result}`表示搜索结果，例如：

```python
search_prompt = """
# 以下是来自互联网的信息：
{search_result}

# 当前日期: 2024-XX-XX

# 要求：
根据最新发布的信息回答用户问题，当回答引用了参考信息时，必须在句末使用对应的[ref_序号]来标明参考信息来源。
"""

client = ZhipuAI(api_key=zhipu_api_key) # 填写您自己的APIKey

tools = [
    {
        "type": "web_search",
        "web_search": {
            "enable": True,
            "search_query": "最近国内有哪些新闻",
            "search_result": True,
            "search_prompt": search_prompt
        }
    }
]

response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=[
        {"role": "user", "content": "问：最近国内有哪些新闻，答："}
    ],
    top_p=0.7,
    temperature=0.1,
    tools=tools
)
print(response)
```

启用`search_result`参数允许用户获取详细的网页搜索来源信息，返回角标序号`'refer': 'ref_序号'`，可用于关联模型回答所引用的搜索角标。

<end>
增强检索

介绍
通过在大语言模型生成答案之前，先从知识库中检索相关知识，然后将相关知识作为背景信息输入给大模型，有效地提升内容的准确性和相关性。

用法
构建知识库
用于管理文件，支持上传多个文件，并通过关联知识库ID后进行调用。知识库最大容量为1G、调用方式请参考[接口文档](/dev/api#uploadfile)。

调用示例

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey

result = client.knowledge.create(
    embedding_id=3,
    name="knowledge name",
    description="knowledge description"
)
print(result.id)
```

上传文件
支持将doc、docx、pdf、xlsx类型文件上传到知识库，支持自定义文件切片的大小和规则。文件大小不得超过50MB。

调用示例

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey

resp = client.knowledge.document.create(
    file=open("xxx.xlsx", "rb"),
    purpose="retrieval",
    knowledge_id="1798330146986561536",
    sentence_size=202,
    custom_separator=["\n"]
)
print(resp)
```

通过工具调用知识库
创建知识库后，您将获得一个知识库ID。调用模型服务时，传入知识库ID，使大模型能获取相关内容以响应用户查询。

调用示例

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey

response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=[
        {"role": "user", "content": "你好！你叫什么名字"},
    ],
    tools=[
            {
                "type": "retrieval",
                "retrieval": {
                    "knowledge_id": "your knowledge id",
                    "prompt_template": "从文档\n\"\"\"\n{{knowledge}}\n\"\"\"\n中找问题\n\"\"\"\n{{question}}\n\"\"\"\n的答案，找到答案就仅使用文档语句回答问题，找不到答案就用自身知识回答并且告诉用户该信息不是来自文档。\n不要复述问题，直接开始回答。"
                }
            }
    ],
    stream=True,
)
for chunk in response:
    print(chunk.choices[0].delta)
```

<end>
函数调用
介绍
ChatGLM 的函数调用功能可以增强模型推理效果或进行其他外部操作，包括信息检索、数据库操作、知识图谱搜索与推理、操作系统、触发外部操作等工具调用场景。
本教程将介绍如何使用 ChatGLM 的函数调用功能，实现对模型与外部函数库的连接。
tools 是内容生成 API 中的可选参数，用于向模型提供函数定义。通过此参数，模型能够生成符合用户所提供规范的函数参数。请注意，API 实际上不会执行任何函数调用，仅返回调用函数所需要的参数。开发者可以利用模型输出的参数在应用中执行函数调用。
本教程包括以下3个部分:
1. 如何使用 Chat Completion 接口向模型描述外部函数。
2. 如何与模型交互，触发模型对函数的调用。
3. 如何使用模型生成的结果调用外部函数。

如何描述外部函数
假设我们要创建一个具备查询航班功能的聊天机器人。我们定义如下两个外部函数供模型选择调用：
 1. 查询两地之间某日航班号函数：get_flight_number(departure: str, destination: str, date: str)
 2. 查询某航班某日票价函数：get_ticket_price(flight_number: str, date: str)

描述函数功能
为了向模型描述外部函数库，需要向 tools 字段传入可以调用的函数列表。参数如下表：
参数名称 | 类型 | 是否必填 | 参数说明
--- | --- | --- | ---
type | String | 是 | 设置为function
function | Object | 是 |

示例：
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_flight_number",
            "description": "根据始发地、目的地和日期，查询对应日期的航班号",
            "parameters": {
                ......
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_ticket_price",
            "description": "查询某航班在某日的票价",
            "parameters": {
                ......
            },
        }
    },
]

编写函数参数列表的 JSON 描述
为了准确定义函数的参数列表，在编写参数列表的 JSON Schema 时建议最少包含以下字段：
description ：说明函数方法的用途。
type ：定义 JSON 数据的数据类型约束。
properties：一个Object，其中的每个属性代表要定义的 JSON 数据中的一个键。
required：指定哪些属性在数据中必须被包含。
enum：如果一个属性是枚举类型，则此字段应当设置为枚举值的数组。

则完整的tools字段设置为：
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_flight_number",
            "description": "根据始发地、目的地和日期，查询对应日期的航班号",
            "parameters": {
                "type": "object",
                "properties": {
                    "departure": {
                        "description": "出发地",
                        "type": "string"
                    },
                    "destination": {
                        "description": "目的地",
                        "type": "string"
                    },
                    "date": {
                        "description": "日期",
                        "type": "string",
                    }
                },
                "required": [ "departure", "destination", "date" ]
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_ticket_price",
            "description": "查询某航班在某日的票价",
            "parameters": {
                "type": "object",
                "properties": {
                    "flight_number": {
                        "description": "航班号",
                        "type": "string"
                    },
                    "date": {
                        "description": "日期",
                        "type": "string",
                    }
                },
                "required": [ "flight_number", "date"]
            },
        }
    },
]

函数调用选择
在 tools 参数中，如果填写了 functions 参数，则默认情况下模型将决定何时适合使用其中一个函数。 如果要控制模型如何选择函数调用，需要设置 tool_choice 参数。参数默认值为auto，此时模型根据上下文信息自行选择是否返回函数调用。将其设置为 {"name": "your_function_name"} 时，可以强制 API 返回特定函数的调用。还可以通过将 tool_choice 参数设置为 "none" 来强制 API 不返回任何函数的调用。目前函数调用仅支持 auto 模式。

Function Call 流程实践
本节将以上文定义的具备查询航班功能的聊天机器人为例，介绍如何与模型对话完成函数调用。

初始化函数定义和client：
```
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
messages = []
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_flight_number",
            "description": "根据始发地、目的地和日期，查询对应日期的航班号",
            "parameters": {
                "type": "object",
                "properties": {
                    "departure": {
                        "description": "出发地",
                        "type": "string"
                    },
                    "destination": {
                        "description": "目的地",
                        "type": "string"
                    },
                    "date": {
                        "description": "日期",
                        "type": "string",
                    }
                },
                "required": [ "departure", "destination", "date" ]
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_ticket_price",
            "description": "查询某航班在某日的票价",
            "parameters": {
                "type": "object",
                "properties": {
                    "flight_number": {
                        "description": "航班号",
                        "type": "string"
                    },
                    "date": {
                        "description": "日期",
                        "type": "string",
                    }
                },
                "required": [ "flight_number", "date"]
            },
        }
    },
]
```

我们想查询2024年1月20日从北京前往上海的航班。我们向模型提供这个信息：
```
messages.append({
    "role": "user",
    "content": "帮我查询从2024年1月20日，从北京出发前往上海的航班"
})
response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=messages,
    tools=tools,
)
print(response.choices[0].message)
messages.append(response.choices[0].message.model_dump())
```

此时模型成功触发对get_flight_number函数的调用，参数为：date="2024-01-20",departure="北京",destination="上海"

```
content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8252663420321749719', function=Function(arguments='{"date":"2024-01-20","departure":"北京","destination":"上海"}', name='get_flight_number'), type='function')]
```

现在，清空消息历史。我们尝试提供信息，触发模型对get_ticket_price函数的调用。
```
messages = []
messages.append({
    "role": "system",
    "content": "不要假设或猜测传入函数的参数值。如果用户的描述不明确，请要求用户提供必要信息"
})
messages.append({
    "role": "user",
    "content": "帮我查询2024年1月20日1234航班的票价"
})
response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=messages,
    tools=tools,
)
print(response.choices[0].message)
messages.append(response.choices[0].message.model_dump())
```

此时模型成功触发对get_ticket_price函数的调用，参数为：date="2024-01-20",flight_number="1234"

```
content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8252648611274312180', function=Function(arguments='{"date":"2024-01-20","flight_number":"1234"}', name='get_ticket_price'), type='function')]
```

我们也可以强制模型使用特定函数，比如，我们通过设置tool_choice为{"type": "function", "function": {"name": "get_ticket_price"}}以强制模型生成调用get_ticket_price的参数。

```
messages = []
messages.append({
    "role": "system",
    "content": "不要假设或猜测传入函数的参数值。如果用户的描述不明确，请要求用户提供必要信息"
})
messages.append({
    "role": "user",
    "content": "帮我查询1234航班的票价"
})
response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=messages,
    tools=tools,
 tool_choice={"type": "function", "function": {"name": "get_ticket_price"}},
)
print(response.choices[0].message)
messages.append(response.choices[0].message.model_dump())
```

此时模型被强制触发对get_ticket_price函数的调用，参数为：date="2022-01-01",flight_number="1234"。注意到此时模型假设了一个date。

```
content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8252663214163297577', function=Function(arguments='{"date":"2022-01-01","flight_number":"1234"}', name='get_ticket_price'), type='function')]
```

我们也可以强制模型不调用函数。需要设置tool_choice为none。
使用模型生成的参数调用函数
将所需的函数实现
```
def get_flight_number(date:str , departure:str , destination:str):
    flight_number = {
        "北京":{
            "上海" : "1234",
            "广州" : "8321",
        },
        "上海":{
            "北京" : "1233",
            "广州" : "8123",
        }
    }
    return { "flight_number":flight_number[departure][destination] }

def get_ticket_price(date:str , flight_number:str):
    return {"ticket_price": "1000"}
```

定义处理 Function call 的函数：
```
def parse_function_call(model_response,messages):
    # 处理函数调用结果，根据模型返回参数，调用对应的函数。
    # 调用函数返回结果后构造tool message，再次调用模型，将函数结果输入模型
    # 模型会将函数调用结果以自然语言格式返回给用户。
    if model_response.choices[0].message.tool_calls:
        tool_call = model_response.choices[0].message.tool_calls[0]
        args = tool_call.function.arguments
        function_result = {}
        if tool_call.function.name == "get_flight_number":
            function_result = get_flight_number(**json.loads(args))
        if tool_call.function.name == "get_ticket_price":
            function_result = get_ticket_price(**json.loads(args))
        messages.append({
            "role": "tool",
            "content": f"{json.dumps(function_result)}",
            "tool_call_id":tool_call.id
        })
        response = client.chat.completions.create(
            model="glm-4",  # 填写需要调用的模型名称
            messages=messages,
            tools=tools,
        )
        print(response.choices[0].message)
        messages.append(response.choices[0].message.model_dump())
```

查询北京到广州的航班：
```
# 清空对话
messages = []
messages.append({
    "role": "system",
    "content": "不要假设或猜测传入函数的参数值。如果用户的描述不明确，请要求用户提供必要信息"
})
messages.append({
    "role": "user",
    "content": "帮我查询1月23日，北京到广州的航班"
})

response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=messages,
    tools=tools,
)
print(response.choices[0].message)
messages.append(response.choices[0].message.model_dump())

parse_function_call(response,messages)
```

返回
```
content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8282666790542042140', function=Function(arguments='{"date":"2023-01-23","departure":"北京","destination":"广州"}', name='get_flight_number'), type='function')]
content='根据您的要求，我已经查询到了1月23日从北京到广州的航班号，航班号为8321。' role='assistant' tool_calls=None
```

查询1234航班票价：
```
messages.append({
    "role": "user",
    "content": "这趟航班的价格是多少？"
})
response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=messages,
    tools=tools,
)
print(response.choices[0].message)
messages.append(response.choices[0].message.model_dump())

parse_function_call(response,messages)
```

返回
```
content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8282666893621289712', function=Function(arguments='{"date":"2023-01-23","flight_number":"8321"}', name='get_ticket_price'), type='function')]
content='这趟航班的票价为1000元。' role='assistant' tool_calls=None
```

<end>
文件问答
介绍
文件内容抽取用于获取文件中的文本内容，您可以通过此工具实现文件问答，下面我们用一个代码示例来讲述如何通过 API 实现文件问答：

1. 利用开放平台的文件上传功能，完成文件的上传；
2. 通过文件内容抽取接口，提取上传文件中的文本；
3. 将抽取到的文件内容添加至messages的任意位置，并发送给大模型；

单文件问答调用示例
```python
from zhipuai import ZhipuAI
from pathlib import Path
import json

# 填写您自己的APIKey
client = ZhipuAI(api_key="your_api_key_here")

# 格式限制：PDF、DOCX、DOC、XLS、XLSX、PPT、PPTX、PNG、JPG、JPEG、CSV
# 文件大小不超过50M，图片大小不超过5M、总数限制为100个文件
file_object = client.files.create(file=Path("aaa.pdf"), purpose="file-extract")

# 获取文本内容
file_content = json.loads(client.files.content(file_id=file_object.id).content)["content"]

# 生成请求消息
message_content = f"请对\n{file_content}\n的内容进行分析，并撰写一份论文摘要。"

response = client.chat.completions.create(
    model="glm-4-long",
    messages=[
        {
            "role": "user",
            "content": message_content
        }
    ],
)

print(response.choices[0].message)
```

多文件问答调用示例
```python
from zhipuai import ZhipuAI
from pathlib import Path
import json

# 填写您自己的APIKey
client = ZhipuAI(api_key="your_api_key_here")

# 上传并提取文本内容
file_01 = client.files.create(file=Path("aaa.pdf"), purpose="file-extract")
content_01 = json.loads(client.files.content(file_01.id).content)["content"]

# 上传并提取文本内容
file_02 = client.files.create(file=Path("bbb.pdf"), purpose="file-extract")
content_02 = json.loads(client.files.content(file_02.id).content)["content"]

# 生成请求消息，将不同文件的内容放入消息中
message_content = (
    "请对以下论文进行分析，并且生成一份论文综述："
    "第一篇论文内容如下："
    f"{content_01}"
    "第二篇论文内容如下："
    f"{content_02}"
)

response = client.chat.completions.create(
    model="glm-4-long",
    messages=[
        {
            "role": "user",
            "content": message_content
        }
    ],
)

print(response.choices[0].message)
```

常见问题
支持哪些文件格式？
- 支持PDF、DOCX、DOC、XLS、XLSX、PPT、PPTX、PNG、JPG、JPEG、CSV等文件格式。

文件大小有什么限制？
- 单个文件的最大限制是50MB、图片的最大限制是5MB。

可以上传多少文件？
- 每个用户最多可以上传100个文件。
- 建议在提取数据后删除文件，并将文件抽取内容存储到本地，避免重复上传。

<end>
模型微调
概览
模型微调是指通过微调工具，加入企业独有的场景数据，对平台的基础模型进行微调。它可以帮助您快速定制出更符合您业务场景需求的专属大模型。它的优势在于对基础模型进行少量调整，满足特定的需求。相比训练新模型高效且低成本。

什么场景下适用微调
您可以先尝试调整提示词或者使用一些工具如函数调用 、检索功能来获得更好的效果。若您仍认为目前的基础模型及相关工具无法提供满意答案或处理复杂推理任务时，可以使用微调获得更好的效果。
微调可改善效果的典型场景：
- 需要采用特定的风格、语调
- 需要处理复杂的任务
- 需要提高输出的可靠性
- 难以通过 Prompt 说明的新任务

微调方式有哪些
1. LoRA微调
   - 含义：通过在模型的现有权重矩阵中添加低秩矩阵来调整模型，可以在增加少量计算负担的情况下有效调整模型。
   - 优点：只需要添加少量参数，参数效率高；资源利用少且训练周期较短

2. 全参微调
   - 含义：对预训练模型的所有参数进行调整获得新模型。
   - 优点：可以对模型进行全面的调整，使其更好地适应新任务；在有足够数据和计算资源的情况下，更可能达到更优的性能。

哪些模型可以微调
- glm-4-0520（LoRA微调、全参微调，云端私有化套餐用户可用）
- glm-4-air（LoRA微调、全参微调，云端私有化套餐用户可用）
- glm-4-flash（LoRA微调、全参微调，所有用户可用）
- glm-4-9b（LoRA微调、全参微调，所有用户可用）
- chatglm3-6b（LoRA微调，所有用户可用）

微调的步骤
通常情况下，完成模型微调涉及以下步骤：
1. 准备并上传训练数据
2. 训练新的微调模型
3. 部署并使用微调模型（LoRA微调支持公有池推理，可以不进行部署操作）
4. 评估结果，如有需要返回到步骤1

准备训练数据
微调训练数据通常由一批包含输入和期望输出的数据构成，每条训练数据由单个输入（Prompt）以及对应的期望输出组成。目前仅支持以 json 格式的文件上传训练数据。

数据集要求
- 提供更多的高质量训练数据，微调效果越好。
- 根据训练目标调控数据分布，尽量覆盖业务场景所有可能的数据样本。
- 避免有害数据，确保数据中不包含有害信息。

数据集格式
按示例中的格式准备数据集，json 格式，每行一条，存储到文件中并调用文件管理接口上传文件。

创建微调任务
如您已经按照上述说明准备好了优质的训练数据，接下来您可以开始创建微调任务，训练模型。您可以通过页面操作微调任务创建，入口如下：
- 模型广场点击模型卡片内微调按键
- 微调任务「+创建微调任务」按键

部署微调模型
模型完成训练后可进行部署，部署入口如下：
- 模型广场点击模型卡片内部署按键
- 私有实例「+创建部署任务」按键

使用微调模型
模型完成微调训练后，您可以通过体验中心或 API 使用该模型。通过API请求时，您可以将您命名的新模型编码作为 model 参数的值来传参发出请求。

调用示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
response = client.chat.completions.create(
    model="chatglm3-6b-1001",  # 填写需要调用的模型名称
    messages=[
        {"role": "system", "content": "你是一个人工智能助手，你叫叫chatGLM"},
        {"role": "user", "content": "你好！你叫什么名字"},
    ],
    stream=True,
)
for chunk in response:
    print(chunk.choices[0].delta)
```

<end>
Batch API
概述
Batch API 适用于无需即时反馈并需使用大模型处理大量请求的场景。通过 Batch API，开发者可以通过文件提交大量任务，且价格降低50%、无并发限制，并在24小时内完成任务处理。典型应用场景包括：
- 文章分类：为大量文章、帖子或产品描述添加分类标签。
- 情感分析：评估客户反馈、社交媒体帖子和商品评价的情感倾向。
- 文档处理：为大量文档生成摘要、提炼关键信息或进行翻译。
- 信息提取：从文本数据中识别和抽取关键内容
本指南将通过实际场景示例，向您介绍如何使用 Batch API。

Batch API 教程：
我们将使用 GLM-4 对商品评价进行情感分类（正面、中性、负面），并添加特定问题标签（如产品缺陷、配送延迟、客服态度等）。预期的结果格式如下：
{
    "分类标签": "负面",
    "特定问题标签": "产品缺陷"
}

创建 Batch 文件
Batch 文件的格式应为 .jsonl，其中每个请求占据一行（JSON 对象）。每一行包含 API 单个请求的详细信息。每个请求的定义如下：

- "custom_id": "request-1" #每个请求必须包含custom_id且是唯一的，用来将结果和输入进行匹配
- "method": "POST"
- "url": "/v4/chat/completions"
- "body": {
    "model": "glm-4" #每个batch文件只能包含对单个模型的请求,支持 glm-4-0520 glm-4-air、glm-4-flash、glm-4、glm-3-turbo.
    "messages": [
        {
            "role": "system",
            "content": "你是一个意图分类器."
        },
        {
            "role": "user",
            "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
            # 评论：review = \"订单处理速度太慢，等了很久才发货。\"
            # 输出格式：
            {\n \"分类标签\": \" \", \n \"特定问题标注\": \" \" } "
        }
    ],
    "temperature": 0.1
}

如何构建高质量prompt，请参考 prompt工程。

构建的 .jsonl 文件如下，本示例中包含 10 个请求，单个文件最多支持 50000 个请求且大小不超过 100M：

{
    "custom_id": "request-1",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"订单处理速度太慢，等了很久才发货。\"
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-2",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \",商品有点小瑕疵，不过客服处理得很快，总体满意。\",
                # 输出格式：
                '''{\",分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-3",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"这款产品性价比很高，非常满意。\"
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-4",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"说明书写得不清楚，看了半天也不知道怎么用。\"
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-5",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"总体还不错，但价格偏高，不太划算。\"
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-6",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"物流速度很慢，等了两个星期才收到货 \""
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-7",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"收到的产品跟描述不符，有些失望。\"
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-8",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"客服很耐心，解决问题很快，感谢！\"
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-9",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"包装太简单，商品在运输过程中被压坏了。\"
                # 输出格式：
                '''{\"分类标签
\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}
{
    "custom_id": "request-10",
    "method": "POST",
    "url": "/v4/chat/completions",
    "body": {
        "model": "glm-4",
        "messages": [
            {
                "role": "system",
                "content": "你是一个意图分类器."
            },
            {
                "role": "user",
                "content": "#任务：对以下用户评论进行情感分类和特定问题标签标注，只输出结果，
                # 评论：review = \"产品质量不错，但是颜色和图片上的不一样\"
                # 输出格式：
                '''{\"分类标签\": \" \", \"特定问题标注\": \" \" } '''"
            }
        ]
    }
}

上传文件
通过文件管理上传 Batch 文件并获取文件 ID。

```python
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="") # 请填写您自己的APIKey

result = client.files.create(
    file=open("product_reviews.jsonl", "rb"),
    purpose="batch"
)
print(result.id)
```

创建 Batch 任务
成功上传输入文件后，您可以使Batch 文件的 id 创建 Batch 任务。在本示例中，我们假设文件 ID 为 file_123。

```python
from zhipuai import ZhipuAI

client = ZhipuAI()  # 填写您自己的APIKey

create = client.batches.create(
    input_file_id="file_123",
    endpoint="/v4/chat/completions",
    completion_window="24h", #完成时间只支持 24 小时
    metadata={
        "description": "Sentiment classification"
    }
)
print(create)
```

检查 Batch 状态
Batch 任务将在 24 小时内处理完成，状态为 "completed" 表示任务已完成。

```python
batch_job = client.batches.retrieve("batch_id")
print(batch_job)
```

状态 | 描述
--- | ---
validating | 文件正在验证中，Batch 任务未开始
failed | 文件未通过验证
in_progress | 文件已成功验证，Batch 任务正在进行中
finalizing | Batch 任务已完成，结果正在准备中
completed | Batch 任务已完成，结果已准备好
expired | Batch 任务未能在24小时内完成
cancelling | Batch 任务正在取消中
cancelled | Batch 任务已取消

下载 Batch 结果
Batch 任务完成后，您可以使用 Batch 对象中的output_file_id 字段下载结果，并将其保存到本地。

注意：系统只保留您的数据30天。请及时下载和备份您的数据，过期后文件将自动删除，无法恢复。

```python
from zhipuai import ZhipuAI

client = ZhipuAI()  # 填写您自己的APIKey

# client.files.content返回 _legacy_response.HttpxBinaryResponseContent实例
content = client.files.content("file-456")

# 使用write_to_file方法把返回结果写入文件
content.write_to_file("write_to_file_batchoutput.jsonl")
```

最终处理完成的结果如下：

```
{
    "response":{
        "status_code":200,
        "body":{
            "created":1715959701,
            "usage":{
                "completion_tokens":26,
                "prompt_tokens":89,
                "total_tokens":115
            },
            "model":"glm-4",
            "id":"8668357533850320547",
            "choices":[
                {
                    "finish_reason":"stop",
                    "index":0,
                    "message":{
                        "role":"assistant",
                        "content":"```json\n{\n \"分类标签\": \"负面\",\n \"特定问题标注\": \"订单处理慢\"\n}\n```"
                    }
                }
            ],
            "request_id":"615-request-1"
        }
    },
    "custom_id":"request-1",
    "id":"batch_1791490810192076800"
}
```

删除文件
上传 Batch 文件时，每次最多上传100个。若任务量巨大，请及时删除已处理完毕的文件，以便继续上传新文件。

```python
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="") # 请填写您自己的APIKey

result = client.file.delete(
    id="文件id"
)
```

常见问题
支持的Batch API模型有哪些？
- GLM-4-Flash
- GLM-4-Air
- GLM-3-Turbo
- Embedding-2
- Embedding-3
- GLM-4-0520
- GLM-4
- GLM-4-FLash
- Cogview-3
- CogVideoX
- GLM-4V

Batch API的价格如何？
价格是标准API的50%。参考产品定价

Batch API的并发限制是怎样的？
Batch API 的并发限制与现有的每个模型并发限制是分开的。BatchAPI 引入了两种新的限制：
- 单个 Batch 文件中包含最多 50,000 个请求且不超过 100M。
- 每个模型的 Batch 有最大排队限制。当达到请求队列上限时，请等待当前任务完成后再提交新任务。

模型 | Batch 队列限制
--- | ---
GLM-4-Flash | 100万次
GLM-4-Air | 100万次
GLM-3-Turbo | 20万次
Embedding-2 | 20万次
Embedding-3 | 20万次
GLM-4-0520 | 5万次
GLM-4 | 5万次
GLM-4-FLash | 5万次
Cogview-3 | 3千次
CogVideoX | 1千次
GLM-4V | 1千次

如何在调用Batch API 前进行实名认证？
调用Batch API 必须实名认证，请先前往实名认证页面完成个人认证或企业认证，成功认证后，将免费获得500万tokens。

Batch 的过期如何处理？
如果Batch未能及时完成，该批次将被标记为过期状态；批次中未完成的请求将被取消。对于批次中已完成的请求，用户可以通过文件获取，并且需要支付这些请求消耗的费用。

Batch 文件有哪些存储限制？
Batch 文件最多上传100个文件。系统只保留您的文件30天，过期后文件将自动删除，无法恢复。

如何删除Batch 文件？
请前往 Batch数据页面进行删除、或通过调用接口删除。

以上内容未解决您的问题？请加入开放平台社群。

<end>
代码沙盒
介绍
GLM-4-AllTools模型提供了 Code Interpreter 工具能够准确理解自然语言描述的编程需求，自动生成代码片段来解决实际问题。同时支持安全代码沙盒 Sandbox，可以在其中模拟真实环境中的代码执行结果。

用法
开启代码沙盒
使用模型时，如果选择 Code Interpreter 工具，默认会调用沙盒环境执行代码，对应参数为 sandbox = auto 。

调用示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"每年五一假期全国旅游出行数据是[100,200,300,400,500]，绘制成柱状图展示数据趋势。"
                }
            ]
        }
    ],
    stream=True,
    tools=[
      {
        "type": "code_interpreter"
      }
    ]
)

for chunk in response:
   print(chunk)
```

响应示例
开启代码沙盒后，模型自动生成代码并执行代码输出结果，进一步推理。

```python
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': ' the'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': ' chart'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': '\n'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': 'plt'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': '.'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': 'show'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': '()'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=None), finish_reason='tool_calls', index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='tool', tool_calls=[ChoiceDeltaToolCall(index=None, id=None, function=None, type='code_interpreter', code_interpreter={'outputs': [{'type': 'file', 'file': 'http://all-tool-interpreter.cn-wlcb.ufileos.com/10571a86-9194-43f7-ab2c-274ba29b9835_fig.png'}]})]), finish_reason=None, index=0)], created=1718687735, model='glm-4-alltools', usage=None, extra_json=None)
```

关闭代码沙盒
如果只需要模型生成代码，不需要代码沙盒来运行，设置参数 sandbox = none，代码生成后返回状态 status = requires_action，需要用户提交代码执行结果。

调用示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"每年五一假期全国旅游出行数据是[100,200,300,400,500]，绘制成柱状图展示数据趋势。"
                }
            ]
        }
    ],
    stream=True,
    tools=[
      {
        "type": "code_interpreter",
        "code_interpreter":{
            "sandbox":"none"
        }
      }
    ]
)

for chunk in response:
   print(chunk)
```

响应示例
关闭了沙盒后，模型生成代码后，会返回 status = requires_action。

```python
ChatCompletionChunk(id='60955153-fcff-4c7b-b610-166cab49a92b', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_Oiwh-QgVVajIUhafnJsFG', function=None, type='code_interpreter', code_interpreter={'input': '\n'})]), finish_reason=None, index=0)], created=1719802220, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='60955153-fcff-4c7b-b610-166cab49a92b', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_Oiwh-QgVVajIUhafnJsFG', function=None, type='code_interpreter', code_interpreter={'input': 'plt'})]), finish_reason=None, index=0)], created=1719802220, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='60955153-fcff-4c7b-b610-166cab49a92b', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_Oiwh-QgVVajIUhafnJsFG', function=None, type='code_interpreter', code_interpreter={'input': '.'})]), finish_reason=None, index=0)], created=1719802220, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='60955153-fcff-4c7b-b610-166cab49a92b', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_Oiwh-QgVVajIUhafnJsFG', function=None, type='code_interpreter', code_interpreter={'input': 'show'})]), finish_reason=None, index=0)], created=1719802220, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='60955153-fcff-4c7b-b610-166cab49a
92b', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_Oiwh-QgVVajIUhafnJsFG', function=None, type='code_interpreter', code_interpreter={'input': '()'})]), finish_reason=None, index=0)], created=1719802220, model='glm-4-alltools', usage=None, extra_json=None)
ChatCompletionChunk(id='60955153-fcff-4c7b-b610-166cab49a92b', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_Oiwh-QgVVajIUhafnJsFG', function=None, type='code_interpreter', code_interpreter={'input': ''})]), finish_reason='tool_calls', index=0)], created=1719802220, model='glm-4-alltools', usage=CompletionUsage(prompt_tokens=510, completion_tokens=226, total_tokens=736), extra_json=None, status='requires_action')
```

提交沙盒结果
接下来，需要用户提交代码沙盒的运行结果 Tool Message ，以及模型生成的代码 Assistant Message，提交后模型会继续推理。

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"每年五一假期全国旅游出行数据是[100,200,300,400,500]，绘制成柱状图展示数据趋势。"
                }
            ]
        },
        {
            "role": "assistant",
            "content":"""
                import matplotlib.pyplot as plt

                # Data received from the API
                years = ["2018", "2019", "2020", "2021", "2022", "2023", "2024"]
                tourist_data = [100, 100, 200, 200, 300, 400, 500]  # Assuming the data for 2023 and 2024 based on the trend

                # Creating a bar chart
                plt.figure(figsize=(10, 6))
                plt.bar(years, tourist_data, color='skyblue')
                plt.xlabel('年份')
                plt.ylabel('旅游出行人数')
                plt.title('2018年至2024年五一假期全国旅游出行数据趋势')
                plt.grid(axis='y')

                # Show the chart
                plt.show()
            """,
        },
        {
            "role": "tool",
            "content":"http://all-tool-interpreter.cn-wlcb.ufileos.com/e01459c3-ddd6-4963-adf7-163513184f0c_fig.png"
        }
    ],
    stream=True,
    tools=[
      {
        "type": "code_interpreter",
        "code_interpreter":{
            "sandbox":"none"
        }
      }
    ]
)

for chunk in response:
   print(chunk)
```

链接信息：
1. http://all-tool-interpreter.cn-wlcb.ufileos.com/10571a86-9194-43f7-ab2c-274ba29b9835_fig.png
2. http://all-tool-interpreter.cn-wlcb.ufileos.com/e01459c3-ddd6-4963-adf7-163513184f0c_fig.png
<end>
提示工程
本指南分享了 GLM 语言模型和 CogView 图像生成模型获得更好生成结果的策略。可以组合使用提示词技巧以获得更好的生成效果。

语言模型 Prompt 工程
策略：编写清晰、具体的指令
为了获得最佳的回答，用户需要向 GLM 提供清晰、具体的指令。GLM 越能明确您的需求，提供的回答质量越高。

技巧：定义 System Prompt
用于设定AI助手行为模式的工具，包括角色设定、语言风格、任务模式和针对特定问题的具体行为指导。
推荐示例
你擅长从文本中提取关键信息，精确、数据驱动，重点突出关键信息，根据用户提供的文本片段提取关键数据和事实，将提取的信息以清晰的 JSON格式呈现。

技巧：提供具体的细节要求
在 Prompt 中添加要求模型输出内容的细节和背景信息。
推荐示例
我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。

技巧：让 GLM 进行角色扮演
让 GLM 扮演角色、可以更准确地模仿该角色的行为和对话方式。
推荐示例
作为一个量子物理学家，解释量子物理学的基本原理，并简要介绍其在现代科技中的应用。

技巧：使用分隔符标示不同的输入部分
推荐示例
请基于以下内容：
""" 要总结的文章内容"""
提炼核心观点和纲要

技巧：思维链提示
要求模型分步骤解答问题，还要求其展示其推理过程的每个步骤。通过这种方式，可以减少不准确结果的可能性，并使用户更容易评估模型的响应。
推荐示例
作为一个 AI 助手，你的任务是帮助用户解决复杂的数学问题。对于每个问题，你需要首先独立解决它，然后比较和评估用户的答案，并最终提供反馈。在这个过程中，请展示你的每一步推理过程。我有一个数学问题需要帮助:"""问题是：一个农场有鸡和牛共 35 头，脚总共有 94 只。鸡和牛各有多少头？我的答案是鸡有 23 头，牛有 12 头"""。

技巧：少样本学习
可以作为进行少样本学习的示例。这些样本可以用来引导模型模仿特定的行为和语言风格。
推荐示例
模仿这种风格
    ''1、三杯鸡在锅中欢跃，是岁月的篝火，是浪漫的乐章。
        2、炖排骨的滋味，是冬日的棉被，是乡土的回响。
        3、红烧勤鱼的鲜香，是海洋的密语，是大海的情书。'''
生成新的句子。

指定输出长度的示例
指定按照具体的长度的输出内容，但是让模型精确的生成一个特定的字数难以实现。
推荐示例
请用不超过 100 个词的长度来总结这篇文章。

策略：提供参考资料
引用外部资料能有效提升模型回答的准确性。这种做法特别适用于基于文档的问答系统，因为它有助于减少错误或虚构信息的生成，同时确保回答的时效性和准确性。当模型受到上下文长度限制，无法引用超长文本时，可以通过 Retrieval 工具来获取文档中的语义切片来实现。
推荐示例
作为AI助手，你的任务是帮助用户查找和理解特定公司的规章制度。在这个场景中，你将使用搜索结果来回答用户关于公司请假政策的查询。请根据搜索结果
"""具体的搜索结果"""
提供准确和详细的信息。

策略：将复杂任务分解为简单的子任务
在处理需求复杂的任务时，错误率通常较高。为了提高效率和准确性，最佳做法是将这些复杂任务重构为一系列简单、连贯的子任务。这种方法中，每个子任务的完成成果依次成为下一任务的起点，形成一个高效的工作流。这样的任务流程简化有助于提升模型整体的处理质量和可靠性，特别是在面对需要综合大量数据和深入分析的复杂问题时。通过将复杂任务拆解，可以更加有效地利用模型的强大处理能力。
技巧：意图理解和实体提取
要求大模型输出的内容要直接给到后端服务接口使用，所以大模型一定要按照固定格式输出格式，以便于接口解析模型输出内容，防止报错。
推荐示例
当你理解用户的预约会议室的意图时，提取相关的实体，并且以 Json 格式输出。

技巧：总结上文关键信息
在长对话中，为了确保对话的连贯性和有效性，对之前的交流内容进行精炼和总结，可以保持对话的焦点、减少重复和混乱、加快模型处理速度。

技巧：分段归纳长文档并逐步构建完整摘要
由于模型处理文本的上下文长度有限，它无法一次性总结超出特定长度的文本。例如，在总结一本长书时，我们可以采用分步骤的方法，逐章节进行总结。各章节的摘要可以组合在一起，再进行进一步的概括，形成更为精炼的总摘要。这个过程可以重复进行，直到整本书的内容被完整总结。如果后续章节的理解需要依赖于前面章节的信息，那么在当前部分的总结中附加之前内容的连贯摘要，能够显著提升模型的生成质量。

策略：给于模型思考时间
技巧：在模型给出最终结论之前，先引导它进行自我探索和推理。
在明确引导模型进行推理判断之前，让它先生成结果作为基准。例如，如果我们需要模型评估代码的质量，可以先让模型自行生成答案，随后再对其正确性进行评判。这样做不仅促使模型更加深入地理解任务，还可以提高最终结果的准确性和可靠性。
推荐示例
分析并评估以下 Python 代码片段"代码片段"的质量和功能。在生成你的回答之前，请先生成推荐示例代码，然后对代码的结构、清晰度以及其执行的功能进行评分。

技巧：隐藏推理过程，只输出结果
在回答问题之前，模型有时需要进行深入的推理并将推理过程一并输出，可以引导模型只输出结果或者结构化信息以便于解析处理。
推荐示例
请计算函数 f(x) = x^2 在区间 [0, 1] 上的积分。仅提供最终的积分结果，无需展示推理过程。

策略：使用外部工具增强模型能力
通过让模型访问工具的获取信息来弥补模型的缺陷和拓展功能，如通过 Function Call 访问外部的信息和执行操作，利用 Retrieval 工具访问知识库获取文档信息。
技巧：通过 Function Call 访问外部 API
允许模型访问外部信息和执行操作，信息查询：如实时天气预报、股票市场动态，提供即时且准确的数据，执行操作：比如播放音乐、控制智能家居设备等。
推荐示例
使用外部 API 查询天气信息的功能。请根据用户的请求，调用相应的天气服务 API ，获取并展示最新的天气信息，包括温度、湿度、天气状况（如晴、雨等），风速和风向。例如，当用户询问‘北京今天的天气如何？’时，应调用API获取北京当前的天气数据，并以用户友好的方式展示结果。

技巧：通过 Retrieval 访问智谱AI 开放平台的知识库
通过Retrieval方法访问智谱开放平台的知识库，用户可上传相关的知识到知识库，模型将基于用户的查询，，提取相关的语义切片，提供更加精准详细的信息。
推荐示例
作为 AI 助手，你的任务是帮助用户查找和理解特定公司的规章制度。用户询问关于公司的相关政策。你将通过搜索公司内部知识库或相关文档，找到最新的规定。根据搜索到的内容，提供关于相关的详细信息。请确保所提供信息的准确性和适用性，帮助用户完全理解公司的政策。

图像生成模型 Prompt 工程
策略：使用结构化的提示语
在使用图像生成工具时，应采用精确、具体的视觉描述而非抽象概念。明确、清晰的结构化提示词可以帮助 CogView 创造出更高质量的图像。
主体: 人、动物、建筑、物体等
媒介: 照片、绘画、插图、雕塑、涂鸦等
环境: 竹林、荷塘、沙漠、月球上、水下等
光线: 自然光、体积光、霓虹灯、工作室灯等
颜色: 单色、复色、彩虹色、柔和色等
情绪 : 开心、生气、悲伤、惊讶等
构图/角度: 肖像、特写、侧脸图、航拍图等

推荐示例:
清晨的阳光照耀下，一只活泼的边牧犬在绿色草地上欢快奔跑，这一场景以生动的彩色摄影方式，呈现出愉快的氛围和明亮的色彩。

在平静的河流上，一座古老的石桥被周围的垂柳环绕，黑白水墨画描绘出它在阳光下的宁静和古典之美，光线和阴影在画面中形成鲜明对比。

一本敞开的古书静卧在老式木桌上，台灯的光线柔和地照亮书页，周围是昏暗的图书馆环境。这个场景通过高清照片捕捉，展现了知识和历史的宁静美。

在干燥的沙漠环境中，一棵孤独的仙人掌在夕阳的余晖中显得格外醒目。这幅油画捕捉了仙人掌坚韧的生命力和沙漠中的壮丽景色，色彩饱满且表现力强烈。

深藏在茂密森林中的一座古朴木屋，在夜幕中被温暖的灯光照亮。这幅油画捕捉了木屋周围自然环境的宁静与和谐，使用柔和的色调和细腻的光影处理，创造了一种神秘而温馨的氛围。画中突出了木屋作为与世隔绝的避难所，和周围树木、灌木的自然美。

Batch API Prompt 工程
Batch API 适用于无需即时反馈但需要处理大量请求的场景。以下是一些典型的任务和最佳实践提示，帮助您更好地使用 Batch API。找不到适合您任务的 prompt？试试我们的 Prompt优化专家吧。

任务一：文本分类:
将大量文本数据分类到预定义类别中，如：新闻分类和垃圾邮件检测等。
推荐示例
# Role:新闻分类器

## Goals
- 对给定新闻进行分类，并仅输出相应的类别。

## Constrains
- 新闻必须属于以下类别之一：军事、财经、民生、文化、其他、待分类。
- 输出结果必须仅为类别名称，不能包含其他多余信息。

## Skills
- 强化新闻分类的能力
- 理解并解析新闻内容
- 确定新闻所属类别

## outfromt
- 输出格式: 类别名称

## Workflow
1. 读取并理解给定的新闻："请在此处插入新闻"。
2. 根据新闻内容，判断其所属类别。
3. 输出判断出的类别名称。

任务二：情感分析：
识别和分析文本中的情感倾向，如：正面、负面或中性情感。
推荐示例
# Role: 情感分析专家

## Goals
- 对给定的文本进行情感分析，并仅输出相应的类别。

## Constrains
- 文本必须属于以下类别之一：正面、负面、中性。
- 输出结果必须仅为类别名称，不能包含其他多余信息。

## Skills
- 情感分析的专业知识
- 理解并解析文本内容
- 确定文本的情感倾向

## Output
- 输出格式: 类别名称

## Workflow
1. 读取并理解给定的文本内容 "请在此处插入待分析的文本"。
2. 根据文本内容，判断其情感倾向。
3. 输出判断出的类别名称。

任务三：文档处理：
处理和分析大量文档，如：文档摘要生成、关键信息提取等。
推荐示例
# Role: 学术摘要专家

## Goals
- 生成给定论文的摘要，简明扼要地概括论文的主要内容和结论。

## Constrains
- 摘要必须简洁明了，重点突出。
- 摘要长度应控制在 150 字以内。
- 输出结果必须仅为摘要内容，不能包含其他多余信息。

## Skills
- 学术论文分析和总结的专业知识
- 高效提取论文的主要内容和结论
- 生成清晰明了的摘要

## Output
- 输出格式: 摘要内容

## Workflow
1. 读取并理解给定的论文内容"请在此处插入待总结的论文"。
2. 提取论文的主要内容和结论。
3. 生成简明扼要的摘要，并输出摘要内容。

任务四：信息抽取：
从大量文本中提取结构化信息，如：命名实体识别（NER）、关系抽取、事件抽取等。
推荐示例
# Role: 命名实体识别专家

## Goals
- 对给定的文本进行命名实体识别。

## Constrains
- 必须识别以下类别的实体：人名、地点、组织。
- 输出结果必须仅为实体信息，不能包含其他多余信息。

## Workflow
1. 读取并理解给定的文本内容 "请在此处插入待分析的文本。"
2. 输出识别的人名、地点、组织。

任务五：机器翻译：
大规模的文本翻译任务，将文本从一种语言翻译成另一种语言。
推荐示例
# Role: 翻译专家

## Goals
- 专注于多语言翻译领域，提供准确且流畅的翻译服务。

## Constrains
- 翻译必须准确，保留原文的意思和语气。
- 翻译结果必须流畅自然，符合目标语言的表达习惯。

## Skills
- 多语言翻译的专业知识
- 理解并准确翻译文本内容
- 确保翻译结果的流畅度和准确性

## Output
- 输出格式: 目标语言的流畅、准确文本

## Workflow
1. 读取并理解给定的文本内容："请在此处插入待翻译的文本。"
2. 将以文本从[源语言]翻译成[目标语言]。
3. 确保翻译结果流畅、准确，并符合目标语言的表达习惯。

任务六：生成任务：
利用语言模型大批量生成文本内容，如：撰写SEO文章、小说创作等。
推荐示例
# Role: SEO内容专家

## Goals
- 编写一篇用于SEO的文章，确保内容包含特定的关键词，以提高搜索引擎的排名。

## Constrains
- 必须包含指定的关键词，并自然地融入文章中。
- 文章内容要有价值，提供独到见解，并保持自然流畅的阅读体验。
- 符合指定的字数范围。

## Skills
- 专业的SEO优化知识
- 高效的内容创作能力
- 理解并自然融入关键词的技巧

## Workflow
1. 确定文章的主题: "请指定文章的主题或标题"
2. 列出需要优化使用的关键词："请在此处列出需要优化使用的关键词"
3. 编写文章，围绕关键词展开，提供有价值且独到的内容。
4. 确保文章自然流畅，符合SEO最佳实践。
5. 输出符合字数范围的文章文本。

任务七：文本纠错：
自动检测和纠正大批量文本中的拼写错误、语法错误等。
推荐示例 glm-4v
# Role:语法和拼写纠错专家

## Goals
- 检测并纠正给定文本中的语法错误、拼写错误以及其他常见的书写错误。

## Constrains
- 必须检测并纠正所有明显的语法和拼写错误。
- 保持文本的原意不变，提高文本的准确性和可读性。

## Skills
- 专业的语法和拼写纠错能力
- 理解并解析文本内容
- 确保纠错后的文本流畅且准确

## Output
- 输出格式: 纠错后的文本

## Workflow
1. 读取并理解给定的文本内容："请在此处插入待纠错的文本"
2. 检测文本中的语法错误、拼写错误和其他书写错误。
3. 纠正所有检测到的错误，确保文本准确且可读。
4. 输出纠错后的文本。

任务八：图像分类：
对大量图像进行分类，如：识别图像中的物体、场景分类等。
推荐示例 glm-4v
## Goals
- 将图像分类到预定义类别之一

## Workflow
1. 读取并理解给定的图像内容。
2. 根据图像内容，从预定义类别列表"预定义类别"中选择一个类别。
3. 输出图像的类别。

任务九：图像标注：
为图像提供准确的标注，如：标出图像内容的坐标点
推荐示例 glm-4v
# Role:坐标标注专家

## Goals
- 在图中标出指定的坐标点，提供准确的坐标标注服务。

## Constrains
- 必须准确标注图像中的所有指定坐标点。
- 提供每个坐标点的详细注释。

## Skills
- 专业的图像分析和坐标标注能力
- 理解并解析图像内容
- 提供准确的坐标标注和注释

## Example
坐标点: [
  {
    "x": 100,
    "y": 150,
{    "注释": "示例坐标1"}
  },
  {
    "x": 200,
    "y": 250,
{    "注释": "示例坐标2"}
  }
]

## Workflow
1. 读取并理解给定的图像内容。
2. 标出图像中的指定坐标点。
3. 为每个坐标点提供详细注释。
4. 输出标注坐标的图像。

任务十：文本提取：
从图像中提取文本信息，如：处理扫描文档、票据等
推荐示例 glm-4v
# Role: 文本提取专家

## Goals
- 从以下发票图像中提取所有文本信息，提供提取的字段及其内容。

## Constrains
- 必须提取发票图像中所有可见的文本信息。
- 提供每个字段及其对应的内容。
- 确保提取的信息准确且易于识别。

## Skills
- 专业的图像文本提取能力
- 理解并解析发票内容
- 提供准确的字段和内容提取

## Example
{
{  "发票号码": "12345678"}
{  "日期": "2023-06-01"}
{  "金额": "$100.00"}
{  "购买方": "张三"}
{  "销售方": "李四"}
{  "商品明细": [
{    {"名称": "商品1"}
{    "数量": "2"}
{    "单价": "$50.00"}
  }]
}

## Workflow
1. 读取并理解给定的发票图像内容。
2. 提取发票图像中所有可见的文本信息。
3. 确定每个字段及其对应的内容。
4. 输出提取的字段及其内容。

任务十一：图像内容分析：
对图像内容进行深度分析，例如情感分析、医学图像识别等。
推荐示例 glm-4v
# Role: 图像情绪识别专家

## Goals
- 分析以下图像，识别图中人物的情绪。

## Constrains
- 必须准确识别图像中的情绪。
- 只输出人物情绪类别，不能包含其他多余信息。

## Skills
- 专业的图像情绪分析能力
- 理解并解析图像内容
- 提供准确的情绪识别结果

## Workflow
1. 读取并理解给定的图像内容。
2. 分析图像中的情绪，提供情绪分析结果。
3. 输出情绪分析结果。

任务十二：图像到文本生成：
根据图像内容生成相应的文本描述，如：新闻报道、社交媒体内容生成等场景。
推荐示例
# Role: 小红书文案专家

## Goals
- 根据以下图像生成适用于小红书的文案。

## Constrains
- 文案需简洁生动，符合小红书的创作风格。
- 突出图像中的关键元素，强调亮点和吸引力。
- 内容需具有互动性，鼓励用户点赞、评论和分享。

## Skills
- 专业的图像分析和文案创作能力
- 理解并解析图像内容
- 提供吸引人且详细的文案

## Workflow
1. 读取并理解给定的图像内容。
2. 分析图像中的关键元素和整体上下文。
3. 生成适用于小红书的文案，简洁生动且具有吸引力。
4. 输出适用于小红书的文案。

<end>
速率限制指南
速率限制
用户的API 使用会受到速率限制，当前我们限制的维度是请求并发数量。

为什么要做速率限制
有效防止请求过载：帮助管理总负载情况，避免请求激增导致的服务器性能问题，提高服务可靠性。
保障资源的公平性及合理利用：避免某一方过多的请求，影响其他方使用。保障更多方的请求调用和用户的使用体验。
安全防护：防止恶意性的攻击，提高整体网络安全。

用量级别等级
当前我们基于用户的月度 API 调用消耗金额情况将速率控制分为6种等级。
消耗金额选取逻辑：我们会选取用户当前月份1号～t-1日的调用 API 推理消耗总金额和用户上个月的 API 调用消耗总金额做比较，取更高金额作为用户当前的 API 消耗金额。
特别的，若您从未曾付费充值/购买过资源包，则会归为免费级别。

用量级别	资质
免费	api调用消耗0元-50元/每月（不含）
用量级别1	api调用消耗50元-500元/每月（不含）
用量级别2	api调用消耗500元-5000元/每月（不含）
用量级别3	api调用消耗5000元-10000元/每月（不含）
用量级别4	api调用消耗10000元-30000元/每月（不含）
用量级别5	api调用消耗30000元以上/每月


模型分类	模型名称	免费	用户级别1	用户级别2	用户级别3	用户级别4	用户级别5
通用模型	GLM-4-Plus	10	15	20	25	30	-
通用模型	GLM-4-0520	10	15	20	25	30	-
通用模型	glm-4-flash-long	10	20	30	50	100	-
通用模型	GLM-4V-Plus	1	3	4	5	6	-
通用模型	GLM-4-AllTools	5	10	15	20	25	-
通用模型	GLM-4-Air	5	50	70	150	300	1000
通用模型	GLM-4-Long	5	10	15	20	25	-
通用模型	GLM-4-AirX	5	10	15	20	25	-
通用模型	GLM-4-Flash	100	200	400	800	1000	1500
通用模型	GLM-4V	5	10	20	30	50	100
图像大模型	CogView-3	5	10	15	20	30	40
视频模型	CogVideoX	1	2	3	4	5	6
向量模型	Embedding-2	5	10	20	30	40	50
图像大模型	CogView-3-Plus	5	10	15	20	30	40
通用模型	CharGLM-3	5	10	20	30	40	50
向量模型	Embedding-3	1	2	4	6	8	10
通用模型	GLM-4	5	10	20	30	100	200
通用模型	GLM-3-Turbo	5	50	70	150	300	1000
代码模型	CodeGeeX-4	5	10	20	30	100	200
通用模型	Web-Search-Pro	1	2	3	4	5	6

其他说明
我们会尽可能的保障用户的正常使用，若评估负载有风险时会根据用户用量等级对应并发数进行相关限制。
私有模型的速率限制情况和部署的实例数量相关，未部署时并发为0。
针对企业权益用户，智谱官方大模型的速率限制将收到并发数量保障，我们将择取企业权益与用量级别两项权益服务中并发数量最高者，为您提供速率限制服务。
<end>
内容安全
介绍
智谱AI致力于做到人工智能的安全可控、可审计、可监督、可追溯和可信赖。为此，我们内置了安全审核机制，旨在减少模型应用中违法及不良信息（包括但不限于违反法律法规、危害国家安全、恶意营销、涉黄、谩骂、暴恐违禁以及其它不良内容）的出现。当我们的内置安全审核机制识别到违法及不良信息时，将提供相应的提示信息或进行拦截处置，例如通过输入拦截、输出限制和终止内容生成。

模型同步响应
当API检测到模型输入或输出内容中含有违法及不良信息时，系统会向开发者返回错误码（1301）、输入（role = user）或输出（role = assistant）、严重程度（level 0-3，level 0表示最严重，3表示轻微），不再同步生成结果。建议开发者采取措施，对用户进行正面引导，以确保内容的合规性和适当性。返回示例如下：

"contentFilter":[{"level":1,"role":"user"}],{"error":{"code":"1301","message":"系统检测到输入或生成内容可能包含不安全或敏感内容，请您避免输入易产生敏感内容的提示语，感谢您的配合。"}

模型流式响应
在模型流式输出生成内容的过程中，我们会分批对模型生成内容进行检测，当检测到违法及不良信息时，API返回错误码（1301），API（V4)返回停止词"finish_reason":"sensitive"。开发者识别到相关信息，应及时采取终止生成、撤回、修改、清屏、重启等措施删除生成内容，并确保不将含有违法及不良信息的内容传递给模型继续生成，避免其造成负面影响。 返回示例如下：

id='202408121950062bfd5bf951d24169', choices=[Choice(delta=ChoiceDelta(content='', role='user', tool_calls=None), finish_reason='sensitive', index=0)], created=1723463407, model='glm-4-0520', usage=None, extra_json=None, content_filter=[{'role': 'user', 'level': 1}]

终端用户管理
在请求中发送终端用户 ID 可以协助平台对终端用户的违规行为、生成违法及不良信息或其他滥用行为进行干预。当我们检测到您的终端用户存在违规、生成违法及不良信息或其他滥用行为时，平台将会对终端用户请求进行封禁处理，避免您的企业账号因终端用户的违规或滥用行为受到影响。

ID 是唯一标识终端用户的字符串，用户ID长度至少为6个字符，但不超过128个字符，您可以通过在API 请求中上传终端用户 ID，如下所示：

{
    "model": "glm-3-turbo",
    "messages": [
     {
        "role": "user",
        "content": "作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan"
     },
     {
        "role": "assistant",
        "content": "当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息"
     },
     {
        "role": "user",
        "content": "智谱AI开放平台"
     }
    ],
    "stream": "true",
    "user_id": "user_123456",
    }

安全测试申请
如果您需要进行安全相关的测试，请联系商务经理、致电（400-6883-991）进行申请，避免您的企业账号出现违规或滥用等问题。

违法及不良内容反馈
智谱AI高度重视生成式人工智能服务的安全性。如果您在开发过程中发现API存在任何安全问题，请联系企业微信客服或者致电（400-6883-991）告知我们。我们非常感谢您的贡献和支持。
<end>
OpenAI模型迁移（搬家计划）
本指南介绍了如何从 OpenAI 模型快速迁移到智谱AI，我们用实例展示这个过程，帮助您更好的完成迁移工作。同时，智谱面向 OpenAI API用户提供「特别搬家计划」，帮助您轻松切换至国产大模型，立即获取相关福利

特别搬家计划
| 开发者专项福利 | 高用量客户专项福利 |
| --- | --- |
| 1.5亿 Tokens（5000万 GLM-4 和 1亿 GLM-4-Air）；从 OpenAI 到 GLM 的系列迁移培训； | OpenAI 使用规模对等的 Token 赠送计划（不设上限）；OpenAI 对等的并发规模；匹配高等级会员政策，最高可享6折；专属搬家顾问和 5 人/天技术专家支持；辅助备案和培训。 |

基础工具包
OpenAI SDK为我们提供了一个开箱即用的调用工具，对此，我们在后端兼容了OpenAI的所有Endpoint, 提供了便捷的迁移方式，仅需更换api_key与base_url，就可以使用我们的模型。
切换API Endpoint
```python
from openai import OpenAI
client = OpenAI(
    api_key="your zhipuai api key",
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
response = client.chat.completions.create(
    model="glm-4",
    messages=[
        {"role": "system", "content": "你是一个聪明且富有创造力的小说作家"},
        {"role": "user", "content": "请你作为童话故事大王，写一篇短篇童话故事。"}
    ],
    top_p=0.7,
    temperature=0.9
)
print(response.choices[0].message)
```

使用智谱AI 官方SDK
智谱AI的部分功能需要您通过官方SDK 进行调用, 您可以通过 pypi 进行安装
```
pip install zhipuai
```

调用示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=[
        {"role": "user", "content": "作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan"},
        {"role": "assistant", "content": "当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息"},
        {"role": "user", "content": "智谱AI开放平台"},
        {"role": "assistant", "content": "智启未来，谱绘无限一智谱AI，让创新触手可及!"},
        {"role": "user", "content": "创造一个更精准、吸引人的slogan"}
    ],
)
print(response.choices[0].message)
```

开源框架
在智能体和相关任务框架的迁移方面，我们支持langchain框架的快速迁移。我们提供了langchain-zhipuai的拓展工具，提供了对BaseChatModel、Embeddings的支持适配，LangChain用户可以使用下面的示例快速完成迁移：
安装 langchain-zhipuai
下载地址 https://github.com/MetaGLM/langchain-zhipuai/releases
使用前请设置环境变量ZHIPUAI_API_KEY，值为智谱AI的API Key。
从ChatOpenAI迁移至ChatZhipuAI
```python
from langchain_zhipuai.agents.zhipuai_all_tools.base import _get_assistants_tool
from langchain_zhipuai.chat_models import ChatZhipuAI
from langchain.agents import tool
from langchain.tools.shell import ShellTool
from pydantic.v1 import BaseModel, Extra, Field
from langchain import hub
from langchain_zhipuai.agents.all_tools_bind.base import create_zhipuai_tools_agent
from langchain_zhipuai.agent_toolkits import BaseToolOutput
from langchain_zhipuai.agents.all_tools_agent import ZhipuAiAllToolsAgentExecutor

@tool
def shell(query: str = Field(description="The command to execute")):
    """Use Shell to execute system shell commands"""
    tool = ShellTool()
    return BaseToolOutput(tool.run(tool_input=query))

llm = ChatZhipuAI(api_key="") # 这里可以指定apikey

tools = [
    _get_assistants_tool(shell),
    {"type": "code_interpreter", "code_interpreter": {"sandbox": "none"}},
    {"type": "web_browser"},
    {"type": "drawing_tool"},
]

llm_with_all_tools = llm.bind(
    tools=tools
)

prompt = hub.pull("zhipuai-all-tools-chat/zhipuai-all-tools-agent")
agent = create_zhipuai_tools_agent(
    prompt=prompt, llm_with_all_tools=llm_with_all_tools
)

agent_executor = ZhipuAiAllToolsAgentExecutor(
    agent=agent,
    tools=[shell] ,
    verbose=True,
    return_intermediate_steps=True,
)

agent_executor.invoke(
    {
        "input": "你好",
        "chat_history": [],
    }
)
```

兼容向量数据库
我们提供了兼容 OpenAI 的Embedding调用方式，使用向量库相关的 Embeddings 时，您只需要替换 Embedding的实例为ZhipuAIEmbeddings。
```python
from langchain_zhipuai.embeddings.base import ZhipuAIEmbeddings

"""Test zhipuai embeddings."""
documents = ["foo bar"]
embedding = ZhipuAIEmbeddings()
output = embedding.embed_documents(documents)
# len(output) == 1
# len(output[0]) ==1024

<end>
企业权益
概述
任何完成企业认证的开发者可享有智谱企业权益。
企业开发者通过消耗账户余额、实时计费调用模型API接口来获得积分、提升企业权益等级，凭等级享受模型计费折扣、智谱新产品体验、智谱平台服务等8类平台权益内容。

获得企业权益积分
企业开发者可通过实时计费调用以下模型API，获得智谱企业权益积分（积分通过Tokens用量折算后，将仅取积分整数部分）：

模型 | 消耗Tokens用量 | 获得积分值
---|---|---
GLM-4-0520 | 1万 Tokens | 2
GLM-4-Air | 100万 Tokens | 1
GLM-4-AirX | 10万 Tokens | 1
GLM-4-Flash | 1000万 Tokens | 1
GLM-4-AllTools | 1万 Tokens | 1
GLM-4-Long | 100万 Tokens | 1
GLM-4 | 1万 Tokens | 1
GLM-3-Turbo | 100万 Tokens | 1
Embedding-3 | 200万 Tokens | 1
Embedding-2 | 200万 Tokens | 1
CodeGeeX-4 | 1000万 Tokens | 1
GLM-4V | 1万 Tokens | 1
CogView-3 | 10张 | 1
CogView-3.5 | 50张 | 3
CogVideoX | 2视频 | 1
CharGLM-3 | 20万 Tokens | 3
Emohaa | 20万 Tokens | 3

企业权益等级计算规则
等级与积分范围的对应关系如下：

等级 | 积分范围
---|---
V0 | [ 0 , 10000 )
V1 | [ 10000 , 100000 )
V2 | [ 100000 , 200000 )
V3 | >= 200000

企业权益等级的计算与生效
我们将在每月 1 日 00:00:00 开始统计您在上月累计获得的积分，根据您最近三个月的最高积分确定您在本月的企业权益等级。
您的企业权益等级将在每月 1 日 06:00:00 计算完成、更新并生效（计算过程中您将继续享受上月等级的各项权益）。在本月您将凭借企业权益等级，享有对应的各项权益。
为保障您及时获得更高的企业权益等级，如果您本月已获积分所对应的等级超过了本月已生效的等级，您将立即升级到更高等级、享受更佳企业权益。

企业权益内容
当前各等级企业权益将享受以下服务，我们将陆续推出更多企业权益内容，敬请期待：

**表1：等级、计费折扣权益、平台服务权益**

| 等级 | 计费折扣权益 | 平台服务权益 |
|------|--------------|----------------|
| V0   | 90%          | 1. 智谱在线课程 <br> 2. 官方技术支持 |
| V1   | 80%          | 1. 智谱在线课程 <br> 2. 官方技术支持 <br> 3. 新平台功能体验权 <br> 4. 新模型服务体验权 |
| V2   | 70%          | 1. 智谱在线课程 <br> 2. 官方技术支持 <br> 3. 新平台功能体验权 <br> 4. 新模型服务体验权 <br> 5. 智谱活动特权 <br> 6. 行业活动特权 |
| V3   | 60%          | 1. 智谱在线课程 <br> 2. 官方技术支持 <br> 3. 新平台功能体验权 <br> 4. 新模型服务体验权 <br> 5. 智谱活动特权 <br> 6. 行业活动特权 |

**表2：模型及各等级最高并发保障**

| 模型             | V0    | V1     | V2     | V3     |
|-----------------|-------|--------|--------|--------|
| GLM-4-0520       | 20    | 100    | 300    | 600    |
| GLM-4-Air        | 100   | 1000   | 3000   | 5000   |
| GLM-4-AirX       | 20    | 30     | 50     | 100    |
| GLM-4-Flash      | 100   | 200    | 400    | 1500   |
| GLM-4-AllTools   | 5     | 10     | 15     | 20     |
| GLM-4-Long       | 5     | 10     | 15     | 20     |
| GLM-4            | 20    | 100    | 400    | 800    |
| GLM-3-Turbo      | 100   | 200    | 700    | 1500   |
| Embedding-3      | 20    | 50     | 100    | 200    |
| Embedding-2      | 20    | 100    | 1000   | 2000   |
| CodeGeeX-4       | 100   | 200    | 400    | 1500   |
| GLM-4V           | 20    | 30     | 50     | 100    |
| CogView-3        | 10    | 20     | 30     | 40     |
| CogView-3.5      | 10    | 20     | 30     | 40     |
| CogVideoX        | 1     | 3      | 5      | 10     |
| CharGLM-3        | 20    | 50     | 100    | 200    |
| Emohaa          | 20    | 100    | 400    | 800    |


常见问题
如何查看我的积分企业权益等级？
您可以在 企业权益 查看自己的积分与企业权益等级。

我已完成企业认证，企业权益在什么时候可以生效？
2024年6月前完成企业认证的开发者，将自动根据最近3个月的模型用量获得企业权益积分与等级，享受企业权益服务；
新企业认证的开发者，将在认证完成立即获得 V0 等级。

我已完成企业认证，变更企业认证是否影响我的企业权益等级？
当前完成企业认证信息变更后，您本月获得的企业权益等级将不会变更。

消耗资源包中的 Tokens 会增加积分么？
不会，仅通过消耗现金余额、实时计费调用模型API接口的方式，才能产生积分。当您持有Tokens资源包时，将优先消耗资源包内Tokens，此时不产生积分收益。

使用Batch API 会增加积分么？
不会，仅通过消耗现金余额、实时计费调用模型API接口的方式，才能产生积分。通过 Batch API 您将获得 Batch API 专属计费折扣。
<end>
常见问题
一、注册及登录问题
是否支持海外手机号注册？
我们的平台是支持海外手机号注册的。在注册过程中，请您选择相应的国家区号，并通过短信验证码进行验证，即可完成注册。
注册/登录时收不到短信验证码是什么原因？
为了保障用户账号的安全，我们已设置验证码发送频率的限制。如果在短时间内频繁发送验证码，可能会触发该限制，从而导致验证码发送失败，请您在5分钟后再次尝试接收验证码。如果以上方法仍无法解决问题，请联系人工客服。

二、账号问题
个人账号和企业账号有什么区别吗？
企业账号和个人账号在用户权益上没有区别，但认证方式不同，提交的认证材料也不同。强烈建议企业账号不要使用个人身份进行个人实名认证，以免企业人员变动或交接引发账号登录信息丢失或产生不必要的纠纷。
没有实名认证，可以使用 API 吗？
目前调用 API 并不强制要求实名认证，但为确保您的账户安全，我们建议您进行实名认证。
企业实名账号可以更改为个人账号吗？
企业实名账号不支持更改为个人账号，请谅解。
海外企业是否可以进行企业认证？
平台是支持海外企业进行认证的，您需要在实名认证页面选择海外企业并上传相关的认证材料即可。

三、API 调用问题
如何调用我们的API?
您可以参考我们平台提供的接口文档进行调用。
同步、异步、SSE调用方式有什么区别？
同步、异步、SSE调用是三种不同的 API 响应方式。
SSE调用：客户发起请求后，可以流式的实时获取到模型生成的内容直到推理结束，类似于智谱清言APP上的打字机效果。该调用方式适用于对首响及响应时长要求较高的场景，如和用户直接进行交互的智能客服、对话闲聊等。我们推荐您使用SSE调用，用户体验更好。
同步调用：客户发起请求，模型完成推理后一次性返回全量生成结果。
异步调用：客户发起请求后，需要用户调用异步接口结果查询模型处理状态和推理结果，如处理完成，可通过结果查询接口获取到模型生成结果。该调用方式适用于对响应时间不敏感的业务场景，如批量处理数据、批量生成文章等。
调用模型时的并发限制是多少？
您可以参考速率限制了解当前的并发以及如何提升您的并发数
temperature 和top_p参数该如何设置？
在大语言模型中，temperature 和 top_p 参数用于调节生成文本的多样性和质量。
temperature 参数用于控制模型输出结果的随机性，取值范围是: [0.0,1.0]。值越大，生成的文本越随机，值越小，生成的文本越稳定；
top_p 参数用于控制模型输出结果中单词或词组的概率分布，取值范围是：[0.0,1.0]。值越大，模型会在更多单词或词组中进行选择，增加输出结果的随机性，值越小，模型会在更少的单词或词组中进行选择，增加输出结果的稳定性。
要获得更有创意、更多样性的回答，可将 temperature 设为较高值或 top_p 设为较高值；要获得更稳定、更有确定性的回答，可将 temperature 设为较低值或 top_p 设为较低值。您可根据实际的应用场景调整temperature 或 top_p参数，但不要同时调整这两个参数。
如何使用函数调用能力？
您可参考函数调用使用文档了解调用逻辑
tools列表支持传多个函数吗？
tools支持传多个函数，但每次调用只能命中一个
函数调用，知识库检索，网络搜索可以全部添加到tools参数里吗？
函数调用、知识库检索、网络搜索，3个功能互斥。如果同时使用，按照优先级只会生效一个。优先级顺序为：函数调用>知识库检索>网络搜索。
模型微调怎么做？
目前可通过提交模型微调接口文档开发者 Pro 版平台服务权益申请 获得 chatglm3-6b 模型微调权限，其他模型的微调能力会陆续迭代。开通权限后可通过模型微调接口文档了解调用详情。
您也可以购买我们的云端私有化服务，获得私有化部署及模型微调服务，请随时联系我们，我们的咨询顾问将为您详细介绍。

四、财务常见问题
开放平台如何计费？
我们的计费方式是以 token 为单位（图像大模型按照模型产出的图片数量计费），每个 token 代表一个自然语言文本的基本单位，如“字”或“词”。
我们会根据您的模型输入和输出的总 token 数进行计费（向量大模型embedding-2仅按照输入token量计费）。如果您开启了搜索服务，搜索结果作为输入也会被计费。
我们支持两种扣减方式：费用扣减和资源包扣减。费用扣减是根据 token 使用量×模型单价从您的现金账户中扣除。资源包扣减则是根据 token 使用量从您的资源包账户扣除。在扣除时，我们会优先使用资源包账户，然后再使用充值账户或赠金账户。
体验中心是否计费？
体验中心的计费规则和 API 调用一致，具体的模型调用单价可参考产品定价。
如何查看我的消费明细？
您好，您可以在财务总览页面查看消耗情况，包括今日消费金额以及近6个月的消费统计。您也可以在费用账单页面，查看详细的使用记录，如需下载账单，可在导出记录页面点击下载汇总账单。
如何申请发票？
您好,关于开发票的相关事宜,可进入平台自助完成开具。立即开具
我们目前的开票模式是：
按照实际消耗开票
可开票金额=用户已消耗的现金金额
其中可勾选发票范围：t-1个月及之前的 API推理「账单」& t-1日及之前的产品资源包购买「订单」
可以按充值金额开具发票吗？
目前平台仅支持按照消耗开具，不支持按充值金额开具发票。感谢您的理解与支持。

五、开源大模型商业授权申请
个人用户可以申请模型商用授权吗？
模型商用授权仅开放给企业用户，个人用户无法获得商用授权。若您想将模型用于学术研究或（非商用的）应用开发，无需申请授权，在HuggingFace下载模型使用即可。
已经提交了申请，但还未收到授权书，请问是什么原因？
提交申请后未收到授权书的原因可能是：
申请正在审核
我们将会在2 个工作日内进行审核并通过邮件向您发送授权书，也可在平台后授权管理界面下载授权书；
尚未完成企业认证
请您先完成企业认证，再填写表单进行申请。
如有其它问题，可提交工单进行询问

更多问题
以上内容未解决您的问题？更多平台相关问题，点击这里查看或者加入开放平台社群。

以下是提取的链接信息：
- [实名认证](/usercenter/auth)
- [接口文档](/dev/api)
- [速率限制](/dev/howuse/rate-limits)
- [函数调用使用文档](/dev/howuse/functioncall)
- [模型微调接口文档](/dev/api#fine-tuning)
- [模型微调接口文档](/tokenspropay?productIds=product-001)
- [联系我们](/online-book/modelLocalDeployment?channel_track_key=modelLocalDeployment)
- [产品定价](/pricing)
- [财务总览](/finance/overview)
- [费用账单](/finance/expensebill/list?active=detail)
- [导出记录](/finance/exportrecord)
- [立即开具](/finance/invoice/list)
- [更多平台相关问题](https://zhipu-ai.feishu.cn/wiki/VdWrwLQLSicQxekqlvJcVhPQnze)
<end>
大模型开放平台用户协议
最新版本生效日期：2024年6月3日
欢迎您与大模型开放平台签署本《用户协议》（下称"本协议"）并使用大模型开放平台（定义见下文）服务。

重要提示
【审慎阅读】您在申请注册流程中点击同意本协议之前，应当认真阅读本协议。请您务必审慎阅读、充分理解各条款内容，特别是免除或者限制责任的条款、法律适用和争议解决条款，特别是粗体下划线标识之处，您应重点阅读。如您对协议有任何疑问，可向大模型开放平台客服咨询。除本协议外，您还应充分知悉并遵循开放平台上的用户协议、使用规范、安全审核说明、接口文档、使用指南、通知等要求使用产品或服务（详见 https://open.bigmodel.cn/dev/howuse/ProtocolStatement，  https://open.bigmodel.cn/dev/howuse/securityaudit 等链接）

【签约动作】当您按照注册页面提示填写信息、阅读并同意本协议且完成全部注册程序后，即表示您已充分阅读、理解并接受本协议的全部内容，并与大模型开放平台达成一致，成为大模型开放平台用户（下称"用户"或"您"）。阅读本协议的过程中，如果您不同意本协议或其中任何条款约定，您应立即停止注册程序。如您与智谱已就您使用智谱大模型开放平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。

一、定义
智谱：北京智谱华章科技有限公司
大模型开放平台：指智谱经营的通过互联网提供的自然语言处理、开放平台服务、API调用等服务，以及智谱不时开发的新型服务类型的平台。
大模型开放平台服务提供者：指大模型开放平台的互联网信息及软件技术服务提供者智谱。
大模型开放平台规则：大模型开放平台已经发布及后续发布的全部规则、解读、公告等内容。
关联公司：指智谱在中国境内设立的一家或多家公司，包括其直接或间接控股的公司，参股或形成经营、协作的具有关联关系的企业。

二、账户注册与使用
在您使用大模型开放平台的服务时，需要您先进行用户注册或者实名认证。

1. 用户资格
您确认，在您开始注册程序使用大模型开放平台服务前，您应当具备中华人民共和国法律规定的与您行为相适应的民事行为能力。若您不具备前述与您行为相适应的民事行为能力而进行用户注册，则您及您的监护人应依照法律规定承担因此而导致的一切后果。
您知悉，无民事行为能力人、限制民事行为能力人不当注册为大模型开放平台用户的，其与大模型开放平台之间的服务协议自始无效，一经发现，大模型开放平台有权立即停止为该用户服务或注销该用户账号。

2. 账户注册
账户注册是指用户利用享有权利的移动电话号码在大模型开放平台注册账号，按要求填写相关信息并确认同意履行本协议的过程。如有证据证明或大模型开放平台根据相关规则判断您存在不当注册或不当使用多个大模型开放平台账户的情形，大模型开放平台可采取冻结或关闭账户、拒绝提供服务等措施，如给大模型开放平台及相关方造成损失的，您还应承担赔偿责任。
我们将用户分为个人用户与企业用户两类，请您根据您使用服务时所代表的身份及实际使用情况注册为恰当的用户类型。

3. 账户安全
您有权使用您设置或确认的手机号码及您设置的密码登录大模型开放平台。您的账户为您自行设置并由您保管，大模型开放平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，大模型开放平台并不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。
由于您的大模型开放平台账户关联您的个人信息，您的大模型开放平台账户仅限您本人使用。未经大模型开放平台同意，您直接或间接授权第三方使用您大模型开放平台账户或获取您账户项下信息的行为无效。如大模型开放平台根据平台规则中约定的违约认定程序及标准判断您的账户使用可能危及您的账户安全及/或大模型开放平台信息安全的，大模型开放平台可拒绝提供相应服务或终止本协议。

4. 更新维护
您应当及时更新您提供的信息，在法律有明确规定要求大模型开放平台作为平台服务提供者必须对部分用户的信息进行核实的情况下，大模型开放平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。
如大模型开放平台按您最后一次提供的信息与您联系未果、您未按大模型开放平台的要求及时提供信息、您提供的信息存在明显不实或行政司法机关核实您提供的信息无效的，您将承担因此对您自身、他人及大模型开放平台造成的全部损失与不利后果。大模型开放平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部大模型开放平台服务，大模型开放平台对此不承担任何责任。

三、您的权利和义务
1. 您有权根据本协议的约定享受大模型开放平台提供的以下服务：通过互联网提供的自然语言处理、开放平台服务、API调用等服务，以及智谱不时开发的新型服务类型。大模型开放平台有权依据业务需要增加或减少服务的内容。
2. 您应当保证在使用大模型开放平台时不采取不正当行为，不扰乱平台正常秩序。
3. 您不得向大模型开放平台输出或诱导大模型开放平台向您输出包含以下内容的言论，否则大模型开放平台可对您发布的信息依法或依本协议进行删除或屏蔽，并将您发布信息的情况和向有关机关报告：
反对宪法所确定的基本原则的；
危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的；
损害国家荣誉和利益的；
煽动地域歧视、地域仇恨的；
煽动民族仇恨、民族歧视，破坏民族团结的；
破坏国家宗教政策，宣扬邪教和封建迷信的；
散布谣言，扰乱社会秩序，破坏社会稳定的；
散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的；
侮辱或者诽谤他人，侵害他人合法权益的；
煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的；
以非法民间组织名义活动的；
有可能涉及版权纠纷的非本人作品的；
有可能侵犯他人在先权利的；
对他人进行暴力恐吓、威胁，实施人肉搜索的；
涉及他人隐私、个人信息或资料的；
侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的；
侵害未成年人合法权益或者损害未成年人身心健康的；
未获他人允许，偷拍、偷录他人，侵害他人合法权利的；
违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的“七条底线”要求的；
相关法律、行政法规等禁止的。
您在发表言论和图片时，除遵守本条款外，还应遵守国家相关法律法规。
4. 您不应以以下方式不当使用大模型开放平台：
以任何方式试图从大模型开放平台中提取数据、参数或代码；
将大模型开放平台使用于任何对主体资格有要求的服务中，包括但不限于医疗服务、法律服务等；
利用大模型开放平台用于任何决策行为；
删除大模型开放平台及平台内模型上关于著作权的信息；
对大模型开放平台进行反向工程、反向汇编、反向编译，或者以其他方式尝试发现大模型开放平台的源代码；
对智谱拥有知识产权的内容进行使用、出租、出借、复制、修改、链接、转载、汇编、发表、出版、建立镜像站点等；
对大模型开放平台或者大模型开放平台运行过程中释放到任何终端内存中的数据、软件运行过程中客户端与服务器端的交互数据，以及大模型开放平台运行所必需的系统数据，进行复制、修改、增加、删除、挂接运行或创作任何衍生作品，形式包括但不限于使用插件、外挂或非经智谱授权的第三方工具/服务接入大模型开放平台和相关系统；
通过修改或伪造软件运行中的指令、数据，增加、删减、变动软件的功能或运行效果，或者将用于上述用途的软件、方法进行运营或向公众传播，无论这些行为是否为商业目的；
通过非智谱开发、授权的第三方软件、插件、外挂、系统，登录或使用智谱软件及服务，或制作、发布、传播上述工具；
自行或者授权他人、第三方软件对大模型开放平台及其组件、模块、数据进行干扰；
您除将平台内模型与您具体的业务场景结合后使用外，不得将平台内模型、提示词和通过平台内模型提示生成的内容用于平台内模型之外的新模型或其他模型的开发、训练、标注、微调、优化、迭代以及其他类似活动，不得利用平台内模型开发、训练或改善其他与智谱存在竞争关系的算法、模型；
利用大模型开放平台及平台内模型生成恶意代码；
其他未经智谱明示授权的行为。
其他可能损害智谱利益的使用方式。
5. 您利用大模型开放平台及其中模型向任何第三方提供服务，相应的权利义务和责任均由您承担，大模型开放平台不对由此造成的任何损失负责。
6. 您在海外使用大模型开放平台应遵守美国、欧盟和/或其他政府机关等外国实体的全部法律、法规、政策的限制与监督。您不得将大模型开放平台或使用大模型开放平台开发的任何产品转售、出口或转移至受监管控制的特定国家和特定人士。未事先获得相关政府机关的必要批准及智谱事先同意，您不得直接或间接出口大模型开放平台、包含有大模型开放平台的任何技术、如何大模型开放平台内部的技术。
7. 您对大模型开放平台提供的任何服务的利用均应符合《生成式人工智能服务管理暂行办法》《互联网信息服务算法推荐管理规定》《互联网信息服务深度合成管理规定》以及适用的其他法律法规。您调用大模型开放平台内模型API开发的产品和应用，由您负责自行进行互联网信息服务算法备案、具有舆论属性或社会动员能力的互联网信息服务安全评估、上线备案等合规程序，以及其他基于法律法规及政策所要求的审批、备案、评估及流程，按照相关规定和主管机关要求真实、准确地公示使用智谱模型及其他模型（如有）的情况，请勿对未使用智谱模型的产品和服务进行虚假的、混淆事实的公示、标识及展示。您违反前述法律法规和约定造成的后果由您自行承担，由于您的行为给智谱造成损失的，您应赔偿由此造成的损失。
8. 收费服务
产品的某些服务是以收费方式提供的，如您使用收费服务，请遵守服务相关的协议，若您不同意相关协议及其修改和变更，请暂停使用相关服务并联系我们。
若您为未满18周岁的未成年人，您将不能使用付费服务。
智谱有权决定收费类服务的收费标准，具体的收费标准以相关收费服务页面公布的标准为准，您可以根据需要自行选择并付费使用相应服务。
您理解并同意，若您已经根据大模型开放平台中特定产品公布的费用标准完成了付款，您已与智谱就您订购该产品订立了合同。除因您购买的相应收费类服务有特别约定或单独归因于智谱的过错导致您无法正常使用该服务外，我们不会退还您为使用该服务而支付的款项。
若您在购买服务时有任何问题，您可以通过各服务页面提供的客服联系方式进行咨询，或通过本协议明确的联系方式联系我们。
9. 未经智谱事先书面同意，您不得在任何时候、以任何方式、通过任何途径（无论是直接还是间接，也无论是明示还是暗示，包括但不限于任何营销、广告、促销、市场推广或其他目的）：（1）使用、引用、公布、复制、展示（公开或非公开）、提及、注册或申请注册：(i)智谱或其关联方拥有或有权使用的任何商标（无论是否已注册）、商号、名称、标志或者标识（包括但不限于：“智谱”、“智谱AI”、“Zhipu”、“Zhipu.AI”、“ChatGLM”、“CodeGeeX”、“CogView”，或与清华大学有关的任何文字及标志等），或通过特定描述使第三方能够识别智谱或其任何关联方；(ii) 智谱或其关联方任何董事、监事、管理人员、雇员或合伙人、科学家团队的姓名、肖像、形象、照片、图片、标识、发言或评论（或其一部分）；或(iii)与前述各项相似的、以任何语言形式存在的任何名称、商标、标识、文字、词语、符号或其任何组合；以及（2）直接或间接声明您或您的任何关联方所提供的任何产品或服务已由智谱或其任何关联方认可或支持。特别地，未经智谱事先书面确认和承诺，您不得将智谱相关的宣传/广告/影响策略及内容向任何第三方进行宣传或披露、亦不得利用智谱或其相关方品牌直接或间接谋求及/或招揽任何投资及/或合作机会。如您违反前述约定的，智谱有权要求您立即删除相关内容并负责消除影响、赔偿智谱的所有损失。
10. 如您在使用大模型开放平台及平台内模型的过程中加入新的数据进行模型训练、微调和开发，由此产生的责任由您自行承担。您进行训练、微调和开发后，受有损害并主张智谱承担责任的，应证明损害与其训练、微调和开发无关，否则智谱对损害免责。
11. 大模型开放平台及平台内模型均不要求您或最终用户输入个人信息、秘密信息和其他值得保护的智力成果。您应当注意，并应提醒您的最终用户注意，为确保您和最终用户个人信息、秘密信息和其他值得保护的智力成果的安全，除非您或最终用户使用智谱产品或服务所必需且您和最终用户已充分知悉相应风险，您和最终用户应避免向大模型开放平台及平台内模型输入个人信息、秘密信息和其他值得保护的智力成果。
12. 您接入智谱产品或服务向公众提供内容生成式人工智能产品或服务的，应根据适用法律法规开展安全评估、算法备案、上线备案或法律规定的其他要求、审批，按照相关规定和主管机关要求真实、准确地公示使用智谱模型及其他模型（如有）的情况，请勿对未使用智谱模型的产品和服务进行虚假的、混淆事实的公示、标识及展示。您应对您的应用生成内容的安全性、合法性、合规性进行有效管理和控制，建立包括但不限于内容审核、用户管理、数据安全、监测预警和应急处置等机制。鉴于API返回的信息不一定毫无瑕疵，您应对您发现的或智谱提示您的违法和不良信息及时依法采取删除、屏蔽、撤回等处置措施，确保您的应用合法合规运营。
13. 您在使用智谱的产品和服务时须遵守相关法律法规，履行法律法规规定的安全义务，不违反《中华人民共和国刑法》《中华人民共和国反不正当竞争法》《中华人民共和国网络安全法》《中华人民共和国数据安全法》《中华人民共和国个人信息保护法》《互联网信息服务算法推荐管理规定》《互联网信息服务深度合成管理规定》《生成式人工智能服务管理暂行办法》《具有舆论属性或社会动员能力的互联网信息服务安全评估规定》《互联网新闻信息服务新技术新应用安全评估管理规定》《网络信息内容生态治理规定》等相关法律法规及政策，维护互联网秩序和网络安全，请勿利用产品发布危害国家安全的、破坏民族团结的、扰乱社会秩序的、有歧视性的、不正当的言论，或侵害任何第三方的个人信息保护权、名誉权、人格权、知识产权、财产权、肖像权等其他任何权益，或从事涉及黄赌毒、违反法律法规或公序良俗的行为。
14. 如您利用智谱产品创建虚拟人物，需保证虚拟人物的形象、头像、名称、人物设定及创建过程中的数据和内容均不侵犯第三方知识产权、肖像权、名誉权、隐私权、个人信息保护权等合法权益，不会利用虚拟人物从事任何可能构成不正当竞争的行为。
<end>
大模型开放平台用户协议
四、大模型开放平台的权利和义务
1. 大模型开放平台有义务在现有技术上维护整个平台的正常运行，并努力提升和改进技术，保障您的产品和服务使用体验。
2. 对于您在注册使用大模型开放平台时遇到的与本产品或服务有关的问题及反映的情况，大模型开放平台将在法律规定期限内及时作出回复。
3. 对于您在大模型开放平台上的不当行为，或任何大模型开放平台认为应当终止服务的情况，大模型开放平台有权实施屏蔽相关信息、终止提供服务等处理措施，并将相关情况及时通知于您和告知有关部门；您对大模型开放平台的处理措施存在异议的，可以提供相关证据予以说明。若经核实，您的行为确有违反大模型开放平台用户协议或违法违规情况的，大模型开放平台有权终止对您提供服务。
4. 大模型开放平台将尽最大努力、采取必要合理措施，保障大模型开放平台网络安全和稳定运行。
5. 如大模型开放平台为您提供免费服务的，您理解并同意，该种免费使用可能根据研究进展进行调整。您承诺不会因该规则的调整、免费使用权益的失效而向大模型开放平台追究任何责任。
6. 您不得以任何方式删除、篡改、隐匿大模型开放平台在输出内容中生成的深度合成服务标识。
7. 您同意智谱可以在提供服务的过程中自行或由第三方广告商向您发送广告、推广或宣传信息（包括商业与非商业信息），其方式和范围可不经向您特别通知而变更。您有权拒绝该种商业信息。
8. 智谱会依照法律的规定履行广告相关义务，您也应当自行审慎判断广告以及广告所包含的商品或服务信息的真实性、合法性、可靠性并为自己的判断行为负责，除法律明确规定外，您因依该广告信息进行的交易或前述广告所涉及的商品或服务而遭受的损失或损害，智谱不承担责任。

五、服务协议的终止
1. 您有权通过以下任一方式终止本协议：
您注销您的账户的；
变更事项生效前您停止使用并明示不愿接受变更事项的；
您明示不愿继续使用大模型开放平台服务，且符合平台终止条件的。
由您向大模型开放平台提出注销账号申请后，经大模型开放平台审核同意，由大模型开放平台注销该注册用户，您即解除与大模型开放平台的服务协议关系。
2. 在下列情况下，大模型开放平台可以通过注销用户的方式终止服务：
在您违反本服务协议相关规定时，大模型开放平台依据违约条款终止本协议。大模型开放平台将在终止服务时通知您。但如您在大模型开放平台终止提供服务后，再一次直接或间接以他人名义注册为大模型开放平台用户的，大模型开放平台有权再次单方面终止向您提供服务；
如大模型开放平台通过您提供的信息与您联系时，发现您在注册时填写的电子邮箱或手机等已不存在或无法接收信息的，经大模型开放平台以您在注册时填写的其他联系方式通知您更改，而您在三个工作日内仍未能提供，或大模型开放平台无法根据您注册时预留的信息联系到您的；
经大模型开放平台发现您注册信息中主要内容是虚假的；
本服务协议终止或更新时，您明示不愿接受新的服务协议的；
您在大模型开放平台有发布违法信息、侵犯他人合法权益或其他严重违法违约行为的；
除上述情形外，因您多次违反大模型开放平台规则相关规定且情节严重，大模型开放平台依据平台规则对您的账户予以查封的；
其它大模型开放平台认为需终止服务的情况。
3. 协议终止后的处理
本协议终止后，除法律有明确规定外，大模型开放平台无义务向您或您指定的第三方披露您账户中的任何信息。
本协议终止后，大模型开放平台仍享有下列权利：
在匿名化处理您的用户信息的前提下，继续保存您留存于大模型开放平台的各类信息；
对于您过往的违约行为，大模型开放平台仍可依据本协议向您追究违约责任。

六、通知
1. 您在注册成为大模型开放平台用户，并接受大模型开放平台服务时，您应该向大模型开放平台提供真实有效的联系方式，对于联系方式发生变更的，您有义务及时更新有关信息，并保持可被联系的状态。
您在注册大模型开放平台用户时生成的账户用于登录大模型开放平台，也作为您的有效联系方式。
大模型开放平台将向您的上述联系方式送达各类通知，而此类通知的内容可能对您的权利义务产生重大的有利或不利影响，请您务必及时关注。
2. 大模型开放平台通过上述联系方式向您发出通知，其中以电子的方式发出的书面通知，包括但不限于在大模型开放平台公告，发送站内信，向您提供的联系电话发送手机短信，向您的电子邮箱发送电子邮件，在发送成功后即视为送达。
3. 对于在大模型开放平台上引起的任何纠纷，您同意司法机关（包括但不限于人民法院）通过手机短信等现代通讯方式或邮寄方式向您送达法律文书（包括但不限于诉讼文书）。您指定接收法律文书的手机号码等联系方式为您在大模型开放平台注册、更新时提供的联系方式，司法机关向上述联系方式发出法律文书即视为送达。您指定的邮寄地址为您的法定联系地址或您提供的有效联系地址。
您同意司法机关可采取以上一种或多种送达方式向您送达法律文书，司法机关采取多种方式向您送达法律文书，送达时间以上述送达方式中最先送达的为准。
您同意上述送达方式适用于各个司法程序阶段。如进入诉讼程序的，包括但不限于一审、二审、再审、执行以及督促程序等。
您应当保证所提供的联系方式是准确、有效的，并进行实时更新。如果因提供的联系方式不确切，或不及时告知变更后的联系方式，使法律文书无法送达或未及时送达，由您自行承担由此可能产生的法律后果。
4. 您可以通过邮箱：service@zhipuai.cn 与我们联系。但请注意，我们仅接受您通过邮箱发送任何有法律效力的通知，不接受您通过电话或其他方式送达我们该等通知。

七、知识产权
1. 大模型开放平台上的图表、标识、网页页眉、按钮图标、文字、服务品名等标示在网站上的信息都是智谱或其关联公司的财产，受中国和国际知识产权相关法律的保护。未经智谱许可，您不得以任何可能引起用户混淆的方式或任何贬低或诽谤智谱或其关联公司的方式用于与非智谱的任何产品或服务上。在大模型开放平台上出现的不属于上述主体的所有其他商标是其商标权利人各自的财产，这些权利人可能是也可能不是与智谱相关联、相联系或由智谱的关联公司赞助的。未经智谱或相关商标所有人的书面许可，大模型开放平台上的任何内容都不应被解释为以默许或其他方式授予许可或使用网站上出现的商标的权利。
2. 您充分理解并同意，对于大模型开放平台及平台内模型的非付费功能，您仅可以非商业的、个人研究学习的方式使用。对于大模型开放平台及平台内模型的付费功能，您可以在按照大模型平台明确的规则支付对价或以其他方式取得智谱的授权后按照授权进行商业使用；除非智谱与您另行达成其他协议，智谱授予您非排他的、不可转让、不可分许可、不可转许可、有期限限制的普通使用许可权。大模型开放平台及其程序、软件、信息、数据、开发文档及相关的元素、组件等内容均受中华人民共和国法律法规和相应的国际条约保护，由智谱及相关权利人享有知识产权。
3. 未经智谱及相关权利人书面同意：
您无权复制、转让、出售、出租、出借、许可、提供他人使用或以任何智谱明示同意之外的商业化方式使用大模型开放平台、平台内模型；
为免疑义，您可以在按照大模型开放平台届时有效的规则支付费用后，按相应产品的规则商业化使用平台内模型及其生成的内容。
您不得创建任何与大模型开放平台功能及平台内模型基本相同的软件并将其提供给第三方；
您不得利用大模型开放平台及平台内模型开发与大模型开放平台及平台内模型相竞争的产品或服务。
您不得删除或修改大模型开放平台及平台内模型所做的任何版权声明，并应告知您的客户、最终用户等不得进行该种删除或修改。
4. 您输入大模型开放平台的任何内容的版权均仅归原作者所有，若作者有版权声明或原作从其他网站转载而附带有原版权声明者，其版权归属以附带声明为准。
5. 由于现有生成式人工智能技术共同面临的技术困境，平台内模型可能生成与他人享有权利的已有作品或其他用户生成的内容相同或相似的内容。您基于平台内模型生成的内容的版权由您自行维护并对其独立判断后使用，基于大模型开放平台内模型生成内容的创作、使用产生的任何知识产权问题由您自行处理，智谱对由此造成的任何损失不负责任，您由此给智谱造成损失的智谱有权向您追偿。您不得以任何方式删除、掩藏、修改或替换大模型开放平台及呈现内容中所附的或包含的任何专有权利声明、其他任何链接等。
6. 如果您认为您的知识产权受到侵犯，请将侵权通知和相应证据发送至以下电子邮箱：service@zhipuai.cn。我们将在确定您陈述的真实性后删除或禁用相关内容，并可能终止重复侵权者的账户。
7. 除本协议明确许可的内容外，智谱不提供有关产品的源代码。未经智谱书面许可，您对智谱提供的产品不得进行任何参数、代码等的修改。由于您对智谱提供的产品进行任何参数、代码等的改动而导致产品不能正常运行或产品效果降低的，智谱对此不承担责任。

八、责任限制
1. 您承诺，您将尽一切努力不使智谱及其关联公司、雇员受到任何与您使用大模型开放平台及平台内模型的行为相关的诉讼、仲裁、赔偿、损失。出现此种情形的，您将代为承担相关责任。
2. 大模型开放平台依照法律规定履行基础保障义务，但对于下述原因导致的合同履行障碍、履行瑕疵、履行延后或履行内容变更等情形，大模型开放平台并不承担相应的违约责任：
因自然灾害、罢工、暴乱、战争、政府行为、司法行政命令等不可抗力因素；
因电力供应故障、通讯网络故障等公共服务因素或第三人因素；
在大模型开放平台已尽善意管理的情况下，因常规或紧急的设备与系统维护、设备与系统故障、网络信息与数据安全等因素。
3. 您理解，尽管智谱已经尽了最大努力，但是由于大模型开放平台及平台内模型提供服务所依赖的技术本身存在的技术瓶颈，大模型开放平台仍然不能对以下事项作出任何保证：
不保证大模型开放平台及平台内模型将符合您的实际或特定需求或目的，经大模型开放平台获得的任何产品、服务或其他内容符合您的期望；
不保证大模型开放平台及平台内模型百分百准确可靠、功能可用、及时、安全、无错误、不受干扰、无中断、持续稳定、不存在任何故障；
大模型开放平台及平台内模型并不真正像人类一样理解用户输入的内容，大模型开放平台及平台内模型也不理解背后隐含的潜在风险和伦理问题，大模型开放平台及平台内模型的输出不构成对您的任何建议或决策，不保证其生成内容的真实性、完整性、准确性、及时性及实用性，您需根据自己的实际情况做出独立判断，智谱不承担由此带来的任何直接或间接的损失，以及您对大模型开放平台及平台内模型的依赖而产生的风险；
大模型开放平台及平台内模型的输出虽已经过人工智能算法自动过滤，但仍不排除其中部分信息具有瑕疵、不合理或引发用户不适，且其生成的内容不代表智谱的态度或观点;
不保证大模型开放平台及平台内模型中的代码、程序及其指向的内容的准确性、稳定性和完整性。
4. 除非另有明确的书面说明，大模型开放平台及其所包含的或以其他方式通过大模型开放平台提供给您的全部信息、内容、材料、商品（包括软件）和服务，由智谱依照“现状”和“现有”基础予以提供。
5. 除非另有明确的书面说明，在中华人民共和国法律允许的最大范围内，智谱不对大模型开放平台及平台内模型所包含的信息、内容、材料、产品、软件或服务作任何形式的声明或担保。智谱及其关联公司不担保大模型开放平台及其所包含的或以其他方式提供给您的全部信息、内容、材料、产品、软件和服务、其服务器或从大模型开放平台发出的电子信件没有病毒或其他有害成分。
6. 除非另有明确的书面说明或法律规定应当承担责任的，智谱不对由于使用大模型开放平台或其所包含的或以其他方式通过客户端提供给您的全部信息、内容、材料、产品、软件和服务引起的任何损害承担责任，包括但不限于直接的、间接的、特殊的、附带的、后果性的或惩罚性的任何性质的损害。
7. 您理解并同意智谱将会尽其商业上的合理努力保障您在大模型开放平台及服务中的数据安全，但是，智谱并不能就此提供完全保证，包括但不限于以下情形：
智谱不对您在大模型开放平台及服务中相关数据的删除或储存负责。
如果您停止使用大模型开放平台及服务或服务被终止或取消，智谱没有义务向您返还任何数据。

九、第三方产品及服务
1. 您理解并同意：因大模型开放平台调用第三方系统或者通过第三方支持您的使用或访问时，大模型开放平台仅向第三方的产品或服务提供链接跳转服务，使用或访问的结果由该第三方提供，鉴于本协议不适用于任何其他第三方向您提供的产品和服务，若需开通和使用该产品或服务，您还应遵守第三方的用户协议、隐私政策等公示文件。
2. 通过大模型开放平台您所接触到的由第三方提供的产品及服务，由第三方自主独立运营并独立承担全部责任，大模型开放平台不会参与第三方服务的运营等任何活动。您因使用第三方产品及服务而产生的任何纠纷、责任等，您应与第三方协商解决或通过其他合法途径解决，相关责任、损失等由您或第三方独立承担。

十、用户信息保护及授权
1. 大模型开放平台非常重视用户个人信息的保护，在您使用大模型开放平台提供的服务时，您同意大模型开放平台按照在大模型开放平台上公布的隐私权政策收集、存储、使用、披露和保护您的个人信息，具体请见《大模型开放平台隐私政策》。
2. 为了改善我们向您提供的产品和服务的质量，我们可能利用您使用大模型平台或平台内模型过程中产生的数据，定位、维护和优化我们的产品和服务，但是您与智谱另有约定的除外。
3. 对于您提供、发布及在使用大模型开放平台服务中形成的除个人信息外的文字、图片、视频、音频等非个人信息，均不会因上传、发布等行为发生知识产权、肖像权等权利的转移。除非我们另行说明，在法律允许的范围内，您免费授予智谱及其关联公司非排他的、无地域限制的、永久的、免费的许可使用（包括存储、使用、复制、修订、编辑、发布、展示、翻译、分发上述信息或制作派生作品，以已知或日后开发的形式、媒体或技术将上述信息纳入其他作品内等）及可再许可第三方使用的权利，以及可以自身名义对第三方侵权行为取证及提起诉讼的权利。

十一、未成年人使用条款
我们的产品、平台和服务主要面向对智谱产品、业务感兴趣的成年人，平台暂不对未成年人提供付费服务。如您是未成年人，您仅可在监护人同意后，出于学习研究目的使用大模型平台不需付费的功能，您将不能充值及使用需要付费的服务。

十二、违约责任
1. 您存在下列行为的，视为违约，大模型开放平台有权做出相应处理：
大模型开放平台有权对您的注册数据及产品/服务使用行为进行查阅，发现或怀疑注册数据或产品/服务使用行为中存在问题，有权向您发出询问和/或要求改正的通知，若您未在合理期限内作出合理回应，大模型开放平台可以对您的注册数据或产品/服务使用做出屏蔽、删除等处理；
经国家生效法律文书或行政处罚决定确认您存在违法行为，或者大模型开放平台有足够事实依据可以认定您存在违法或违反服务协议行为的，大模型开放平台有权暂停或终止向您提供服务；
对于您在大模型开放平台发布的下列各类信息，大模型开放平台有权在不通知您的前提下进行删除或采取其他限制性措施：大模型开放平台有理由相信存在欺诈等恶意或虚假内容的信息；大模型开放平台有理由相信存在试图扰乱正常平台秩序因素的信息；大模型开放平台有理由相信违反公共利益或可能严重损害大模型开放平台和其他用户合法利益的信息。

十三、法律适用与争议解决
1. 本协议之订立、生效、解释、修订、补充、终止、执行与争议解决均适用中华人民共和国大陆地区法律；如法律无相关规定的，参照商业惯例及/或行业惯例。
2. 您因使用大模型开放平台服务所产生及与大模型开放平台服务有关的争议，由大模型开放平台与您协商解决。您可通过邮箱：service@zhipuai.cn 与我们联系。协商不成时，任何一方均可向智谱所在地有管辖权的人民法院提起诉讼。
3. 本协议任一条款被视为废止、无效或不可执行，该条应视为可分的且并不影响本协议其余条款的有效性及可执行性。

<end>
大模型开放平台隐私政策
简介&提示
更新日期：2024年6月5日
欢迎您使用我们的产品和服务！我们深知个人信息对您的重要性，您的信任对我们非常重要，我们将根据法律法规要求并参照行业最佳实践为您的个人信息安全提供充分保障。为此，大模型开放平台服务提供者北京智谱华章科技有限公司（“智谱”或称“我们”）制定本《大模型开放平台 隐私政策》（下称“本政策”）以便您充分了解在您使用大模型开放平台的产品和服务的过程中，我们会如何收集、使用、共享、存储和保护您的个人信息以及您可以如何管理您的个人信息。如您与智谱就您使用智谱大模型开放平台服务的个人信息保护事宜另有约定，则本政策与该等约定冲突的部分对您不适用。

在您开始使用我们的产品和服务前，请您务必先仔细阅读和理解本政策，特别应重点阅读我们以粗体/粗体下划线标识的条款，确保您充分理解和同意后再开始使用。本政策中涉及的专业词汇，我们尽量以简明通俗的表述向您解释，以便于您理解。

本政策主要向您说明：
我们如何收集和使用您的个人信息
大模型开放平台为您提供问答对话生成服务，为了向您提供服务，我们主要会基于如下功能处理您的个人信息：
账号注册：您在注册为大模型开放平台的用户时，需要绑定您的手机号码、填写您的姓名。
实名认证：您为了更全面地使用大模型开放平台，可能需要进行实名认证，如您认证为个人账号，大模型开放平台将收集您的身份证信息。如您认证为企业账号，大模型开放平台将收集您所在公司的名称及公司的其他信息。
留言咨询：如您就本平台服务有任何的问题，您需要在本平台中填写并向智谱提供以下信息：您的姓名、联系电话、公司名称、公司所在地、您需要咨询的事宜。
合作业务咨询：如您希望能够与智谱进行合作，您需要在本平台中填写并向智谱提供以下信息：您的姓名、联系邮箱、联系电话、您的职务、公司名称、您想咨询的问题。
试用平台内模型：您在试用平台内模型时，可能自愿输入您的个人信息，供平台内模型为您生成内容。
客服及争议处理：我们将使用您的个人信息用于为您提供客户服务和争议处理。

您如何管理自己的信息
您可以通过多种方式管理您的个人信息，例如查询、复制、更新、补充您的个人信息。如果您在管理您的个人信息时遇到问题，您还可以通过下方联系方式与我们联系，我们将在15个工作日内回复您的要求。但也请您理解，我们可能会因为履行法律法规义务或者我们提供服务必要性的原因无法完全满足您的请求。

未成年人个人信息保护
我们的产品、平台和服务主要面向对智谱产品、业务感兴趣的成年人，平台不试图收集任何未成年人个人信息。如果您是未成年人，我们建议您和您的父母或其他监护人一起阅读本政策，并在取得您父母或其他监护人的同意后，在您父母或其他监护人的指导下使用我们的服务，以确保您在使用我们的服务和进行交易时的安全。如果监护人发现我们在未获监护人同意的情况下收集了未成年人的个人信息，请联系我们，我们会设法尽快删除相关数据。

本政策适用范围
请您特别注意：本政策适用于大模型开放平台服务提供者以网站、客户端、小程序以及随技术发展出现的新形态向您提供的各项产品和服务。如我们的产品或服务中使用了大模型开放平台的产品或服务（如使用大模型开放平台账号登录），但未设独立隐私权政策的，则本政策同样适用于该部分产品或服务。我们就向您提供的产品或服务单独设有隐私权政策的，则相应产品或服务适用相应隐私权政策。

除本政策说明的相关信息收集使用活动外，本政策不适用于其他第三方向您提供的其他服务，其他服务适用其向您另行说明的个人信息收集使用规则。

联系我们
如您对本政策有任何疑问、意见或建议，或者您在管理您的个人信息时遇到任何问题，您可以通过我们提供的多种反馈渠道与我们联系：
1、您的个人信息相关咨询、投诉问题，可通过大模型开放平台主界面的“企微客服”与我们取得联系。
2、如您对本政策内容有任何疑问、意见、建议以及个人信息泄露投诉举报，可与我们的个人信息保护负责人联系，联系邮箱：service@zhipuai.cn，办公地址：北京市海淀区中关村东路1号院9号楼10层。

引言
欢迎您使用我们的产品和服务！我们深知个人信息对您的重要性，您的信赖对我们非常重要，我们将严格遵守法律法规要求采取相应的安全保护措施，致力于保护您的个人信息安全。基于此，大模型开放平台服务提供者（或称“我们”“智谱”）制定本《大模型开放平台隐私政策》（下称“本政策”），帮助您充分了解在您使用我们产品和服务的过程中，我们会如何处理和保护您的个人信息以及您可以如何管理您的个人信息，以便您更好地做出适当的选择。

在您开始使用我们的产品和服务前，请您务必先仔细阅读和理解本政策，特别应重点阅读我们以粗体/粗体下划线标识的条款，确保您充分理解和同意之后再开始使用。本政策中涉及的专业词汇，我们尽量以简明通俗的表述向您解释，以便于您理解。如对本政策内容有任何疑问、意见或建议，您可通过大模型开放平台提供的各种联系方式与我们联系。

本政策将帮助您了解以下内容：
一、定义及适用范围
二、我们如何收集、使用您的信息
三、我们如何共享、转让、公开披露您的信息
四、我们如何保护您的信息
五、我们如何存储您的信息
六、您如何管理您的信息
七、我们如何处理未成年人的信息
八、本政策如何更新
九、您如何联系我们

一、定义及适用范围
（一）定义
大模型开放平台：指智谱经营的通过互联网提供的自然语言处理、开放平台服务、API调用等服务，以及智谱不时开发的新型服务类型的平台。
大模型开放平台服务提供者：指大模型开放平台的互联网信息及软件技术服务提供者智谱。
个人信息：个人信息是以电子或者其他方式记录的与已识别或者可识别的自然人有关的各种信息，不包括匿名化处理后的信息。
敏感个人信息：敏感个人信息是一旦泄露或者非法使用，容易导致自然人的人格尊严受到侵害或者人身、财产安全受到危害的个人信息，包括生物识别、宗教信仰、特定身份、医疗健康、金融账户、行踪轨迹等信息，以及不满十四周岁未成年人的个人信息。（我们将在本政策中对具体敏感个人信息以粗体进行显著标识）。
个人信息删除：指在实现日常业务功能所涉及的系统中去除个人信息的行为，使其保持不可被检索、访问的状态。
儿童：指不满十四周岁的未成年人。
除另有约定外，本政策所用定义与《用户服务协议》中的定义具有相同的含义。

（二）适用范围
本政策适用于智谱旗下的大模型开放平台及随其技术发展出现的新形态向您提供的各项产品和服务。如我们的产品或服务中使用了大模型开放平台的产品或服务，但未设独立隐私权政策的，则本政策同样适用于该部分产品或服务。我们就向您提供的产品或服务单独设立有隐私权政策的，则相应产品或服务适用相应隐私权政策。

除本政策说明的相关信息收集使用活动外，本政策不适用于其他第三方向您提供的其他服务，其他服务适用其向您另行说明的隐私政策等个人信息收集使用规则。

二、我们如何收集、使用您的信息以及您可以如何管理您的信息
在您使用我们的产品/服务时，我们需要/可能需要收集和使用的您的个人信息，包括如下两种：
1、为实现向您提供我们产品及/或服务的基本功能，您须授权我们收集、使用的必要的信息。如您拒绝提供相应信息，您将无法正常使用我们的产品及/或服务；
2、为实现向您提供我们产品及/或服务的附加功能，您可选择是否授权我们收集、使用的信息。如您拒绝提供，您将无法正常使用相关附加功能或无法达到我们拟达到的功能效果。
我们在此特别提醒您：
为给您带来更好的产品和服务体验，我们持续努力改进我们的产品、服务及技术，随之我们可能会不时推出新的或优化后的功能，可能需要收集、使用新的个人信息或变更个人信息使用目的或方式。如发生上述情形，我们将通过更新本政策、弹窗、页面提示等方式另行向您详细说明，并重新征得您的同意，仅在征得您明示同意后才开始收集、使用。在此过程中，如果您有任何疑问、意见或建议的，您可通过本政策文末联系方式与我们联系，我们会尽快为您做出解答。

我们仅为您注册，向您提供平台服务及履行我们该过程中法定义务的目的处理您的个人信息，目前不会为其他目的处理您的个人信息。我们会为您提供的各项具体功能场景包括：
（一）帮助您成为我们的注册用户
我们基于大模型开放平台账户为您提供服务。为了创建大模型开放平台账户，您需要向我们关联您的手机号，如果您拒绝提供上述信息，您将无法注册大模型开放平台账户，无法使用我们的产品和服务。为了更好地为您提供客户服务，您可以向我们提供您的电子邮箱，但您不提供不影响您使用我们的服务。
对于个人用户，为了确保我们是在为您本人提供服务，我们可能会根据您提供的上述信息校验您的身份。

（二）帮助您进行实名认证
为了更好地向您提供服务，同时实现产品合规，我们可能需要对您进行实名认证，对于个人用户，您将需要提供您的身份证信息。如我们采购第三方服务对您进行人脸识别认证，且您通过扫描二维码使用该种服务的，您的人脸信息将由第三方收集处理，我们不处理您的人脸信息。对于企业用户，您将需要上传您的营业执照、提供您的企业名称、统一社会信用代码，并完成对公打款认证。您的以上企业信息不属于个人信息。

（三）回复您的留言咨询
如您就本平台服务有任何的问题，您需要在本平台中填写并向智谱提供以下信息：您的姓名、联系电话、公司名称、公司所在地、您需要咨询的事宜。以上这些信息，我们将用于与您进行电话联络，就您咨询的问题进行回复。

（四）回复您关于业务合作的咨询
如您希望能够与智谱进行合作，您需要在本平台中填写并向智谱提供以下信息：您的姓名、联系邮箱、联系电话、您的职务、公司名称、您想咨询的问题。以上这些信息，我们将用于与您进行电话或邮件联络，就您的咨询进行回复。

（五）履行我们的法定义务
《网络信息内容生态治理规定》第10条要求我们在发现违法或不良信息时，向主管机关报告相关记录，因此我们将需记录并可能向主管机关提供您的账号、操作时间、操作类型、网络源地址和目标地址、网络源端口、客户端硬件特征等日志信息以及您输入的信息等个人信息。
该种情形下对您个人信息的处理将不需要您的同意。

（六）试用平台内模型
您在试用平台内模型时，可能自愿输入您的各类个人信息，供平台内模型为您生成内容。此时您输入个人信息的种类、范围由您自行决定，我们不会强制要求您提供任何个人信息。

（七）客服及争议处理
当您与我们联系或提出纠纷处理申请时，为了保障您的账户及系统安全，我们需要您提供必要的个人信息以核验您的会员身份。
为便于与您联系、尽快帮助您解决问题或记录相关问题的处理方案及结果，我们会保存您与我们的沟通、通信/通话记录及相关内容，如果您针对具体订单进行咨询、投诉或提供建议的，我们会使用您的账户信息和订单信息。
为了提供服务及改进服务质量的合理需要，我们还可能使用的您的其他信息，包括您与客服联系时您提供的相关信息，您参与问卷调查时向我们发送的问卷答复信息。

（八）我们如何使用 Cookie 和同类技术
为确保本平台正常运转，我们会在您的计算机或移动设备上存储名为 Cookie 的小数据文件。
Cookie 通常包含标识符、站点名称以及一些号码和字符。Cookie主要的功能是便于您使用本平台产品和服务，以及帮助本平台统计独立访客数量等。运用Cookie技术，我们能够为您提供更加周到的个性化服务，并允许您设定您特定的服务选项。
当您浏览智谱的页面时，平台会向您的设备发送Cookie。我们不会将 Cookie 用于本隐私政策所述目的之外的任何用途。您可根据自己的偏好管理或删除 Cookie。有关详情，请参见aboutcookies.org。您可以清除计算机上保存的所有 Cookie，大部分网络浏览器都设有阻止 Cookie 的功能。但如果您这么做，则需要在每一次访问本平台时亲自更改设置，但您可能因为该等修改，无法登录或使用依赖于Cookie的服务或功能。

（九）收集和使用个人信息的其他规则
1、若您提供的信息中含有其他用户的个人信息，在向大模型开放平台提供这些个人信息之前，您需确保您已经取得合法的授权。
2、若我们将信息用于本政策未载明的其他用途，或者将基于特定目的收集而来的信息用于其他目的，均会事先获得您的同意。
3、若我们从第三方处间接获取您的信息，我们会在收集前明确以书面形式要求该第三方说明其个人信息来源，以及是否已经就其收集、处理以及向我们提供您的个人信息取得了您的合法授权。除法律明确允许的情形外，我们只会在确认第三方已经取得您的授权同意后再从第三方收集您的个人信息，如果第三方的授权范围无法涵盖我们的处理和使用目的，我们会要求该第三方征得您的同意后再行处理您的个人信息。同时，我们的专业安全团队对个人信息会进行安全加固（包括敏感信息报备、敏感信息加密存储、访问权限控制等）。我们会使用不低于我们对自身用户个人信息同等的保护手段与措施对间接获取的个人信息进行保护。
4、征得授权同意的例外
根据相关法律法规规定，我们在以下情况下收集、使用您的个人信息无需您的授权同意：
（1）为订立、履行个人作为一方当事人的合同所必需，或者按照依法制定的劳动规章制度和依法签订的集体合同实施人力资源管理所必需；
（2）为履行法定职责或者法定义务所必需；
（3）为应对突发公共卫生事件，或者紧急情况下为保护自然人的生命健康和财产安全所必需；
（4）为公共利益实施新闻报道、舆论监督等行为，在合理的范围内处理个人信息；
（5）依照本法规定在合理的范围内处理个人自行公开或者其他已经合法公开的个人信息；
（6）法律、行政法规规定的其他情形。
请知悉，根据适用的法律，若我们对个人信息采取技术措施和其他必要措施进行处理，使得数据接收方无法重新识别特定个人且不能复原，或我们可能会对收集的信息进行匿名化的研究、统计分析和预测，用于改善大模型开放平台的内容和布局，为商业决策提供产品或服务支撑，以及改进我们的产品和服务（包括使用匿名数据进行机器学习或模型算法训练），按照相关法律法规规定，此类数据已不属于个人信息范畴，因此此类处理后数据的使用无需另行征得您的同意。
5、如我们停止运营大模型开放平台产品或服务，我们将及时停止继续收集您个人信息的活动，将停止运营的通知以逐一送达或公告的形式通知您，并对我们所持有的与已关停业务相关的个人信息进行删除或匿名化处理。涉及儿童个人信息的，我们会并将停止运营的通知及时告知儿童监护人。
6、大模型开放平台及平台内模型均不要求您或最终用户输入个人信息。您应当注意，并应提醒您的最终用户注意，为确保您和最终用户个人信息的安全，除非您或最终用户使用智谱产品或服务所必需且您和最终用户已充分知悉相应风险，您和最终用户应避免向大模型开放平台及平台内模型输入个人信息。

三、我们如何共享、转让、公开披露您的信息
（一）共享
目前，我们委托基础云服务商处理您的个人信息，智谱采用公有云服务作为底层资源支持，您的个人信息将使用公有云服务进行存储和处理。智谱仅会出于特定、明确而合法的目的处理您的信息，并且只会共享提供服务所必要的信息。同时，智谱会与其签署严格的保密协议，要求合作伙伴按照智谱的说明、本隐私政策以及其他任何相关的保密和安全措施来处理相关信息。

为保障我们服务的稳定运行、功能实现，使您能够享受和使用更多的服务及功能，我们的应用中会嵌入授权合作伙伴的SDK、API或其他类似的应用程序，详情如下表所示：

第三方SDK/API名称 使用场景 个人信息字段 第三方机构名称及链接
支付宝人脸认证API 账号实名认证场景中个人身份的识别 人脸识别信息、姓名、身份证号 蚂蚁云创数字科技(北京)有限公司
支付宝电脑网站支付API 用户在商户页面确认使用支付宝支付后，浏览器自动跳转支付宝电脑网页完成付款 支付结果 支付宝（杭州）信息技术有限公司

我们会对授权合作伙伴获取有关信息的应用程序接口（API）、软件工具开发包（SDK）进行严格的安全检测，并与授权合作伙伴约定严格的数据保护措施，令其按照本政策以及其他任何相关的保密和安全措施来处理个人信息。

除此之外，我们不会向其他公司、组织和个人共享您的个人信息；如我们进行此类活动，将按照本隐私政策的相关约定更新本政策并征求您的单独同意，但以下情况除外：
1、在法定情形下的共享：我们可能会根据法律法规规定、诉讼、争议解决需要，或按行政、司法机关依法提出的要求，对外共享您的个人信息。
2、在获取明确同意的情况下共享：获得您的明确同意后，我们会与其他方共享您的个人信息。
3、为您提供您需要的产品或服务必要的情况下共享。
4、与授权合作伙伴共享：我们可能委托授权合作伙伴为您提供某些服务或代表我们履行职能，我们仅会出于本政策声明的合法、正当、必要、特定、明确的目的共享您的信息，授权合作伙伴只能接触到其履行职责所需信息，且我们将会通过协议要求其不得将此信息用于其他任何目的。我们会在取得您的同意，或将您的个人信息进行匿名化处理，以便授权合作伙伴无法识别您个人后才与授权合作伙伴共享您的个人信息。

（二）转让
我们不会将您的个人信息转让给任何公司、组织和个人，但以下情况除外：
1、在获取明确同意的情况下转让：获得您的明确同意后，我们会向其他方转让您的个人信息；
2、在大模型开放平台服务提供者发生合并、收购或破产清算情形，或其他涉及合并、收购或破产清算情形时，如涉及到个人信息转让，新的持有您个人信息的公司、组织会重新征得您的同意，该公司、组织也将继续受本政策的约束。

（三）公开披露
我们仅会在以下情况下，公开披露您的个人信息：
1、获得您明确同意或基于您的主动选择，我们可能会公开披露您的个人信息；
2、如果我们确定您出现违反法律法规或严重违反大模型开放平台相关协议及规则的情况，或为保护大模型开放平台用户或公众的人身财产安全免遭侵害，我们可能依据法律法规或在征得您同意的情况下披露关于您的个人信息，包括相关违规行为以及大模型开放平台已对您采取的措施。

（四）共享、转让、公开披露个人信息时事先征得授权同意的例外
根据相关法律法规规定，以下情形中，共享、转让、公开披露您的个人信息无需事先征得您的授权同意：
1、与我们履行法律法规规定的义务相关的；
2、与国家安全、国防安全直接相关的；
3、与公共安全、公共卫生、重大公共利益直接相关的；
4、与犯罪侦查、起诉、审判和判决执行等司法或行政执法直接相关的；
5、出于维护您或其他个人的生命、财产等重大合法权益但又很难得到本人同意的；
6、您自行向社会公众公开的个人信息；
7、从合法公开披露的信息中收集个人信息的，如合法的新闻报道、政府信息公开等渠道。

请知悉，根据适用的法律，若我们对个人信息采取技术措施和其他必要措施进行处理，使得数据接收方无法重新识别特定个人且不能复原，则此类处理后数据的共享、转让、公开披露无需另行征得您的同意。
<end>
大模型开放平台隐私政策(信息保护)
四、我们如何保护您的信息
（一）我们采取的数据保护技术措施
我们已采取符合业界标准、合理可行的安全防护措施保护您的信息，防止个人信息遭到未经授权访问、公开披露、使用、修改、损坏或丢失。例如，我们已采取数据分类分级制度，对数据进行分类分级保护；采取身份鉴别技术进行用户身份验证。此外我们会使用受信赖的保护机制防止个人信息遭到恶意攻击；我们会部署访问控制机制，确保只有授权人员才可访问个人信息。

（二）我们采取的数据保护管理组织措施
我们建立了完备的以数据为核心、围绕数据生命周期进行的数据安全管理体系，从组织建设、制度设计、人员管理、产品技术等方面多维度提升个人信息的安全性。我们已经建立了个人信息管理制度，并设置了个人信息保护负责人对您的个人信息予以特别保护。我们会举办安全和隐私保护培训课程，加强员工对于保护个人信息重要性的认识。

（三）个人信息安全事件的响应
如果我们的物理、技术或管理防护设施遭到或可能遭到破坏，导致或可能导致信息被非法授权访问、公开披露、篡改或毁坏，以致您的合法权益受损的，我们会及时启动应急预案，采取合理救济措施，以尽可能降低对您个人信息和其他权益的影响。如发生个人信息安全事件，我们还将按照法律法规的要求向您告知：发生或者可能发生个人信息泄露、篡改、丢失的信息种类、原因和可能造成的危害；我们采取的补救措施和您可以采取的减轻危害的措施；我们的联系方式。事件相关情况我们将以邮件、信函、电话、推送通知等方式告知您，难以逐一告知个人信息主体时，我们会采取合理、有效的方式发布公告。根据相关法律规定，如果我们采取措施能够有效避免信息泄露、篡改、丢失造成危害的，可以不通知您；履行个人信息保护职责的部门认为有必要的除外。同时，我们还将按照监管部门要求，上报个人信息安全事件的处置情况。

（四）账户安全风险的自主防范
我们强烈建议您在使用大模型开放平台服务时不要使用非大模型开放平台推荐的通信方式发送您的信息。如我们向您提供密码登录服务的，请您使用与其他账号不同的复杂密码，协助我们保护您的账户安全。
请您妥善保护自己的个人信息，仅在必要的情形下向他人提供。如您发现自己的个人信息尤其是您的账户或密码发生泄露，请您立即联络大模型开放平台客服以便我们根据您的申请采取相应措施。
请注意，您在使用我们服务时自愿提供的信息，可能会涉及您或他人的个人信息甚至个人敏感信息。请您更加谨慎地考虑，是否在使用我们的服务时提供相关信息。

五、我们如何存储您的信息
（一）存储地点
我们在中国境内运营中收集和产生的个人信息存储在中国境内。
目前我们不会跨境传输或存储您的个人信息，将来如需跨境传输或存储的，我们会向您告知信息出境的目的、接收方、安全保障措施和安全风险，并事先征得您的同意。

（二）存储期限
我们只会在达成本政策所述目的所需的期限内保留您的个人信息，除非法律有强制的留存要求，例如《网络信息内容生态治理规定》第10条要求网络信息内容服务平台发现违法违规、不良信息的，保存有关记录。我们判断个人信息的存储期限主要参考以下标准并以其中较长者为准：
1、完成、维护与您相关的业务记录，以应对您可能的查询或投诉；
2、保证我们为您提供服务的安全和质量；
3、您是否同意更长的留存期间；
4、是否存在关于保留期限的其他特别约定或法律法规规定。
在前述法律法规有强制留存要求的情况下，即使您注销您的账户或要求删除您的个人信息，我们亦无法删除或匿名化处理您的个人信息。在超出保留期间后，我们会根据适用法律的要求删除您的个人信息，或对其进行匿名化处理。

六、您如何管理您的信息
您可以通过以下方式访问及管理您的信息：
（一）查询、复制、更正和补充您的信息
您有权查询、复制、更正或补充您的信息。您可以通过以下方式进行：向我们的个人信息保护负责人发送邮件，联系邮箱：service@zhipuai.cn。

（二）删除您的信息
您可以通过“（一）查询、复制、更正和补充您的信息”中列明的方式删除您的个人信息。
当您或我们协助您删除相关信息后，因为适用的法律和安全技术限制，我们可能无法立即从备份系统中删除相应的信息，我们将安全地存储您的个人信息并限制对其的任何进一步的处理，直到备份可以清除或实现匿名化。

（三）改变您授权同意的范围
您可以通过“（一）查询、复制、更正和补充您的信息”中列明的方式改变或者撤回您授权我们收集和处理您的个人信息的范围：
当您收回授权后，我们将不再处理相应的个人信息。但您收回授权的决定，不会影响我们此前基于您的授权而开展的个人信息处理。

（四）注销您的账户
由于目前的用户账户注销功能尚不完备，我们建议您通过以下方式申请关闭/注销您的账户：
向我们的个人信息保护负责人发送邮件，联系邮箱：service@zhipuai.cn。
在您主动注销账户之后，我们将停止为您提供产品或服务，并根据适用法律的要求删除您的个人信息，或对其进行匿名化处理。

（五）响应您的上述请求
为保障您的账户安全，您向我们提出上述请求时，我们可能会先要求您验证您的身份（如要求您提供书面请求或其他方式），然后再处理您的请求。
对于您向我们提出的上述请求，我们将在15天内作出答复。如您不满意我们的答复，还可以直接向我们的个人信息保护负责人发起投诉。
对于您合理的请求，我们原则上不收取费用，但对多次重复、超出合理限度的请求，我们将酌情收取一定费用。对于与您的身份不直接关联的信息、无合理理由重复申请的信息，或者需要过多技术手段（例如，需要开发新系统或从根本上改变现行惯例）、给他人合法权益带来风险或者不切实际的请求，我们可能会予以拒绝。
在以下情形中，按照法律法规要求，我们将无法响应您的请求：
1、与我们履行法律法规规定的义务相关的；
2、与国家安全、国防安全直接相关的；
3、与公共安全、公共卫生、重大公共利益直接相关的；
4、与刑事犯罪侦查、起诉、审判和执行判决等直接相关的；
5、有充分证据表明个人信息主体存在主观恶意或滥用权利的；
6、出于维护个人信息主体或其他个人的生命、财产等重大合法权益但又很难得到本人授权同意的；
7、响应您的请求将导致您或其他个人、组织的合法权益受到严重损害的；
8、涉及商业秘密的。

七、本政策如何更新
我们的服务以及技术不断跟随您以及其他的用户的需求更新和优化，因此在新的服务及业务流程变更时，我们可能会更新我们的隐私权政策以告知您具体的变化。但未经您明确同意，我们不会限制您按照本政策所应享有的权利。
对于重大变更，我们还会提供更为显著的通知（包括我们会通过大模型开放平台公示的方式进行通知或向您提供弹窗提示）。
本政策所指的重大变更包括但不限于：
1、我们的服务模式发生重大变化。如处理个人信息的目的、处理的个人信息类型、个人信息的使用方式等；
2、我们在控制权等方面发生重大变化。如并购重组等引起的信息控制者变更等；
3、个人信息共享、转让或公开披露的主要对象发生变化；
4、您拥有的个人信息处理方面的权利及其行使方式发生重大变化；
5、我们负责处理个人信息保护的责任部门、联络方式及投诉渠道发生变化；

八、您如何联系我们
您可以通过以下方式与我们联系，我们将在15天内回复您的请求：
1、向我们的个人信息保护负责人发送邮件，联系邮箱：service@zhipuai.cn。需注意的是，我们可能不会回复与本政策或与个人信息保护无关的问题。
如果您对我们的回复不满意，特别是您认为我们的个人信息处理行为损害了您的合法权益，您还可以通过向智谱所在地有管辖权的法院提起诉讼来寻求解决方案。
<end>
服务协议

一、接受条款
欢迎您使用大模型开放平台。以下所述条款和条件为大模型开放平台的用户（以下简称“用户“或“您“）和北京智谱华章科技有限公司（以下简称“智谱”）就您使用大模型开放平台服务所达成的协议（以下简称“本协议”）。

本协议包括但不限于本协议正文及所有智谱已经发布的或将来可能发布的关于服务的各类规则、规范、公告、说明和（或）通知等，以及其他各项网站规则、制度等。所有前述规则为本协议不可分割的组成部分，与本协议正文具有同等法律效力。如您与智谱已就您使用智谱大模型开放平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。

智谱有权根据国家法律法规的变化以及实际业务运营的需要不时修改本协议相关内容，并提前公示于平台系统、网站等以通知用户。修改后的条款应于公示通知指定的日期生效。如果您选择继续充值即表示您同意并接受修改后的协议且受其约束；如果您不同意我们对本协议的修改，请立即放弃充值或者停止使用本服务。本协议末尾的签署处系为满足部分客户签订协议的要求预留，双方未完成签署的不影响本协议的生效。

因营销活动、产品推广等各种原因，智谱可能在特定时期内推出“限时免费”、“限时优惠”、“限量优惠”、“充值优惠”以及赠送服务等优惠措施（以下统称“优惠措施”），您理解并同意，这些优惠措施可能是暂时性、阶段性或有数量限制的，也可能仅适用于满足特定条件的客户，您需要按照相应的规则购买、使用相应服务。除非另有书面明确说明，优惠措施不可同时叠加适用。您充分理解并同意，您已获得的优惠权益可能因产品/服务版本更新、功能调整等原因调整、失效，智谱对优惠措施的适用规则具有最终解释权。您承诺不会因优惠措施的调整、优惠权益的失效而向智谱追究任何责任。

*请注意，本协议限制了智谱的责任，还限制了您的救济，具体条款将以加粗并加下划线的形式提示您注意，请您仔细阅读。如果您对本协议的条款有疑问的，请通过客服渠道（电子邮箱：service@zhipuai.cn; 或平台右下角客服企微）进行询问，智谱将向您解释条款内容。*如果您不同意本协议的任意内容，或者无法准确理解智谱对条款的解释，请不要同意本协议或使用本协议项下的服务。

二、定义
2.1 大模型开放平台用户充值余额账户：简称“余额账户”，指由智谱根据用户的大模型开放平台账户为用户自动配置的账户。用户向该账户充值的行为视为用户向智谱预充值，预充值的金额可用于购买大模型开放平台提供的产品或服务。
2.2 充值金额：是指用户进行在线充值并实际支付的金额（人民币），不包括平台赠送的体验金金额以及充值优惠金额，充值金额可在大模型开放平台自由消耗使用。
2.3 平台体验金：是指大模型开放平台针对新客户体验场景赠予的限时有效的体验金，可用于平台大模型API调用消耗使用。除非在赠送时对有效期另有约定，通常平台体验金的使用有效期为自发放之日起30天，且平台有权随时调整体验金的有效期、使用规则等，智谱对该规则享有最终解释权。平台体验金不可提现、不可转让，不可开具发票。
2.4 充值优惠金额：是指根据大模型开放平台不时推出的充值优惠活动，在充值金额以外额外赠予的金额（包括但不限于红包、折扣、充值返现、优惠券、代金券等优惠形式，具体以届时活动通知的规则为准）。充值优惠金额不可提现、不可转让，不可开具发票。充值优惠活动内容及充值优惠金额的使用及发放均以大模型开放平台公布的规则为准，且智谱对该规则享有最终解释权。

三、您的权利义务
3.1 当您充值时，您应该具有完全的民事行为能力，并拥有经实名认证成功后的大模型开放平台账户。
3.2 为保证我们计费的准确，您应当确保您选择的产品/服务、填写的订单信息准确无误。因您订单信息填写错误而导致的计费统计错误，我们不承担责任，且无需退还您已支付的服务款项。除非您有确切证据证明大模型开放平台的使用数据错误，计费统计以大模型开放平台的显示为准。
3.3 您对大模型开放平台提供的任何服务的利用均应符合《生成式人工智能服务管理暂行办法》《互联网信息服务算法推荐管理规定》《互联网信息服务深度合成管理规定》以及适用的其他法律法规。您调用大模型开放平台内模型API开发的产品和应用，由您负责自行进行互联网信息服务算法备案、具有舆论属性或社会动员能力的互联网信息服务安全评估、上线备案等合规程序，以及其他基于法律法规及政策所要求的审批、备案、评估及流程，按照相关规定和主管机关要求真实、准确地公示使用智谱模型及其他模型（如有）的情况，请勿对未使用智谱模型的产品和服务进行虚假的、混淆事实的公示、标识及展示。您违反前述法律法规和约定造成的后果由您自行承担，由于您的行为给智谱造成损失的，您应赔偿由此造成的损失。
3.4 除本协议明确约定外，未经智谱及相关权利人书面同意，您不得复制、转让、出售、出租、出借、许可、提供他人使用或以任何智谱明确允许之外的商业化方式使用大模型开放平台、平台内模型等平台上的内容。为免疑义，您可以在按照大模型开放平台届时有效的规则支付费用后，根据具体产品的规则商业化使用平台内模型及其生成的内容。
3.5 我们有权对您使用产品服务的情况进行监督和独立判断。如我们发现您在使用大模型开放平台所提供的产品服务时违反我们与您达成的任何约定，我们有权采取要求您改正、暂停服务、解除协议等处理方式。由此造成的损失，您应当自行承担。
3.6 您接入智谱产品或服务向公众提供内容生成式人工智能产品或服务的，应根据适用法律法规开展安全评估、算法备案、上线备案或法律规定的其他要求、审批，按照相关规定和主管机关要求真实、准确地公示使用智谱模型及其他模型（如有）的情况，请勿对未使用智谱模型的产品和服务进行虚假的、混淆事实的公示、标识及展示。您应对您的应用生成内容的安全性、合法性、合规性进行有效管理和控制，建立包括但不限于内容审核、用户管理、数据安全、监测预警和应急处置等机制。
3.7 您在使用智谱的产品和服务时须遵守相关法律法规，履行法律法规规定的安全义务，不违反《中华人民共和国刑法》《中华人民共和国反不正当竞争法》《中华人民共和国网络安全法》《中华人民共和国数据安全法》《中华人民共和国个人信息保护法》《互联网信息服务算法推荐管理规定》《互联网信息服务深度合成管理规定》《生成式人工智能服务管理暂行办法》《具有舆论属性或社会动员能力的互联网信息服务安全评估规定》《互联网新闻信息服务新技术新应用安全评估管理规定》《网络信息内容生态治理规定》等相关法律法规及政策，维护互联网秩序和网络安全，请勿利用产品发布危害国家安全的、破坏民族团结的、扰乱社会秩序的、有歧视性的、不正当的言论，或侵害任何第三方的个人信息保护权、名誉权、人格权、知识产权、财产权、肖像权等其他任何权益，或从事涉及黄赌毒、违反法律法规或公序良俗的行为。
3.8 如您利用智谱产品创建虚拟人物，需保证虚拟人物的形象、头像、名称、人物设定及创建过程中的数据和内容均不侵犯第三方知识产权、肖像权、名誉权、隐私权、个人信息保护权等合法权益，不会利用虚拟人物从事任何可能构成不正当竞争的行为。

四、账户和数据安全
4.1 当您进行充值时，用户应仔细确认自己的账号及信息，若因为您自身操作不当、不了解或未充分了解充值计费方式等因素造成充错账号、错选充值种类等情形而损害自身权益，应由用户自行承担责任。
4.2 您在充值时使用第三方支付企业提供的服务的，应当遵守与该第三方的各项协议及其服务规则；在使用第三方支付服务过程中您应当妥善保管个人信息，包括但不限于银行账号、密码、验证码等；您同意并确认，智谱对因第三方支付服务产生的纠纷不承担任何责任。
4.3 您应自行确保大模型开放平台账号和密码的安全，您账户下发生的行为将全部视为您的行为，无论该等行为是否取得您的授权，或由您、您的员工或第三方（包括您的承包商或代理商）实施。我们不对您的账户遭到未授权访问承担责任。
4.4 智谱尊重您的数据安全和隐私，并将采取合理措施保护您的数据安全。您通过智谱提供的服务，加工、存储、上传、下载、分发以及通过其他方式处理的数据，均为您的数据，您完全拥有您的数据，但同时，您应保证您的数据符合相关法律法规的规定和本协议的约定。
4.5 就您的数据，除为您提供服务所必需外，智谱不会进行任何未获授权的使用及披露；但以下情形除外：
 （1）在国家有关机关依法查询或调阅用户业务数据时，智谱具有按照相关法律法规或政策文件要求提供配合，并向第三方或者行政、司法等机构披露的义务；
（2）您和智谱另行协商一致；
（3）法律法规另有规定。
4.6 智谱仅在为您提供服务和满足合规要求所需的最小必要范围内存储您的数据，且会进行必要的匿名化和加密处理。

五、充值方式
5.1 您可通过支付宝、银行汇款等途径将费用充值到您在大模型开放平台的账户中，支付方式及其他具体规则以大模型开放平台展示为准。
5.2 您如委托第三方对其余额账户充值，则您承诺并保证其了解和信任第三方，且第三方亦了解和同意接受您的委托，为您充值；否则，如智谱被第三方告知该等充值非经相关权利人同意，则智谱有权立即锁定您的余额账户（账户锁定期间，智谱将暂停用户使用服务，同时锁定用户APIkeys，下同）。自您的余额账户被锁定之日起30日内，您应提供充足证据证实相关权利人事先同意为其充值，否则您同意并授权智谱配合第三方的要求，自您被锁定的余额账户中将相应款项退还相关权利人。如届时您的消耗账户余额不足以退还，则短缺部分，您同意最晚在30日内充值相应金额，委托智谱退还，或自其微信账户或支付宝账户自行退还，除非相关权利人同意您可不退还这部分款项。
5.3 您承诺并保证用于其消耗账户充值的资金来源的合法性，否则智谱有权配合司法机关或其他政府主管机关的要求，对您的余额账户进行相应处理，包括但不限于对您的余额账户进行锁定、查封、限制使用等。

六、账户金额使用
6.1 您充值后，充值金额的使用不设有效期，不能转移、转赠。因此，请您根据自己的消耗情况选择充值金额，智谱对充值次数不做限制。
6.2 您成功充值后可以立即开始使用相应产品（或服务）。
6.3 您选购产品的付费模式以产品的展示页面为准。对于预付费的服务，您需在使用产品前向智谱支付全部使用费用，在您支付完毕后方可开始使用大模型开放平台提供的服务。对于后付费的服务，您需预先在大模型开放平台进行预充值，在余额充足时可以使用大模型开放平台提供的服务，您的余额不足时大模型开放平台有权停止服务。
6.4 您在使用服务的过程中应注意您的账户余额。由于您的账户余额不足而服务停止，以及由此产生的相关损失，智谱不承担任何责任。

七、发票
7.1 智谱将在您的充值金额消耗后，按照实际消耗金额，根据您订购的产品（或服务）协议开具相应发票，具体开具发票的流程和操作方式以大模型开放平台届时向您展示的内容为准。
7.2 个人认证账户支持开具个人发票和企业发票，个人在申请开具企业发票时需提供在职证明，营业执照和工牌作为证明材料。企业认证账户仅支持按照认证的企业主体开票。

八、退款
8.1 您应充分预估实际需求并确定充值金额。如您因特殊情况必须退款，尚未消费的充值金额（不含体验金、优惠金额等）可联系平台客服发起退款申请，并配合提供相关证明材料，智谱将对用户的退款事宜进行审核。如审核通过的，将会根据用户充值时选取的支付方式将相应充值金额原路返还。
8.2 充值金额仅支持一次性退款，体验金/充值优惠金额（包括但不限于体验金、红包及同类非现金折扣等）不支持申请退款。一旦发起退款申请，充值优惠金额将于退款申请通过之时失效。您的充值优惠金额已经使用，您又对该笔充值发起全部或部分退款的，在退款时我们将全额从充值金额中扣除已经使用的充值优惠金额。
8.3 您完成充值并已经消耗的或根据相关产品（或服务）协议应予扣除的，不支持退款。
8.4 已开票部分的充值金额不支持退款。

九、违约责任
9.1 双方应履行本协议约定的各项义务。由于任意一方违约给相对方造成损失的，违约方应予以赔偿。本协议所称的损失，包括但不限于诉讼费、仲裁费、律师费、鉴定费、差旅费、调查取证费、赔偿金、违约金、和解费用、行政处罚的罚金等。
9.2 大模型开放平台依照法律规定履行基础保障义务，但对于下述原因导致的合同履行障碍、履行瑕疵、履行延后或履行内容变更等情形，智谱并不承担相应的违约责任：
① 因自然灾害、罢工、暴乱、战争、政府行为、司法行政命令等不可抗力因素；
② 因电力供应故障、通讯网络故障等公共服务因素或第三人因素；
在大模型开放平台已尽善意管理的情况下，因常规或紧急的设备与系统维护、设备与系统故障、网络信息与数据安全等因素。
9.3 智谱无需就您特殊的、偶然的、间接的、附带的损害和损失（包括但不限于：预期利益、利润、商业机会、营业中断、资讯丢失等）向您承担责任，即使智谱已被告知该等损害发生的可能性。
9.4 在履行本协议时，智谱对因第三方的作为或不作为而给您或者其他第三方造成的损失不负责任。
9.5 任何情况下，智谱对本协议所承担的违约赔偿责任总额不超过违约服务对应之服务费总额。

十、争议解决
10.1 本协议适用中华人民共和国大陆地区法律。用户如因本协议与智谱发生争议的，双方应首先友好协商解决，如协商不成的，该等争议将由智谱所在地有管辖权的人民法院管辖。

十一、其它
11.1 您未经智谱书面/邮件同意，不得在任何时候、以任何方式（无论是直接还是间接，也无论是明示还是暗示；包括但不限于任何营销、广告、促销、市场推广或其他目的）：
 使用、引用、公布、复制、分销，展示（公开或非公开）、提及、注册或申请注册：
 (i) 智谱或其关联方拥有或有权使用的任何商标（无论是否已注册）、商号、名称、标志或者标识（包括但不限于：“智谱”、“智谱AI”、“Zhipu”、“Zhipu.AI”、“AMiner”、“ChatGLM”、“ChatGLM-130B”、“CodeGeeX”、“CogView”，或与清华大学有关的任何文字及标志，如“清华大学”、“清华大学计算机系”、“清华大学KEG实验室”，等），或通过特定描述使第三方能够识别智谱或其任何关联方。
 (ii) 智谱或其关联方任何董事、监事、管理人员、雇员或合伙人、科学家团队的姓名、肖像、形象、照片、图片、标识、发言或评论（或其一部分）
 (iii) 或与前述各项相似的、以任何语言形式存在的任何名称、商标、标识、文字、词语、符号或其任何组合；
直接或间接声明您或您任何关联方所提供的任何产品或服务已由智谱或其任何关联方认可或支持。特别地，未经智谱事先书面/邮件同意，您不得将智谱相关的宣传/广告/影响策略及内容向任何第三方进行宣传或披露、亦不得利用智谱或其相关方品牌直接或间接谋求及/或招揽任何投资及/或合作机会。

11.2 智谱向您提供的文本生成算法备案信息如下：算法名称：智谱交互式内容生成算法；备案编号：网信算备110108105858001230027号。

11.3 智谱有权向您注册时预留的电话号码、电子邮箱等发送具有法律效力的通知，该等通知于发送之日视为已送达。

11.4 除非法律另有规定，本协议任何一方未能行使或迟延行使本协议项下的权利并不构成对该等权利的放弃；单独或部分行使该等权利不应阻碍任何其他权利、权力或特权的行使。

11.5 本协议中的任何条款无论因何种原因完全或部分无效或不具有执行力，本协议的其余条款仍应有效并且有约束力。

11.6 未经智谱事先书面同意，您不得转让或让与本协议或本协议项下您的任何权利和义务。违反本条约定进行的任何转让或让与无效。

<end>
充值协议
尊敬的用户，为保障您的合法权益，请您在点击“购买”按钮前，完整、仔细地阅读本充值协议，当您点击“立即购买”按钮，即表示您已阅读、理解本协议内容，并同意按照本协议约定的规则进行充值和使用余额行为。如您不接受本协议的部分或全部内容，请您不要点击“立即购买”按钮。

一、接受条款
欢迎您使用大模型开放平台。以下所述条款和条件为平台充值的用户（以下简称“用户“或“您“）和北京智谱华章科技有限公司（以下简称“智谱科技”）就充值以及余额使用所达成的协议。
当您以在线点击“立即购买”等方式确认本协议或实际进行充值时，即表示您已理解本协议内容并同意受本协议约束，包括但不限于本协议正文及所有智谱科技已经发布的或将来可能发布的关于服务的各类规则、规范、公告、说明和（或）通知等，以及其他各项网站规则、制度等。所有前述规则为本协议不可分割的组成部分，与协议正文具有同等法律效力。
智谱科技有权根据国家法律法规的变化以及实际业务运营的需要不时修改本协议相关内容，并提前公示于软件系统、网站等以通知用户。修改后的条款应于公示通知指定的日期生效。如果您选择继续充值即表示您同意并接受修改后的协议且受其约束；如果您不同意我们对本协议的修改，请立即放弃充值或者停止使用本服务。
*请注意，本协议限制了智谱科技的责任，还限制了您的救济，具体条款将以加粗并加下划线的形式提示您注意，智谱科技督促您仔细阅读。如果您对本协议的条款有疑问的，请通过客服渠道（电子邮箱：service@zhipuai.cn; 或平台右下角客服企微）进行询问，智谱科技将向您解释条款内容。*如果您不同意本协议的任意内容，或者无法准确理解智谱科技对条款的解释，请不要同意本协议或使用本协议项下的服务。

二、定义
2.1 大模型开放平台个人充值消耗账户：简称“消耗账户”，指由智谱科技根据用户的大模型开放平台账户为用户自动配置的账户。用户向该账户充值的行为视为用户向智谱科技预付服务费，预付服务费可用于购买大模型开放平台提供的产品或服务。
2.2 充值包：指智谱科技向用户提供的金额不等的服务费预存充值包。充值包分为一般充值包与自定义充值两种，其中一般充值包主要包括一定金额的服务费预存费用，以订购页面当前显示的内容为准；自定义充值指用户自定义金额的预存费用。

三、充值条件
3.1 当您充值时，您应该具有经实名认证成功后的大模型开放平台账户。

四、账户安全
4.1 当用户进行充值时，用户应仔细确认自己的账号及信息，若因为用户自身操作不当、不了解或未充分了解充值计费方式等因素造成充错账号、错选充值种类等情形而损害自身权益，应由用户自行承担责任。
4.2 用户在充值时使用第三方支付企业提供的服务的，应当遵守与该第三方的各项协议及其服务规则；在使用第三方支付服务过程中用户应当妥善保管个人信息，包括但不限于银行账号、密码、验证码等；用户同意并确认，智谱科技对因第三方支付服务产生的纠纷不承担任何责任。

五、充值方式
5.1 用户充值可以选择智谱科技认可的第三方支付企业（目前支持支付宝和微信）支付充值金额。
5.2 用户如委托第三方对其消耗账户充值，则用户承诺并保证其了解和信任第三方，且第三方亦了解和同意接受用户委托，为用户充值；否则，如智谱科技被第三方告知该等充值非经第三方同意，则智谱科技有权立即锁定用户的消耗账户（账户锁定期间，智谱科技将暂停用户使用服务，同时锁定用户 API keys，下同）。自用户的消耗账户被锁定之日起30日内，用户应提供充足证据证实第三方事先同意为其充值，否则用户同意并授权智谱科技配合第三方的要求，自用户被锁定的消耗账户中将相应款项退还第三方。如届时用户的消耗账户余额不足以退还，则短缺部分，用户同意最晚在30日内充值相应金额，委托智谱科技退还，或自其微信账户或支付宝账户自行退还，除非第三方同意用户可不退还这部分款项。
5.3 用户承诺并保证用于其消耗账户充值的资金来源的合法性，否则智谱科技有权配合司法机关或其他政府主管机关的要求，对用户的消耗账户进行相应处理，包括但不限于锁定用户的消耗账户等。

六、充值金额和充值优惠
6.1 充值金额，是指您进行在线充值并实际支付的金额（人民币），不包括充值赠送的金额，可在大模型开放平台自由消耗使用。
6.2 充值赠送金额，是指根据大模型开放平台不时推出的充值优惠活动，在充值金额以外、额外赠予的金额（包括但不限于红包等）。充值赠送金额不可提现、不可转让，不可开具发票。充值赠送金额将依据对应的活动规则发放并依据对应的使用规则使用。
6.3 用户可根据其实际需求及软件系统要求的最低金额选择订购充值包对其消耗账户充值。充值包成功订购后立即生效，无有效期，可叠加使用。用户消耗账户内金额消耗完毕或余额不足时，用户将无法使用平台服务。

七、账户金额使用
7.1 您充值后，账户余额的使用不设有效期，不能转移、转赠。因此，请您根据自己的消耗情况选择充值金额，智谱科技对充值次数不做限制。
7.2 您成功充值可以立即开始使用相应产品（或服务）。

八、发票
8.1 智谱科技将在您的充值金额消耗后，按照实际消耗金额，根据您订购的产品（或服务）协议开具相应发票。

九、关于退款
9.1 *您应充分预估实际需求并确定充值金额，由于平台接口对tokens连续消耗的特性，消耗账户通常不支持退款。如您因特殊情况必须退款，尚未消费的充值金额申请退款的可联系平台客服并配合提供相关证明材料，智谱科技将对用户的退款事宜进行审核。如审核通过的，将会根据用户充值时选取的支付手段将相应充值金额原路返还给用户，并扣除对应手续费。*
9.2 充值金额仅支持一次性退款，充值赠送金额（包括但不限于红包及同类非现金折扣等）不支持申请退款。一旦发起退款申请，充值赠送金额将于退款申请之时失效。
9.3 您完成充值并已经消耗的或根据相关产品（或服务）协议应予扣除的，将不予退还。

十、争议解决
10.1 本协议适用中华人民共和国大陆地区法律。用户如因本协议与智谱科技发生争议的，双方应首先友好协商解决，如协商不成的，该等争议将由北京市海淀区人民法院管辖。

链接信息：
- 客服邮箱：service@zhipuai.cn

<end>
主体变更协议
在您正式提交账号主体变更申请前，请您务必认真阅读本协议。*本协议将通过加粗或*的形式提示您特别关注对您的权利及义务将产生重要影响的相应条款。如果您对本协议的条款有疑问的，请向大模型开放平台咨询，如果您不同意本协议的内容，或者无法准确理解大模型开放平台对条款的解释，请不要进行后续操作。
当您通过网络页面直接确认、接受引用本页面链接及提示遵守内容、签署书面协议、以及大模型开放平台认可的其他方式，或以其他法律法规或惯例认可的方式选择接受本协议，即表示您与大模型开放平台已达成协议，并同意接受本协议的全部约定内容。自本协议约定的生效之日起，本协议对您具有法律约束力。
*请您务必在接受本协议，且确信通过账号主体变更的操作，能够实现您所希望的目的，且您能够接受因本次变更行为的相关后果与责任后，再进行后续操作。

一、协议主体、内容与生效
1.1 本协议是特定大模型开放平台账号的账号持有人（“您”、“原主体”）与北京智谱华章科技有限公司（“智谱科技”）之间，就您申请将双方之前就本次申请主体变更的大模型开放平台账号所达成的《大模型开放平台网站服务条款》（“账号协议”）的权利义务转让给第三方，及相关事宜所达成的一致条款。
1.2 *本协议为附生效条件的协议，仅在以下三个条件同时满足的情况下，才对您及大模型开放平台产生法律效力：
您所申请变更的大模型开放平台账号已完成了实名认证，且您为该实名认证主体；
大模型开放平台审核且同意您的账号主体变更申请；
您申请将账号协议下权利义务转让给第三方（“新主体”），其同意按照《接受账号主体变更协议》的约定，接受账号主体变更。
1.3 *您与新主体就账号下所有的产品、服务、资金、债权、债务等（统称为“账号下资源”）转让等相关事项，由您与新主体之间另外自行约定。但如果您与新主体之间的约定如与本协议约定冲突的，应优先适用本协议的约定。

二、定义和解释
2.1 “大模型开放平台官网”：是指包含域名为maas.aminer.cn的网站。
2.2 “大模型开放平台账号”：是指大模型开放平台分配给注册用户的数字ID，以下简称为“大模型开放平台账号”、“账号”。
2.3 “大模型开放平台会员”：是指自愿注册并获得大模型开放平台账号的个人、法人或其他组织。
2.4 “大模型开放平台账号持有人”，是指注册、持有并使用大模型开放平台账号的大模型开放平台会员。已完成实名认证的账号，除有相反证据外，大模型开放平台将根据用户的实名认证信息来确定账号持有人，如用户填写信息与实名认证主体信息不同的，以实名认证信息为准；未完成实名认证的账号，大模型开放平台将根据用户的填写信息，结合其他相关因素合理判断账号持有人。
2.5 “账号实名认证主体变更”：是指某一大模型开放平台账号的实名认证主体（原主体），变更为另一实名认证主体（新主体），本协议中简称为“账号主体变更”。
2.6 *本协议下的“账号主体变更”程序、后果，仅适用于依据账号原主体申请发起、且被账号新主体接受的大模型开放平台账号实名认证主体变更情形。

三、变更的条件及程序
3.1 大模型开放平台仅接受符合以下条件下的账号主体变更申请；
由于原账号主体发生合并、分立、重组、解散、死亡等原因，需要进行账号主体变更的；
根据生效判决、裁定、裁决、决定等生效法律文书，需要账号主体变更的；
账号实际持有人与账号实名认证主体不一致，且提供了明确证明的；
根据法律法规规定，应当进行账号主体变更的；
大模型开放平台经过审慎判断，认为可以进行账号主体变更的其他情形。
3.2 您发起账号主体变更，应遵循如下程序要求：
您应在申请变更的大模型开放平台账号下发起账号主体变更申请；
大模型开放平台有权通过手机号等进行二次验证、要求您出具授权证明（当您通过账号管理人发起变更申请时）、以及其他大模型开放平台认为有必要的材料，确认本次申请账号主体变更的行为确系您本人意愿；
您应同意本协议的约定，接受本协议对您具有法律约束力；
您应遵守与账号主体变更相关的其他大模型开放平台规则、制度等的要求。
3.3 *您理解并同意：
在新主体确认接受且完成实名认证前，您可以撤回、取消本账号主体变更流程；
当新主体确认接受且完成实名认证后，您的撤销或取消请求大模型开放平台将不予支持；
且您有义务配合新主体完成账号管理权的转交。
3.4 *您理解并同意，如果发现以下任一情形的，大模型开放平台有权随时终止账号主体变更程序或采取相应处理措施：
第三方对该账号发起投诉，且尚未处理完毕的；
该账号正处于国家主管部门的调查中；
该账号正处于诉讼、仲裁或其他法律程序中；
该账号下存在与大模型开放平台的信控关系、伙伴关系等与原主体身份关联的合作关系的；
存在其他可能损害国家、社会利益，或者损害大模型开放平台、阿里巴巴或其他第三方权利的情形的。

四、账号主体变更的后果
除本协议另有约定外，您与大模型开放平台所签署的账号协议下的全部权利义务，将立即转让给新主体；
该账号及该账号下的全部资源的归属权全部转由新主体拥有。但您通过该账号与大模型开放平台另行达成的关于优惠政策、信控、伙伴合作等相关事项的合作协议，或与其他大模型开放平台账号之间存在的关联关系等，将自账号主体变更之时起自动终止；
大模型开放平台不接受您以和新主体之间的协议为由或以其他理由，要求将该账号下一项或多项业务、权益转移给您指定的其他账号的要求；
大模型开放平台有权拒绝您以和新主体之间存在纠纷为由或以其他理由，要求撤销该账号主体变更的请求；
大模型开放平台有权在您与新主体之间就账号管理权发生争议或纠纷时，采取相应措施使得新主体获得该账号的实际管理权。
4.1 *您理解并确认，账号主体变更并不代表您自变更之时起已对该账号下的所有行为和责任得到豁免或减轻：
您仍应对账号主体变更前，该账号下发生的所有行为承担责任；
您还需要对于变更之前已经产生，变更之后继续履行的合同及其他事项，对新主体在变更之后的履行行为及后果承担连带责任。

五、双方权利与义务
5.1 您应承诺并保证：
您在账号主体变更流程中所填写的内容及提交的资料均真实、准确、有效，且不存在任何误导或可能误导大模型开放平台同意接受该项账号主体变更申请的行为；
您不存在利用大模型开放平台的账号主体变更服务进行任何违反法律、法规、部门规章和国家政策等，或侵害任何第三方权利的行为；
您进行账号主体变更的操作不会置大模型开放平台于违约或者违法的境地。因该账号主体变更行为而产生的任何纠纷、争议、损失、侵权、违约责任等，大模型开放平台不承担法律明确规定外的责任。
您进一步承诺，如上述原因给大模型开放平台造成损失的，您应向大模型开放平台承担相应赔偿责任。
5.2 您理解并同意：
大模型开放平台有权在您发起申请后的任一时刻，要求您提供书面材料或其他证明，证明您有权进行变更账号主体的操作；
大模型开放平台有权依据自己谨慎的判断来确定您的申请是否符合法律法规或政策的规定及账号协议的约定，如存在违法违规或其他不适宜变更的情形的，大模型开放平台有权拒绝；
大模型开放平台有权记录账号实名认证主体变更前后的账号主体、交易流水、合同等相关信息，以遵守法律法规的规定，以及维护自身的合法权益；
如果您存在违反本协议第5.1条的行为的，大模型开放平台一经发现，有权直接终止账号主体变更流程，或者撤销已完成的账号主体变更操作，将账号主体恢复为没有进行变更前的状态。

六、附则
6.1 您理解并接受，本协议的订立、执行和解释及争议的解决均应适用中华人民共和国法律，与法律规定不一致或存在冲突的，该不一致或冲突条款不具有法律约束力。
6.2 就本协议内容或其执行发生任何争议，双方应进行友好协商；协商不成时，任一方均可向被告方所在地有管辖权的人民法院提起诉讼。
6.3 本协议如果与双方以前签署的有关条款或者大模型开放平台的有关陈述不一致或者相抵触的，以本协议约定为准。
*您在此再次保证已经完全阅读并理解了上述《申请账号主体变更协议》，并自愿正式进入账号主体变更的后续流程，接受上述条款的约束。

<end>
自律性原则声明

智谱以增进人类共同福祉为目标，致力于人工智能技术研究，坚持技术中立原则，推进人工智能技术的合理应用。

一、遵守AI伦理原则
- AI的最高原则：安全可控
- AI的创新愿景：促进人类更平等地获取技术和能力
- AI的存在价值：教人学习，让人成长，而非超越人、替代人
- AI的终极理想：为人类带来更多自由与可能

二、树立AI技术发展的行动准则
- 安全可控：高度关注人工智能系统的安全，做到可审核、可监督、可追溯、可信赖。
- 公平公正：促进公平公正，通过持续提高技术水平、改善管理方式，努力在数据获取、算法设计、技术开发、产品研发和应用过程中消除偏见和歧视。
- 增进人类福祉：促进人机和谐，服务人类文明进步；以保障社会安全、尊重人类权益为前提。

三、持续完善AI技术管理标准
- 尊重隐私：尊重和保护个人隐私，充分保障个人的知情权和选择权。
- 遵法自律：始终坚持高度的社会责任感和自律意识，严格遵守法律法规、伦理道德和行业标准规范，同时积极主动遵从国家相关法规标准的变动更新，确保人工智能新技术合法合规。
- 敏捷治理：尊重人工智能发展规律，在推动人工智能创新发展、有序发展的同时，及时发现和解决可能引发的风险。不断提升智能化技术手段，优化管理机制，完善治理体系，推动治理原则贯穿人工智能产品和服务的全生命周期。对未来更高级人工智能的潜在风险持续开展研究和预判，确保人工智能始终朝着有利于人类的方向发展。

四、不断探索AI技术风险控制举措
结合国家法律法规及相关标准的要求，在发布人工智能新技术前进行评估，并结合具体情形采取相应的风险控制措施，如：
- 技术举措：按照网络安全法等法律法规要求进行日志留存、身份认证、开发检测工具等。
- 管理举措：特定技术发布前根据法律法规要求向相关监管机构申请审批或报备；与人工智能开放平台的开发者签署相关协议，对开发者使用行为进行主动提醒等。
<end>
安全与风险提示

概述
平台的 API 可以支持广泛的应用，例如问答、写作和对话。虽然使用我们的 API 能为最终用户创造便利，但它也可能产生安全问题，本文档旨在帮助客户了解使用 API 时可能出现的安全问题。

本文档首先介绍如何将 API 作为产品或服务的一部分并进行安全调用，然后列举了几个要考虑的特定问题，提供了有关风险的一般指导，并特别提供了关于稳健性和公平性的进一步指导。

开放型机器学习系统的安全挑战
我们对API的安全进行如下定义：
免于对人造成身体、心理或社会伤害的条件，包括且不限于死亡、伤害、疾病、痛苦、错误信息、过激行为、财产损失，或对环境造成破坏。

我们对API安全的提示和指导是基于对具有机器学习（ML）组件的系统的特殊考虑，这些系统可以与人类进行高带宽、开放式的互动（如通过自然语言）。

- ML组件鲁棒性是有限的。
- ML组件是有偏见的。
- 开放式系统存在很大的风险隐患。
- 安全是开发ML系统需要持续考虑的因素。

风险分析要考虑的危害
我们将举例说明在涉及API的系统中可能出现的潜在危害（或危害途径）。下面这份示例并非详尽无遗，而且并非每个类别都适用于不同的应用场景，用例的开放程度和高风险程度均不同。在确定潜在的危害时，开发者应基于使用情景考量要开发的系统，包括那些使用该系统的人和受其影响的人，并排查代表性危害的来源。

- 提供虚假信息。
- 歧视。
- 个体伤害。
- 煽动暴力。
- 身体伤害，财产损失，或环境破坏。

健壮性的重要性
“健壮性”指的是一个系统在特定的环境下按照预定和预期进行可靠工作。使用本平台的开发者应确保他们的应用具有安全使用所需的健壮性，并应确保长期保持这种健壮性。

- 健壮性是一种挑战。
- 语境非常重要。
- 人的监督。
- 不断测试。

公平的重要性
这里的 "公平 "是指确保API既不会因为用户的群体统计而降低性能，也不会产生对某些群体有偏见的文本。API使用者应采取合理的步骤来识别和减少与API中的人口统计学偏见有关的可预见的伤害。

- ML系统的公平性是极其具有挑战。
- 请在部署前确定公平性风险的特征。
- 过滤工具可以提供一些帮助，但并不是万能的。
<end>
#速率限制指南
##速率限制
用户的API 使用会受到速率限制，当前我们限制的维度是请求并发数量。
##为什么要做速率限制
有效防止请求过载：帮助管理总负载情况，避免请求激增导致的服务器性能问题，提高服务可靠性。
保障资源的公平性及合理利用：避免某一方过多的请求，影响其他方使用。保障更多方的请求调用和用户的使用体验。
安全防护：防止恶意性的攻击，提高整体网络安全。
##用量级别等级
当前我们基于用户的月度 API 调用消耗金额情况将速率控制分为6种等级。
消耗金额选取逻辑：我们会选取用户当前月份1号～t-1日的调用 API 推理消耗总金额和用户上个月的 API 调用消耗总金额做比较，取更高金额作为用户当前的 API 消耗金额。
特别的，若您从未曾付费充值/购买过资源包，则会归为免费级别。
用量级别|资质
免费|api调用消耗0元-50元/每月（不含）
用量级别1|api调用消耗50元-500元/每月（不含）
用量级别2|api调用消耗500元-5000元/每月（不含）
用量级别3|api调用消耗5000元-10000元/每月（不含）
用量级别4|api调用消耗10000元-30000元/每月（不含）
用量级别5|api调用消耗30000元以上/每月
选择级别，查看各模型在对应级别下的限制
###用量等级为“免费”
模型分类|模型名称|并发数限制
通用模型|GLM-4-0520|5
通用模型|GLM-4-AllTools|5
通用模型|GLM-4-Air|5
通用模型|GLM-4-Long|5
通用模型|GLM-4-AirX|5
通用模型|GLM-4-Flash|5
通用模型|GLM-4V|5
图像大模型|CogView-3|5
视频模型|CogVideoX|1
向量模型|Embedding-2|5
通用模型|CharGLM-3|5
向量模型|Embedding-3|1
通用模型|GLM-4|5
通用模型|GLM-3-Turbo|5
代码模型|CodeGeeX-4|5
通用模型|Web-Search-Pro|1
###用量等级为“用量级别1”
模型分类|模型名称|并发数限制
通用模型|GLM-4-0520|10
通用模型|GLM-4-AllTools|10
通用模型|GLM-4-Air|50
通用模型|GLM-4-Long|10
通用模型|GLM-4-AirX|10
通用模型|GLM-4-Flash|10
通用模型|GLM-4V|10
图像大模型|CogView-3|10
视频模型|CogVideoX|2
向量模型|Embedding-2|10
通用模型|CharGLM-3|10
向量模型|Embedding-3|2
通用模型|GLM-4|10
通用模型|GLM-3-Turbo|50
代码模型|CodeGeeX-4|10
通用模型|Web-Search-Pro|2
###用量等级为“用量级别2”
模型分类|模型名称|并发数限制
通用模型|GLM-4-0520|15
通用模型|GLM-4-AllTools|15
通用模型|GLM-4-Air|70
通用模型|GLM-4-Long|15
通用模型|GLM-4-AirX|15
通用模型|GLM-4-Flash|50
通用模型|GLM-4V|20
图像大模型|CogView-3|15
视频模型|CogVideoX|3
向量模型|Embedding-2|20
通用模型|CharGLM-3|20
向量模型|Embedding-3|4
通用模型|GLM-4|20
通用模型|GLM-3-Turbo|70
代码模型|CodeGeeX-4|20
通用模型|Web-Search-Pro|3
###用量等级为“用量级别3”
模型分类|模型名称|并发数限制
通用模型|GLM-4-0520|20
通用模型|GLM-4-AllTools|20
通用模型|GLM-4-Air|150
通用模型|GLM-4-Long|20
通用模型|GLM-4-AirX|20
通用模型|GLM-4-Flash|100
通用模型|GLM-4V|30
图像大模型|CogView-3|20
视频模型|CogVideoX|4
向量模型|Embedding-2|30
通用模型|CharGLM-3|30
向量模型|Embedding-3|6
通用模型|GLM-4|30
通用模型|GLM-3-Turbo|150
代码模型|CodeGeeX-4|30
通用模型|Web-Search-Pro|4
###用量等级为“用量级别4”
模型分类|模型名称|并发数限制
通用模型|GLM-4-0520|25
通用模型|GLM-4-AllTools|25
通用模型|GLM-4-Air|300
通用模型|GLM-4-Long|25
通用模型|GLM-4-AirX|25
通用模型|GLM-4-Flash|200
通用模型|GLM-4V|50
图像大模型|CogView-3|30
视频模型|CogVideoX|5
向量模型|Embedding-2|40
通用模型|CharGLM-3|40
向量模型|Embedding-3|40
通用模型|GLM-4|100
通用模型|GLM-3-Turbo|300
代码模型|CodeGeeX-4|100
通用模型|Web-Search-Pro|5
###用量等级为“用量级别5”
模型分类|模型名称|并发数限制
通用模型|GLM-4-0520|30
通用模型|GLM-4-AllTools|30
通用模型|GLM-4-Air|1000
通用模型|GLM-4-Long|30
通用模型|GLM-4-AirX|30
通用模型|GLM-4-Flash|300
通用模型|GLM-4V|100
图像大模型|CogView-3|40
视频模型|CogVideoX|6
向量模型|Embedding-2|50
通用模型|CharGLM-3|50
向量模型|Embedding-3|10
通用模型|GLM-4|200
通用模型|GLM-3-Turbo|1000
代码模型|CodeGeeX-4|200
通用模型|Web-Search-Pro|6
##其他说明
我们会尽可能的保障用户的正常使用，若评估负载有风险时会根据用户用量等级对应并发数进行相关限制。
私有模型的速率限制情况和部署的实例数量相关，未部署时并发为0。
针对企业权益用户，智谱官方大模型的速率限制将收到并发数量保障，我们将择取企业权益与用量级别两项权益服务中并发数量最高者，为您提供速率限制服务

<end>
#企业权益
##概述
任何完成企业认证的开发者可享有智谱企业权益。
企业开发者通过消耗账户余额、实时计费调用模型API接口来获得积分、提升企业权益等级，凭等级享受模型计费折扣、智谱新产品体验、智谱平台服务等8类平台权益内容。
##获得企业权益积分
企业开发者可通过实时计费调用以下模型API，获得智谱企业权益积分（ 积分通过Tokens用量折算后，将仅取积分整数部分）：
模型|消耗Tokens用量|获得积分值
GLM-4-0520|1万 Tokens|2
GLM-4|1万 Tokens|1
GLM-4-Air|100万 Tokens|1
GLM-4-AirX|10万 Tokens|1
GLM-4-Flash|1000万 Tokens|1
GLM-4V|1万 Tokens|1
GLM-3-Turbo|100万 Tokens|1
CharGLM-3|20万 Tokens|3
Embedding-2|200万 Tokens|1
CogView-3|10 张|1万 Tokens|1
CodeGeeX-4|1000万 Tokens|1
GLM-4-AllTools|1万 Tokens|1
CogVideoX|2 视频|1
##企业权益等级计算规则
等级|积分范围
V0|[ 0 , 10000 )
V1|[ 10000 , 100000 )
V2|[ 100000 , 200000 )
V3|>= 200000
##企业权益等级的计算与生效
我们将在每月 1 日 00:00:00 开始统计您在上月累计获得的积分，根据您最近三个月的最高积分确定您在本月的企业权益等级。
您的企业权益等级将在每月 1 日 06:00:00 计算完成、更新并生效（计算过程中您将继续享受上月等级的各项权益）。在本月您将凭借企业权益等级，享有对应的各项权益。
为保障您及时获得更高的企业权益等级，如果您本月已获积分所对应的等级超过了本月已生效的等级，您将立即升级到更高等级、享受更佳企业权益。
##企业权益内容
当前各等级企业权益将享受以下服务，我们将陆续推出更多企业权益内容，敬请期待：
###企业权益等级“v0”
模型|计费折扣权益|最高并发保障|平台服务权益
GLM-4-0520|90%|20|智谱在线课程、官方技术支持
GLM-4|90%|20|智谱在线课程、官方技术支持
GLM-4-Air|90%|100|智谱在线课程、官方技术支持
GLM-4-AirX|90%|20|智谱在线课程、官方技术支持
GLM-4-Flash|90%|100|智谱在线课程、官方技术支持
GLM-4V|90%|20|智谱在线课程、官方技术支持
GLM-3-Turbo|90%|100|智谱在线课程、官方技术支持
CharGLM-3|90%|20|智谱在线课程、官方技术支持
Embedding-2|90%|20|智谱在线课程、官方技术支持
CogView-3|90%|20|智谱在线课程、官方技术支持
CogVideoX|90%|5|智谱在线课程、官方技术支持
###企业权益等级“v1”
模型|计费折扣权益|最高并发保障|平台服务权益
GLM-4-0520|80%|100|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
GLM-4|80%|100|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
GLM-4-Air|80%|1000|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
GLM-4-AirX|80%|40|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
GLM-4-Flash|80%|200|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
GLM-4V|80%|30|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
GLM-3-Turbo|80%|200|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
CharGLM-3|80%|50|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
Embedding-2|80%|100|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
CogView-3|80%|30|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
CogVideoX|80%|10|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权
###企业权益等级“v2”
模型|计费折扣权益|最高并发保障|平台服务权益
GLM-4-0520|70%|300|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4|70%|500|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4-Air|70%|3000|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4-AirX|70%|80|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4-Flash|70%|400|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4V|70%|50|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-3-Turbo|70%|700|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
CharGLM-3|70%|100|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
Embedding-2|70%|1000|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
CogView-3|70%|40|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
CogVideoX|70%|15|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
###企业权益等级“v3”
模型|计费折扣权益|最高并发保障|平台服务权益
GLM-4-0520|60%|600|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4|60%|1000|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4-Air|60%|5000|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4-AirX|60%|120|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4-Flash|60%|1500|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-4V|60%|100|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
GLM-3-Turbo|60%|1500|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
CharGLM-3|60%|200|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
Embedding-2|60%|2000|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
CogView-3|60%|40|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权
CogVideoX|60%|20|智谱在线课程、官方技术支持、新平台功能体验权、新模型服务体验权、智谱活动特权、行业活动特权

<end>
#提示工程
本指南分享了 GLM 语言模型和 CogView 图像生成模型获得更好生成结果的策略。可以组合使用提示词技巧以获得更好的生成效果。
##语言模型 Prompt 工程
###策略：编写清晰、具体的指令
为了获得最佳的回答，用户需要向 GLM 提供清晰、具体的指令。GLM 越能明确您的需求，提供的回答质量越高。
####技巧：定义 System Prompt
用于设定AI助手行为模式的工具，包括角色设定、语言风格、任务模式和针对特定问题的具体行为指导。
推荐示例：你擅长从文本中提取关键信息，精确、数据驱动，重点突出关键信息，根据用户提供的文本片段提取关键数据和事实，将提取的信息以清晰的 JSON格式呈现。
####技巧：提供具体的细节要求
在 Prompt 中添加要求模型输出内容的细节和背景信息。
推荐示例：我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。
####技巧：让 GLM 进行角色扮演
让 GLM 扮演角色、可以更准确地模仿该角色的行为和对话方式。
作为一个量子物理学家，解释量子物理学的基本原理，并简要介绍其在现代科技中的应用。
####技巧：使用分隔符标示不同的输入部分
推荐示例：请基于以下内容：
""" 要总结的文章内容"""
提炼核心观点和纲要
####技巧：思维链提示
要求模型分步骤解答问题，还要求其展示其推理过程的每个步骤。通过这种方式，可以减少不准确结果的可能性，并使用户更容易评估模型的响应。
推荐示例：作为一个 AI 助手，你的任务是帮助用户解决复杂的数学问题。对于每个问题，你需要首先独立解决它，然后比较和评估用户的答案，并最终提供反馈。在这个过程中，请展示你的每一步推理过程。我有一个数学问题需要帮助:"""问题是：一个农场有鸡和牛共 35 头，脚总共有 94 只。鸡和牛各有多少头？我的答案是鸡有 23 头，牛有 12 头"""。
####技巧：少样本学习
可以作为进行少样本学习的示例。这些样本可以用来引导模型模仿特定的行为和语言风格。
推荐示例：模仿这种风格
    ''' 1、三杯鸡在锅中欢跃，是岁月的篝火，是浪漫的乐章。
        2、炖排骨的滋味，是冬日的棉被，是乡土的回响。
        3、红烧勤鱼的鲜香，是海洋的密语，是大海的情书。'''
生成新的句子。
###策略：提供参考资料
引用外部资料能有效提升模型回答的准确性。这种做法特别适用于基于文档的问答系统，因为它有助于减少错误或虚构信息的生成，同时确保回答的时效性和准确性。当模型受到上下文长度限制，无法引用超长文本时，可以通过 Retrieval 工具来获取文档中的语义切片来实现。
推荐示例：作为AI助手，你的任务是帮助用户查找和理解特定公司的规章制度。在这个场景中，你将使用搜索结果来回答用户关于公司请假政策的查询。请根据搜索结果
"""具体的搜索结果"""
提供准确和详细的信息。
###策略:将复杂任务分解为简单的子任务
在处理需求复杂的任务时，错误率通常较高。为了提高效率和准确性，最佳做法是将这些复杂任务重构为一系列简单、连贯的子任务。这种方法中，每个子任务的完成成果依次成为下一任务的起点，形成一个高效的工作流。这样的任务流程简化有助于提升模型整体的处理质量和可靠性，特别是在面对需要综合大量数据和深入分析的复杂问题时。通过将复杂任务拆解，可以更加有效地利用模型的强大处理能力。
####技巧：意图理解和实体提取
要求大模型输出的内容要直接给到后端服务接口使用，所以大模型一定要按照固定格式输出格式，以便于接口解析模型输出内容，防止报错。
推荐示例：当你理解用户的预约会议室的意图时，提取相关的实体，并且以 Json 格式输出。
####技巧：总结上文关键信息
在长对话中，为了确保对话的连贯性和有效性，对之前的交流内容进行精炼和总结，可以保持对话的焦点、减少重复和混乱、加快模型处理速度。
####技巧：分段归纳长文档并逐步构建完整摘要
由于模型处理文本的上下文长度有限，它无法一次性总结超出特定长度的文本。例如，在总结一本长书时，我们可以采用分步骤的方法，逐章节进行总结。各章节的摘要可以组合在一起，再进行进一步的概括，形成更为精炼的总摘要。这个过程可以重复进行，直到整本书的内容被完整总结。如果后续章节的理解需要依赖于前面章节的信息，那么在当前部分的总结中附加之前内容的连贯摘要，能够显著提升模型的生成质量。
###策略：给于模型思考时间
####技巧：在模型给出最终结论之前，先引导它进行自我探索和推理。
在明确引导模型进行推理判断之前，让它先生成结果作为基准。例如，如果我们需要模型评估代码的质量，可以先让模型自行生成答案，随后再对其正确性进行评判。这样做不仅促使模型更加深入地理解任务，还可以提高最终结果的准确性和可靠性。
推荐示例：分析并评估以下 Python 代码片段"代码片段"的质量和功能。在生成你的回答之前，请先生成推荐示例代码，然后对代码的结构、清晰度以及其执行的功能进行评分。
####技巧：隐藏推理过程，只输出结果
在回答问题之前，模型有时需要进行深入的推理并将推理过程一并输出，可以引导模型只输出结果或者结构化信息以便于解析处理。
推荐示例：请计算函数 f(x) = x^2 在区间 [0, 1] 上的积分。仅提供最终的积分结果，无需展示推理过程。
###策略：使用外部工具增强模型能力
通过让模型访问工具的获取信息来弥补模型的缺陷和拓展功能，如通过 Function Call 访问外部的信息和执行操作，利用 Retrieval 工具访问知识库获取文档信息。
####技巧：通过 Function Call 访问外部 API
允许模型访问外部信息和执行操作，信息查询：如实时天气预报、股票市场动态，提供即时且准确的数据，执行操作：比如播放音乐、控制智能家居设备等。
推荐示例：使用外部 API 查询天气信息的功能。请根据用户的请求，调用相应的天气服务 API ，获取并展示最新的天气信息，包括温度、湿度、天气状况（如晴、雨等），风速和风向。例如，当用户询问‘北京今天的天气如何？’时，应调用API获取北京当前的天气数据，并以用户友好的方式展示结果。
####技巧：通过 Retrieval 访问智谱AI 开放平台的知识库
通过Retrieval方法访问智谱开放平台的知识库，用户可上传相关的知识到知识库，模型将基于用户的查询，，提取相关的语义切片，提供更加精准详细的信息。
推荐示例：作为 AI 助手，你的任务是帮助用户查找和理解特定公司的规章制度。用户询问关于公司的相关政策。你将通过搜索公司内部知识库或相关文档，找到最新的规定。根据搜索到的内容，提供关于相关的详细信息。请确保所提供信息的准确性和适用性，帮助用户完全理解公司的政策。

<end>
#Batch API
##概述
Batch API 适用于无需即时反馈并需使用大模型处理大量请求的场景。通过 Batch API，开发者可以通过文件提交大量任务，且价格降低50%、无并发限制，并在24小时内完成任务处理。典型应用场景包括：
文章分类：为大量文章、帖子或产品描述添加分类标签。
情感分析：评估客户反馈、社交媒体帖子和商品评价的情感倾向。
文档处理：为大量文档生成摘要、提炼关键信息或进行翻译。
信息提取：从文本数据中识别和抽取关键内容
本指南将通过实际场景示例，向您介绍如何使用 Batch API。
##检查 Batch 状态
Batch 任务将在 24 小时内处理完成，状态为 "completed" 表示任务已完成。
状态|描述
validating|文件正在验证中，Batch 任务未开始
failed|文件未通过验证
in_progress|文件已成功验证，Batch 任务正在进行中
finalizing|Batch 任务已完成，结果正在准备中
completed|Batch 任务已完成，结果已准备好
expired|Batch 任务未能在24小时内完成
cancelling|Batch 任务正在取消中
cancelled|Batch 任务已取消
##Batch API的并发限制是怎样的？
Batch API 的并发限制与现有的每个模型并发限制是分开的。BatchAPI 引入了两种新的限制：
单个 Batch 文件中包含最多 50,000 个请求且不超过 100M。
每个模型的 Batch 有最大排队限制。当达到请求队列上限时，请等待当前任务完成后再提交新任务。
模型|Batch 队列限制
GLM-4-Flash|100万次
GLM-4-Air|100万次
GLM-3-Turbo|20万次
Embedding-2|20万次
GLM-4-0520|5万次
GLM-4|5万次
Cogview-3|3千次
GLM-4V|1千次
##Batch 的过期如何处理？
如果Batch未能及时完成，该批次将被标记为过期状态；批次中未完成的请求将被取消。对于批次中已完成的请求，用户可以通过文件获取，并且需要支付这些请求消耗的费用。
##Batch 文件有哪些存储限制？
Batch 文件最多上传100个文件。系统只保留您的文件30天，过期后文件将自动删除，无法恢复。

<end>
#CogVideoX
CogVideoX是由智谱AI开发的视频生成大模型，具备强大的视频生成能力、只需输入文本或图片就可以轻松完成视频制作。本指南将教您如何系统地构建提示词，从而生成专业级别的视频作品。
立即生成请前往体验中心
接口调用请参阅接口文档
价格：标准价格为0.5元/次、购买资源包：体验包（9.9元/30次）、优享包（399元/1000次）、超大包（2499元/10000次）
##文生视频
提示词的精确度与细节水平直接影响视频内容的质量。采用结构化提示词可以极大提升视频内容的符合度和专业性。以下是构建提示词的关键组成部分：
提示词 = (镜头语言 +景别角度+ 光影) + 主体 (主体描述) + 主体运动 +场景 (场景描述) + (氛围)
镜头语言:通过镜头的各种应用以及镜头之间的衔接和切换来传达故事或信息，并创造出特定的视觉效果和情感氛围。如镜头平移，推近、拉远、升降拍摄、摇摄、跟随拍摄、手持拍摄、无人机航拍等;
景别角度：控制相机与被摄对象之间距离和角度，实现不同的视觉效果和情感表达。如大全景、中景、近景 、鸟瞰视角 、跟随视角、鱼眼效果等;
光影:光影是赋予摄影作品灵魂的关键元素，光影的运用可以使照片更具深度，更具情感，我们可以通过光影创造出富有层次感和情感表达力的作品。如自然光、丁达尔效应、柔和散射、硬光直射 、逆光剪影、三点布光等;
主体:主体是视频中的主要表现对象。如儿童、狮子、向日葵，汽车、城堡等;
主体描述:对主体外貌细节和肢体姿态等的描述，如人物的服饰、动物的毛色、植物的颜色、物体的状态和建筑的风格;
主体运动:对主体运动状态的描述，包括静止和运动等，运动状态不宜过于复杂，符合6s视频内可以展现的画面即可，
场景: 场景是主体所处的环境，包括前景、背景等;
场景描述:对主体所处环境的细节描述。如都市环境、乡村风光、工业区等;
氛围:对预期视频画面的氛围描述。如喧嚣繁忙、悬疑惊悚、宁静舒适等;
其它技巧
关键词重复：在提示的不同部分重复或强化关键词有助于提高输出的一致性。如:摄像机以超高速镜头快速飞过森林;
聚焦内容：提示词应集中在视频中应有的内容上。如：冷清的街道，而不是“没有人的街道”;
使用智能体：使用提示词智能体帮助你生成专业提示词;
##图生视频
CogVideoX 可以将用户提供的静态图像转化为6秒的动态视频。为达到最佳效果，推荐上传比例为3:2的图片，并且文件格式为 PNG 或 JPEG，文件大小不超过5MB。提示词建议使用“主体（背景）+ 运动描述”的表达方式。

<end>
#模型微调
##概览
什么是模型微调
模型微调是指通过微调工具，加入企业独有的场景数据，对平台的基础模型进行微调。它可以帮助您快速定制出更符合您业务场景需求的专属大模型。它的优势在于对基础模型进行少量调整，满足特定的需求。相比训练新模型高效且低成本。
什么场景下适用微调
您可以先尝试调整提示词或者使用一些工具如函数调用 、检索功能来获得更好的效果。若您仍认为目前的基础模型及相关工具无法提供满意答案或处理复杂推理任务时，可以使用微调获得更好的效果。
微调可改善效果的典型场景：
需要采用特定的风格、语调
需要处理复杂的任务
需要提高输出的可靠性
难以通过 Prompt 说明的新任务
微调方式有哪些
1. LoRA微调
含义：通过在模型的现有权重矩阵中添加低秩矩阵来调整模型，可以在增加少量计算负担的情况下有效调整模型。
优点：
只需要添加少量参数，参数效率高；
资源利用少且训练周期较短
2. 全参微调
含义：对预训练模型的所有参数进行调整获得新模型。
优点：
可以对模型进行全面的调整，使其更好地适应新任务；
在有足够数据和计算资源的情况下，更可能达到更优的性能。
哪些模型可以微调
glm-4-flash（LoRA微调、全参微调，所有用户可用）
glm-4-9b（LoRA微调、全参微调，所有用户可用）
chatglm3-6b（LoRA微调，所有用户可用）
chatglm3-6b 的LoRA微调训练及微调模型推理可通过购买 开发Pro版权益 进行体验。
微调的步骤
通常情况下，完成模型微调涉及以下步骤:
1. 准备并上传训练数据
2. 训练新的微调模型
3. 部署并使用微调模型（LoRA微调支持公有池推理，可以不进行部署操作）
4. 评估结果，如有需要返回到步骤1
##准备训练数据
微调训练数据通常由一批包含输入和期望输出的数据构成，每条训练数据由单个输入（Prompt）以及对应的期望输出组成。目前仅支持以 json 格式的文件上传训练数据。
数据集要求
通常情况下，提供更多的高质量训练数据，微调效果越好。反之，如果训练数据中存在问题、瑕疵，将对微调效果产生一定的负面影响。
更多的高质量数据
为了更好的微调模型，您需要至少提供数百条高质量的训练数据；最好由人工对数据进行过严谨的审查，以保证数据质量和微调效果。增加高质量的训练数据是提高微调效果最佳最可靠的方法。
根据训练目标调控数据分布
在您构造训练数据时，需注意根据真实业务场景中的训练目标，构造和调整各类细分任务场景的训练数据量分布，尽量覆盖业务场景所有可能的数据样本。如果您的训练目标是同时强化文本分类、信息提取、文本生成的效果，您需要在训练数据中分别提供适用于这几类任务的足量训练数据。
避免有害数据
为保证您的数据隐私性，平台不会对您的数据进行审查，请您务必检查并确保数据中不包含有害信息，包括不限于色情、暴恐违禁、政治敏感、低俗辱骂、隐私信息等有害内容。使用有害数据微调模型，可能导致微调模型容易生成有害内容，使得模型推理结果的敏感信息校验通过率变低。甚至，过于严重的有害模型将无法通过平台或有关部门的内容合规要求，将被平台强制下架。
数据集格式
新版数据示例（仅 glm-4-flash、glm-4-9b、chatglm3-6b 支持该版本数据，您可以通过api接口上传或者在模型微调训练页面进行操作）。
按示例中的格式准备数据集，json 格式，每行一条，存储到文件中并调用文件管理接口上传文件：
{"messages": [{"role": "system", "content": "你是一位乐于助人，知识渊博的全能AI助手。"},{"role": "user", "content": "请介绍一下AlphaGo的基本原理。"}, {"role": "assistant", "content": "AlphaGo利用深度神经网络与树搜索算法相结合,通过对弈数据进行训练,逐步提升游戏水平,能够对围棋局面进行判断并选择最佳落子位置。"}]}
{"messages": [{"role": "system", "content": "你是一位乐于助人，知识渊博的全能AI助手。"},{"role": "user", "content": "请列举一些健康饮食的重要原则。"}, {"role": "assistant", "content": "健康饮食的重要原则包括:膳食应营养均衡,合理摄入各种营养素;多吃新鲜蔬果,适量饮水;少吃糖、油、盐,忌吃过量快餐;养成规律生活作息习惯,适量运动。"}]}
{"messages": [{"role": "system", "content": "你是一位乐于助人，知识渊博的全能AI助手。"},{"role": "user", "content": "请给出一些改善睡眠质量的建议。"}, {"role": "assistant", "content": "改善睡眠质量的建议包括:保证睡眠时间,避免睡眠不足;睡前放松身心,远离刺激;养成规律作息时间,不要频繁熬夜;适量运动,但不要运动过度;睡前可以喝一杯热牛奶等温和饮料。"}]}
若您不需要上传system则将system段落删除即可，示例如下：
{"messages": [{"role": "user", "content": "请介绍一下AlphaGo的基本原理。"}, {"role": "assistant", "content": "AlphaGo利用深度神经网络与树搜索算法相结合,通过对弈数据进行训练,逐步提升游戏水平,能够对围棋局面进行判断并选择最佳落子位置。"}]}
##创建微调任务
如您已经按照上述说明准备好了优质的训练数据，接下来您可以开始创建微调任务，训练模型。
您可通过页面操作微调任务创建，入口如下：
创建微调任务入口1：模型广场 点击模型卡片内微调按键
创建微调任务入口2：微调任务 「+创建微调任务」按键
创建微调任务时，您可以根据需要为新模型命名，并指定模型编码的后缀。其他参数设置请参考微调 API 接口文档。创建微调任务后需要几分钟至几小时完成训练，具体取决于模型规模和数据集大小。训练完成后我们会通过短信通知您。
##部署微调模型
模型完成训练后可进行部署，部署入口如下：
入口1：模型广场 点击模型卡片内部署按键
入口2：私有实例 「+创建部署任务」按键
##使用微调模型
模型完成微调训练后，您可以通过体验中心或 API 使用该模型。 通过API请求时，您可以将您命名的新模型编码作为 model 参数的值来传参发出请求。
###调用示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
response = client.chat.completions.create(
    model="chatglm3-6b-1001",  # 填写需要调用的模型名称
    messages=[
        {"role": "system", "content": "你是一个人工智能助手，你叫叫chatGLM"},
        {"role": "user", "content": "你好！你叫什么名字"},
    ],
    stream=True,
)
for chunk in response:
    print(chunk.choices[0].delta)

<end>
#GLM-4-AllTools
##介绍
GLM-4-AllTools 是专门为支持智能体和相关任务而进一步优化的模型版本。它能够自主理解用户的意图，规划复杂的指令，并能够调用一个或多个工具（例如网络浏览器、代码解释器和文本生图像）以完成复杂的任务。
##模型能力
GLM-4-AllTools 在解决数学问题的Python解释器、信息检索浏览器方面的性能与ChatGPT-4 相当。
工具类型|对比项|GLM-4-AllTools|GPT-4
Python Interpreter|GSM8K|91.59|92.72
Python Interpreter|MATH|63.60|65.00
Python Interpreter|Math23K|88.50|88.40
Browser|Information Seeking|78.08|67.12
##工具能力
GLM-4-AllTools 模型支持了多种工具，并且持续更新中。
工具|介绍
智能编程助手|智能编程助手（Code Interpreter）能够准确理解自然语言描述的编程需求，自动生成代码片段来解决实际问题。
安全代码沙盒|安全代码沙盒（Sandbox）提供了一个安全的执行和测试环境，可以在其中模拟真实环境中的代码执行结果。
实时联网搜索|实时联网搜索（Web Search）能够在互联网上实时搜索信息，基于全网的搜索结果进行分析，提供更实时更全面的答案。
绘图设计工具|绘图设计工具（Drawing tool）根据文本描述能够生成高质量、高分辨率的图片，支持多种图像风格，满足各类绘图需求。
函数调用能力|函数调用能力（Function Call）允许AI助手调用外部函数，以执行特定任务或获取必要数据，实现与外部系统的无缝集成。
##使用方式
GLM-4-AllTools模型仅支持 SSE 流式输出，请求示例如下，具体请参考接口文档。
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"帮我查询2018年至2024年，每年五一假期全国旅游出行数据，并绘制成柱状图展示数据趋势。"
                }
            ]
        }
    ],
    stream=True,
    tools=[
    {
        "type": "function",
        "function": {
            "name": "get_tourist_data_by_year",
            "description": "用于查询每一年的全国出行数据，输入年份范围(from_year,to_year)，返回对应的出行数据，包括总出行人次、分交通方式的人次等。",
            "parameters": {
                "type": "object",
                "properties": {
                    "type": {
                        "description": "交通方式，默认为by_all，火车=by_train，飞机=by_plane，自驾=by_car",
                        "type": "string"
                    },
                    "from_year": {
                        "description": "开始年份，格式为yyyy",
                        "type": "string"
                    },
                    "to_year": {
                        "description": "结束年份，格式为yyyy",
                        "type": "string"
                    }
                },
                "required": ["from_year","to_year"]
            }
        }
      },
      {
        "type": "code_interpreter"
      }
    ]
)

for chunk in response:
    print(chunk)


<end>
#函数调用
##介绍
ChatGLM 的函数调用功能可以增强模型推理效果或进行其他外部操作，包括信息检索、数据库操作、知识图谱搜索与推理、操作系统、触发外部操作等工具调用场景。
本教程将介绍如何使用 ChatGLM 的函数调用功能，实现对模型与外部函数库的连接。
tools 是内容生成 API 中的可选参数，用于向模型提供函数定义。通过此参数，模型能够生成符合用户所提供规范的函数参数。请注意，API 实际上不会执行任何函数调用，仅返回调用函数所需要的参数。开发者可以利用模型输出的参数在应用中执行函数调用。
本教程包括以下3个部分:
1. 如何使用 Chat Completion 接口向模型描述外部函数。
2. 如何与模型交互，触发模型对函数的调用。
3. 如何使用模型生成的结果调用外部函数。
##如何描述外部函数
假设我们要创建一个具备查询航班功能的聊天机器人。我们定义如下两个外部函数供模型选择调用：
1. 查询两地之间某日航班号函数：get_flight_number(departure: str, destination: str, date: str)
2. 查询某航班某日票价函数：get_ticket_price(flight_number: str, date: str)
###描述函数功能
为了向模型描述外部函数库，需要向 tools 字段传入可以调用的函数列表。参数如下表：
参数名称|类型|是否必填|参数说明
type|String|是|设置为function
function|Object|是
      name|String|是|函数名称
      description|String|是|用于描述函数功能。模型会根据这段描述决定函数调用方式。
      parameters|Object|是|parameters字段需要传入一个 Json Schema 对象，以准确地定义函数所接受的参数。
示例：
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_flight_number",
            "description": "根据始发地、目的地和日期，查询对应日期的航班号",
            "parameters": {
                ......
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_ticket_price",
            "description": "查询某航班在某日的票价",
            "parameters": {
                ......
            },
        }
    },
]
###编写函数参数列表的 JSON 描述
为了准确定义函数的参数列表，在编写参数列表的 JSON Schema 时建议最少包含以下字段：
description ：说明函数方法的用途。
type ：定义 JSON 数据的数据类型约束。
properties：一个Object，其中的每个属性代表要定义的 JSON 数据中的一个键。
required：指定哪些属性在数据中必须被包含。
enum：如果一个属性是枚举类型，则此字段应当设置为枚举值的数组。
则完整的tools字段设置为：
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_flight_number",
            "description": "根据始发地、目的地和日期，查询对应日期的航班号",
            "parameters": {
                "type": "object",
                "properties": {
                    "departure": {
                        "description": "出发地",
                        "type": "string"
                    },
                    "destination": {
                        "description": "目的地",
                        "type": "string"
                    },
                    "date": {
                        "description": "日期",
                        "type": "string",
                    }
                },
                "required": [ "departure", "destination", "date" ]
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_ticket_price",
            "description": "查询某航班在某日的票价",
            "parameters": {
                "type": "object",
                "properties": {
                    "flight_number": {
                        "description": "航班号",
                        "type": "string"
                    },
                    "date": {
                        "description": "日期",
                        "type": "string",
                    }
                },
                "required": [ "flight_number", "date"]
            },
        }
    },
]
###函数调用选择
在 tools 参数中，如果填写了 functions 参数，则默认情况下模型将决定何时适合使用其中一个函数。 如果要控制模型如何选择函数调用，需要设置 tool_choice 参数。参数默认值为auto，此时模型根据上下文信息自行选择是否返回函数调用。将其设置为 {"name": "your_function_name"} 时，可以强制 API 返回特定函数的调用。还可以通过将 tool_choice 参数设置为 "none" 来强制 API 不返回任何函数的调用。目前函数调用仅支持 auto 模式。

<end>
#内容安全
##介绍
智谱AI致力于做到人工智能的安全可控、可审计、可监督、可追溯和可信赖。为此，我们内置了安全审核机制，旨在减少模型应用中违法及不良信息（包括但不限于违反法律法规、危害国家安全、恶意营销、涉黄、谩骂、暴恐违禁以及其它不良内容）的出现。当我们的内置安全审核机制识别到违法及不良信息时，将提供相应的提示信息或进行拦截处置，例如通过输入拦截、输出限制和终止内容生成。
##用户输入审核
当API检测到用户输入中含有敏感内容时，系统会返回错误码（1301），该情况下，建议开发者采取措施，对用户使用行为进行正面引导，以确保内容的合规性和适当性。
错误码|错误信息
1301|系统检测到输入或生成内容可能包含违法及不良内容，请您避免输入易产生违法及不良内容的提示语，感谢您的配合
##模型输出审核
###流式输出
在模型流式输出生成内容的过程中，我们会分批对模型生成内容进行检测，当检测到违法及不良信息时，API（V3）返回错误码（1301），API（V4)返回停止词"finish_reason":"sensitive"。开发者识别到相关信息，应及时采取终止生成、撤回、修改、清屏、重启等措施删除生成内容，并确保不将含有违法及不良信息的内容传递给模型继续生成，避免其造成负面影响。
###同步输出
当API检测到模型输出内容中含有违法及不良信息时，系统会向开发者返回错误码（1301），不同步生成结果。建议开发者采取措施，对用户进行正面引导，以确保内容的合规性和适当性。
##终端用户管理
在请求中发送终端用户 ID 可以协助平台对终端用户的违规行为、生成违法及不良信息或其他滥用行为进行干预。当我们检测到您的终端用户存在违规、生成违法及不良信息或其他滥用行为时，平台将会对终端用户请求进行封禁处理，避免您的企业账号因终端用户的违规或滥用行为受到影响。
ID 是唯一标识终端用户的字符串，用户ID长度至少为6个字符，但不超过128个字符，您可以通过在API 请求中上传终端用户 ID，如下所示：
{
    "model": "glm-3-turbo",
    "messages": [
     {"role": "user", "content": "作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan"},
     {"role": "assistant", "content": "当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息"},
     {"role": "user", "content": "智谱AI开放平台"},
    ],
    "stream": "true",
    "user_id": "user_123456",
    }
}
##安全测试申请
如果您需要进行安全相关的测试，请联系商务经理、致电（400-6883-991）进行申请，避免您的企业账号出现违规或滥用等问题。
##违法及不良内容反馈
智谱AI高度重视生成式人工智能服务的安全性。如果您在开发过程中发现API存在任何安全问题，请联系企业微信客服或者致电（400-6883-991）告知我们。我们非常感谢您的贡献和支持。

<end>
#通用搜索
##介绍
通用搜索web_search工具通过网络搜索获取信息，以增强语言模型输出的质量和时效性。
##用法
###启用与禁用 web_search
语言模型于2024年8月9日起默认关闭web_search 工具。当开启网络搜索时，搜索结果将作为背景知识输入给模型，每次调用将消耗约 1000 tokens。您可以通过以下方式手动开启此功能:
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="您的APIKey")

tools = [{
    "type": "web_search",
    "web_search": {
        "enable": True # 禁用：False，启用：True，默认为 True。
    }
}]

messages = [{
    "role": "user",
    "content": "中国 2024 年一季度的GDP是多少 "
}]

response = client.chat.completions.create(
    model="glm-4",
    messages=messages,
    tools=tools
)
print(response.choices[0].message)
###自定义搜索内容
使用search_query参数可以自定义搜索内容，提升搜索结果的相关性和精确度。 如果不传search_query参数，系统将根据用户的消息自动进行网页检索。
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="您的APIKey")

tools = [{
    "type": "web_search",
    "web_search": {
        "enable": True,
        "search_query": "自定义搜索的关键词"
    }
}]

messages = [{
    "role": "user",
    "content": "中国 2024 年一季度的GDP是多少"
}]

response = client.chat.completions.create(
    model="glm-4",
    messages=messages,
    tools=tools
)
print(response.choices[0].message)
###检索指定网页
访问指定网址以检索网页内容，将作为背景知识输入给模型。注意：由于某些网站的访问限制，可能无法读取页面内容。
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="") # 请填写您自己的APIKey

messages = [
    {
        "role": "user",
        "content": "总结文中的内容：https://news.sciencenet.cn/htmlnews/2024/3/519107.shtm"
    }
]
response = client.chat.completions.create(
    model="glm-4", # 填写需要调用的模型名称
    messages=messages,
)
print(response.choices[0].message)
###返回搜索来源
启用search_result参数允许用户获取详细的网页搜索来源信息，包括来源网站的图标、标题、链接、来源名称以及引用的文本内容。
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="您的APIKey")

tools = [{
    "type": "web_search",
    "web_search": {
        "enable": True,
        "search_result": True       # 禁用False，启用：True，默认为禁用
    }
}]

messages = [{
    "role": "user",
    "content": "最新的AI发展趋势"
}]

response = client.chat.completions.create(
    model="glm-4",
    messages=messages,
    tools=tools
)
print(response)
###使用 Prompt 添加搜索角标
使用search_prompt允许用户自定义模型引用搜索结果的方式，prompt 必须包含{search_result}表示搜索结果，例如：
search_prompt = """

# 以下是来自互联网的信息：
{search_result}

# 当前日期: 2024-XX-XX

# 要求：
根据最新发布的信息回答用户问题，当回答引用了参考信息时，必须在句末使用对应的[ref_序号]来标明参考信息来源。

"""
启用search_result参数允许用户获取详细的网页搜索来源信息，返回角标序号'refer': 'ref_序号'，可用于关联模型回答所引用的搜索角标。
from zhipuai import ZhipuAI

search_prompt = """

# 以下是来自互联网的信息：
{search_result}

# 当前日期: 2024-06-06

# 要求：
根据最新发布的信息回答用户问题，当回答引用了参考信息时，必须在句末使用对应的[ref_序号]来标明参考信息来源。

"""

client = ZhipuAI(api_key=zhipu_api_key) # 填写您自己的APIKey

tools = [{
      "type": "web_search",
      "web_search": {
          "enable": True,
          "search_query": "最近国内有哪些新闻",
          "search_result": True,
          "search_prompt": search_prompt
      }
  }]


response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=[
        {"role": "user", "content": "问：最近国内有哪些新闻，答："}
    ],
    top_p=0.7,
    temperature=0.1,
    tools=tools
)

print(response)
<end>
介绍
为方便用户使用，我们提供了 SDK 和原生 HTTP 来实现模型 API 的调用，建议您使用 SDK进行调用以获得更好的编程体验。

SDK 安装说明
安装 Python SDK
Python SDK 地址： https://github.com/zhipuai/zhipuai-sdk-python-v4
首先请通过如下方式进行安装 SDK 包：
pip install zhipuai
我们升级了最新的模型 GLM-4、GLM-3-Turbo，支持了System Prompt、FunctionCall、Retrieval、Web_Search等新功能。 使用以上新功能需升级最新版本的 Python SDK。如您已安装老版本SDK，请您更新到最新版SDK。
pip install --upgrade zhipuai

安装 Java SDK
Java SDK 地址： https://github.com/zhipuai/zhipuai-sdk-java-v4
如下方式，将SDK的依赖项加入到Maven项目：
<dependency>
    <groupId>cn.bigmodel.openapi</groupId>
    <artifactId>oapi-java-sdk</artifactId>
    <version>release-V4-2.0.2</version>
</dependency>

SDK 用户鉴权
我们的所有 API 使用 API Key 进行身份验证。您可以访问智谱AI开放平台 API Keys 页面 查找您将在请求中使用的 API Key。

提示
请注意保护您的密钥信息！不要与他人共享或在任何客户端代码（浏览器、应用程序）中公开您的 APIKey。如您的 API Key 存在泄露风险，您可以通过删除该密钥来保护您的账户安全。

本版本对鉴权方式进行了升级，历史已接入平台的用户可继续沿用老版本的鉴权方式。新版本的鉴权方法可参考以下详细描述：

Python SDK 创建 Client
我们已经将接口鉴权封装到 SDK，您只需按照 SDK 调用示例填写 API Key 即可，示例如下
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
  model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {
            "role": "user",
            "content": "你好！你叫什么名字"},
    ],
    stream=True,
    )

for chunk in response:
    print(chunk.choices[0].delta)

Java SDK 创建 Client
类似的，使用 Java SDK 您替换自己的 ApiSecretKey 即可，示例如下：
ClientV4 client = new ClientV4.Builder("{Your ApiSecretKey}").build();

传输层默认使用 okhttpclient，如果需要修改为其他 http client，可以如下指定（注意 apache不支持sse调用）：
ClientV4 client = new ClientV4.Builder("{Your ApiSecretKey}")
                  .httpTransport(new ApacheHttpClientTransport())
                  .build();

SDK 代码示例
平台提供了同步、异步、SSE 三种调用方式（调用方式取决于具体模型的支持情况）

同步调用
调用后即可一次性获得最终结果，Python 代码示例如下：
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {
            "role": "user",
            "content": "作为一名营销专家，请为我的产品创作一个吸引人的slogan"},
        {
            "role": "assistant",
            "content": "当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息"},
        {
            "role": "user",
            "content": "智谱AI开放平台"},
        {
            "role": "assistant",
            "content": "智启未来，谱绘无限一智谱AI，让创新触手可及!"},
        {
            "role": "user",
            "content": "创造一个更精准、吸引人的slogan"}
    ],
)

print(response.choices[0].message)

Java 代码示例如下：
/*
* 同步调用
*/
private static void testInvoke() {
   List<ChatMessage> messages = new ArrayList<>();
    ChatMessage chatMessage = new ChatMessage(ChatMessageRole.USER.value(), "作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan");
   messages.add(chatMessage);
   String requestId = String.format(requestIdTemplate, System.currentTimeMillis());

   ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
           .model(Constants.ModelChatGLM4)
           .stream(Boolean.FALSE)
           .invokeMethod(Constants.invokeMethod)
           .messages(messages)
           .requestId(requestId)
           .build();
   ModelApiResponse invokeModelApiResp = client.invokeModelApi(chatCompletionRequest);
   try {
       System.out.println("model output:" + mapper.writeValueAsString(invokeModelApiResp));
   } catch (JsonProcessingException e) {
       e.printStackTrace();
   }
}

异步调用
调用后会立即返回一个任务 ID，然后用任务ID查询调用结果（根据模型和参数的不同，通常需要等待10-30秒才能得到最终结果），Python代码示例如下：
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.asyncCompletions.create(
    model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {
            "role": "user",
            "content": "请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。"
        }
    ],
)

print(response)

Java 代码示例如下：
/*
* 异步调用
*/
private static String testAsyncInvoke() {
   List<ChatMessage> messages = new ArrayList<>();
    ChatMessage chatMessage = new ChatMessage(ChatMessageRole.USER.value(), "作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan");
   messages.add(chatMessage);
   String requestId = String.format(requestIdTemplate, System.currentTimeMillis());

   ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
           .model(Constants.ModelChatGLM4)
           .stream(Boolean.FALSE)
           .invokeMethod(Constants.invokeMethodAsync)
           .messages(messages)
           .requestId(requestId)
           .build();
   ModelApiResponse invokeModelApiResp = client.invokeModelApi(chatCompletionRequest);
   System.out.println("model output:" + JSON.toJSONString(invokeModelApiResp));
   return invokeModelApiResp.getData().getTaskId();
}

SSE 调用
调用后可以流式的实时获取到结果直到结束，Python 代码示例如下：
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {
            "role": "system",
            "content": "你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。"},
        {
            "role": "user",
            "content": "我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。"},
    ],
    stream=True,
)

for chunk in response:
    print(chunk.choices[0].delta)

Java 代码示例如下：
/*
* sse调用
*/
private static void testSseInvoke() {
   List<ChatMessage> messages = new ArrayList<>();
    ChatMessage chatMessage = new ChatMessage(ChatMessageRole.USER.value(), "作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan");
   messages.add(chatMessage);
   String requestId = String.format(requestIdTemplate, System.currentTimeMillis());

   ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
           .model(Constants.ModelChatGLM4)
           .stream(Boolean.TRUE)
           .messages(messages)
           .requestId(requestId)
           .build();
   ModelApiResponse sseModelApiResp = client.invokeModelApi(chatCompletionRequest);
   if (sseModelApiResp.isSuccess()) {
       AtomicBoolean isFirst = new AtomicBoolean(true);
       ChatMessageAccumulator chatMessageAccumulator = mapStreamToAccumulator(sseModelApiResp.getFlowable())
               .doOnNext(accumulator -> {
                   if (isFirst.getAndSet(false)) {
                       System.out.print("Response: ");
                   }
                   if (accumulator.getDelta() != null && accumulator.getDelta().getTool_calls() != null) {
                       String jsonString = mapper.writeValueAsString(accumulator.getDelta().getTool_calls());
                       System.out.println("tool_calls: " + jsonString);
                   }
                   if (accumulator.getDelta() != null && accumulator.getDelta().getContent() != null) {
                       System.out.print(accumulator.getDelta().getContent());
                   }
               })
               .doOnComplete(System.out::println)
               .lastElement()
               .blockingGet();

       Choice choice = new Choice(chatMessageAccumulator.getChoice().getFinishReason(), 0L, chatMessageAccumulator.getDelta());
       List<Choice> choices = new ArrayList<>();
       choices.add(choice);
       ModelData data = new ModelData();
       data.setChoices(choices);
       data.setUsage(chatMessageAccumulator.getUsage());
       data.setId(chatMessageAccumulator.getId());
       data.setCreated(chatMessageAccumulator.getCreated());
       data.setRequestId(chatCompletionRequest.getRequestId());
       sseModelApiResp.setFlowable(null);
       sseModelApiResp.setData(data);
   }
   System.out.println("model output:" + JSON.toJSONString(sseModelApiResp));
}
<end>
HTTP 调用指南
HTTP 请求参数
模型服务支持标准的 HTTP 调用
请求头
Content-Type：application/json
Authorization：支持API Key 和 token 两种鉴权方式
请求地址和参数
见各个模型接口的说明

HTTP 用户鉴权
在调用模型接口时，支持两种鉴权方式：
传 API Key 进行认证
传鉴权 token 进行认证
当前平台鉴权 token 由用户端生成，鉴权 token 生成采用标准 JWT 中提供的创建方法生成（详细参考：https://jwt.io/introduction）。

获取您的 API Key
登录到智谱AI开放平台 API Keys 页面 获取最新版生成的用户 API Key
新版机制中平台颁发的 API Key 同时包含 “用户标识 id” 和 “签名密钥 secret”，即格式为 {id}.{secret}

使用 API Key 进行请求
用户需要将 API Key 放入 HTTP 的 Authorization header 头中。
Example：curl请求中的apikey参数示例
curl --location 'https://open.bigmodel.cn/api/paas/v4/chat/completions' \
--header 'Authorization: Bearer <你的apikey>' \
--header 'Content-Type: application/json' \
--data '{"model": "glm-4", "messages": [{"role": "user", "content": "你好"}]}'
使用 JWT 组装 Token 后进行请求
用户端需引入对应 JWT 相关工具类，并按以下方式组装 JWT 中 header、payload 部分
1、header 具体示例
{"alg":"HS256","sign_type":"SIGN"}
alg : 属性表示签名使用的算法，默认为 HMAC SHA256（写为HS256）
sign_type : 属性表示令牌的类型，JWT 令牌统一写为 SIGN 。
2、payload 具体示例
{"api_key":{ApiKey.id},"exp":1682503829130, "timestamp":1682503820130}
api_key : 属性表示用户标识 id，即用户API Key的{id}部分
exp : 属性表示生成的JWT的过期时间，客户端控制，单位为毫秒
timestamp : 属性表示当前时间戳，单位为毫秒
Example: Python 语言中的鉴权 token 组装过程
import time
import jwt

def generate_token(apikey: str, exp_seconds: int):
    try:
        id, secret = apikey.split(".")
    except Exception as e:
        raise Exception("invalid apikey", e)

    payload = {
        "api_key": id,
        "exp": int(round(time.time() * 1000)) + exp_seconds * 1000,
        "timestamp": int(round(time.time() * 1000)),
    }

    return jwt.encode(
        payload,
        secret,
        algorithm="HS256",
        headers={"alg": "HS256", "sign_type": "SIGN"},
    )

3、将鉴权 token 放入 HTTP 请求的 header 中
用户需要将生成的鉴权 token 放入 HTTP 的 Authorization header 头中：
Authorization: 鉴权token
Example：curl请求中的token参数示例
curl --location 'https://open.bigmodel.cn/api/paas/v4/chat/completions' \
--header 'Authorization: Bearer <你的token>' \
--header 'Content-Type: application/json' \
--data '{"model": "glm-4", "messages": [{"role": "user", "content": "你好"}]}'

<end>
第三方框架
OpenAI SDK 使用
安装 OpenAI SDK
需要确保使用的 Python 版本至少为 3.7.1， OpenAI SDK 版本不低于 1.0.0
pip install --upgrade 'openai>=1.0'

使用 API Key 鉴权
创建 Client，使用您在开放平台的API Key 鉴权。示例如下：
from openai import OpenAI
client = OpenAI(
    api_key="your api key",
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)

对话代码示例
以下代码是GLM-4的对话调用示例：
from openai import OpenAI
client = OpenAI(
    api_key="your zhipuai api key",
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
completion = client.chat.completions.create(
    model="glm-4",
    messages=[
        {"role": "system", "content": "你是一个聪明且富有创造力的小说作家"},
        {"role": "user", "content": "请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。"}
    ],
    top_p=0.7,
    temperature=0.9
)
print(completion.choices[0].message)

Langchain SDK 使用
安装 Langchain SDK
首先需要安装 Langchain 和 对应的依赖包，请确保 langchain_community 的版本在 0.0.32 以上。
pip install langchain langchainhub httpx_sse

使用 Langchain ChatOpenAI
Langchain 的ChatOpenAI类是对 OpenAI SDK 的封装，可以更方便调用。这里展示了如何使用 ChatOpenAI 类来调用 GLM-4 模型。
import os
from langchain_openai import ChatOpenAI
from langchain.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory

llm = ChatOpenAI(
    temperature=0.95,
    model="glm-4",
    openai_api_key="your zhipuai api key",
    openai_api_base="https://open.bigmodel.cn/api/paas/v4/"
)
prompt = ChatPromptTemplate(
    messages=[
        SystemMessagePromptTemplate.from_template(
            "You are a nice chatbot having a conversation with a human."
        ),
        MessagesPlaceholder(variable_name="chat_history"),
        HumanMessagePromptTemplate.from_template("{question}")
    ]
)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
conversation = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True,
    memory=memory
)
conversation.invoke({"question": "tell me a joke"})

使用 LangChain AgentExecutor
同时，GLM-4也能很好的接入到 Langchain 的 AgentExecutor 中， 这里展示了如何使用 AgentExecutor 来调用GLM-4 模型。
from langchain import hub
from langchain.agents import AgentExecutor, create_react_agent
from langchain_community.tools.tavily_search import TavilySearchResults

os.environ["TAVILY_API_KEY"] = "your tavily api key"
tools = [TavilySearchResults(max_results=2)]
prompt = hub.pull("hwchase17/react")

# Choose the LLM to use
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
agent_executor.invoke({"input": "what is LangChain?"})
<end>
GLM-4 系列
提供了多款模型，适用于各种应用场景。查看GLM-4系列模型比较，选择最适合的模型。
模型编码：glm-4-plus New、glm-4-0520、glm-4 、glm-4-air、glm-4-airx、glm-4-long Beta、glm-4-flash

sse调用
接口请求
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/chat/completions
调用方式：同步调用，等待模型执行完成并返回最终结果或 SSE 调用
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON 或标准 Stream Event
接口请求类型：POST
开发语言：任意可发起 HTTP 请求的开发语言

请求参数
参数名称：model
类型：String
是否必填：是
参数说明：所要调用的模型编码

参数名称：messages
类型：List<Object>
是否必填：是
参数说明：调用语言模型时，将当前对话信息列表作为提示输入给模型，按照 {"role": "user", "content": "你好"} 的json 数组形式进行传参；可能的消息类型包括 System message、User message、Assistant message 和 Tool message。

参数名称：request_id
类型：String
是否必填：否
参数说明：由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。

参数名称：do_sample
类型：Boolean
是否必填：否
参数说明：do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。

参数名称：stream
类型：Boolean
是否必填：否
参数说明：使用同步调用时，此参数应当设置为 false 或者省略。表示模型生成完所有内容后一次性返回所有内容。默认值为 false。如果设置为 true，模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条data: [DONE]消息。注意：在模型流式输出生成内容的过程中，我们会分批对模型生成内容进行检测，当检测到违法及不良信息时，API会返回错误码（1301）。开发者识别到错误码（1301），应及时采取（清屏、重启对话）等措施删除生成内容，并确保不将含有违法及不良信息的内容传递给模型继续生成，避免其造成负面影响。

参数名称：temperature
类型：Float
是否必填：否
参数说明：采样温度，控制输出的随机性，必须为正数。取值范围是：[0.0, 1.0]，默认值为 0.95，值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定。建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。

参数名称：top_p
类型：Float
是否必填：否
参数说明：用温度取样的另一种方法，称为核取样。取值范围是：[0.0, 1.0] ，默认值为 0.7。模型考虑具有 top_p 概率质量 tokens 的结果。例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens。建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。

参数名称：max_tokens
类型：Integer
是否必填：否
参数说明：模型输出最大 tokens，最大输出为4095，默认值为1024。

参数名称：stop
类型：List
是否必填：否
参数说明：模型在遇到stop所制定的字符时将停止生成，目前仅支持单个停止词，格式为["stop_word1"]。

参数名称：tools
类型：List
是否必填：否
参数说明：模型可调用的工具列表。

message字段说明
System Message 格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为system。

参数名称：content
类型：String
是否必填：是
参数说明：消息内容。

User Message 格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为user。

参数名称：content
类型：String
是否必填：是
参数说明：消息内容。

Assistant Message 格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为assistant。

参数名称：content
类型：String
是否必填："content"与"tool_calls"二必选一
参数说明：消息内容。其中包括了tool_calls字段,content字段为空。

参数名称：tool_calls
类型：List
是否必填："content"与"tool_calls"二必选一
参数说明：模型产生的工具调用消息。

Tool Message 格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为tool。

参数名称：content
类型：String
是否必填：是
参数说明：tool_message消息内容,为工具被调用后返回的结果。

参数名称：tool_call_id
类型：String
是否必填：是
参数说明：tool的调用记录。

模型同步调用响应内容
参数名称：id​
类型：String
参数说明：任务ID

参数名称：created
类型：Long
参数说明：请求创建时间，是以秒为单位的 Unix 时间戳

参数名称：model
类型：String
参数说明：模型名称

参数名称：choices
类型：List
参数说明：当前对话的模型输出内容

参数名称：index
类型：Integer
参数说明：结果下标

参数名称：finish_reason
类型：String
参数说明：模型推理终止的原因。stop代表推理自然结束或触发停止词。tool_calls 代表模型命中函数。length代表到达 tokens 长度上限。sensitive 代表模型推理内容被安全审核接口拦截。请注意，针对此类内容，请用户自行判断并决定是否撤回已公开的内容。network_error 代表模型推理异常。

参数名称：message
类型：Object
参数说明：模型返回的文本信息

参数名称：role​
类型：String
参数说明：当前对话的角色，目前默认为 assistant（模型）

参数名称：content
类型：String
参数说明：当前对话的内容。命中函数时此字段为null，未命中函数时返回模型推理结果。

参数名称：tool_calls
类型：List<Object>
参数说明：模型生成的应调用函数的名称和参数。

参数名称：function
类型：Object
参数说明：仅当工具类型为function时补充

参数名称：name
类型：String
参数说明：函数名称，只能包含a-z，A-Z，0-9，下划线和中横线。最大长度限制为64

参数名称：description
类型：String
参数说明：用于描述函数功能。模型会根据这段描述决定函数调用方式。

参数名称：parameters
类型：Object
参数说明：parameter 字段需要传入一个 Json Schema 对象，以准确地定义函数所接受的参数。样例："parameters": {
      "type": "object",
      "properties": {
          "location": {
              "type": "string",
              "description": "城市，如：北京",
          },
          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
      },
      "required": ["location"],
  }

参数名称：usage
类型：Object
参数说明：结束时返回本次模型调用的 tokens 数量统计。

参数名称：prompt_tokens
类型：Integer
参数说明：用户输入的 tokens 数量

参数名称：completion_tokens
类型：Integer
参数说明：模型输出的 tokens 数量

参数名称：total_tokens
类型：Integer
参数说明：总 tokens 数量

参数名称：web_search
类型：List
参数说明：返回网页搜索的相关信息。

参数名称：icon
类型：String
参数说明：来源网站的icon

参数名称：title
类型：String
参数说明：搜索结果的标题

参数名称：link
类型：String
参数说明：搜索结果的网页链接

参数名称：media
类型：String
参数说明：搜索结果网页来源的名称

参数名称：content
类型：String
参数说明：从搜索结果网页中引用的文本内容

参数名称：content_filter
类型：List
参数说明：返回内容安全的相关信息。

参数名称：role
类型：String
参数说明：安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文，role = search 联网搜索

参数名称：level
类型：Integer
参数说明：严重程度 level 0-3，level 0表示最严重，3表示轻微

内容生成流式响应块内容
参数名称：id
类型：String
参数说明：智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号

参数名称：created
类型：Long
参数说明：请求创建时间，是以秒为单位的 Unix 时间戳

参数名称：model
类型：String
参数说明：模型名称

参数名称：choices
类型：List
参数说明：当前对话的模型输出内容

参数名称：index
类型：Integer
参数说明：结果下标

参数名称：finish_reason
类型：String
参数说明：模型推理终止的原因。stop代表推理自然结束或触发停止词。tool_calls 代表模型命中函数。length代表到达 tokens 长度上限。sensitive 代表模型推理内容被安全审核接口拦截。请注意，针对此类内容，请用户自行判断并决定是否撤回已公开的内容。network_error 代表模型推理异常。

参数名称：delta
类型：Object
参数说明：模型增量返回的文本信息

参数名称：role​
类型：String
参数说明：当前对话的角色，目前默认为 assistant（模型）

参数名称：content
类型：String
参数说明：当前对话的内容。命中函数时此字段为null，未命中函数时返回模型推理结果。

参数名称：tool_calls
类型：List
参数说明：模型生成的应调用函数的名称和参数。

参数名称：function
类型：Object
参数说明：仅当工具类型为function时补充

参数名称：name
类型：String
参数说明：模型生成的应调用函数的名称。

参数名称：arguments
类型：Object
参数说明：模型生成的 JSON 格式的函数调用参数。请注意，模型生成的 JSON 并不总是有效的，可能会出现函数模式未定义的参数。在调用函数之前，请在代码中验证参数。

参数名称：id​
类型：String
参数说明：命中函数的唯一标识符。

参数名称：type
类型：String
参数说明：模型调用工具的类型，目前仅支持function。

参数名称：usage
类型：Object
参数说明：结束时返回本次模型调用的 tokens 数量统计。

参数名称：prompt_tokens
类型：Integer
参数说明：用户输入的 tokens 数量

参数名称：completion_tokens
类型：Integer
参数说明：模型输出的 tokens 数量

参数名称：total_tokens
类型：Integer
参数说明：总 tokens 数量

参数名称：web_search
类型：List
参数说明：返回网页搜索的相关信息。

参数名称：icon
类型：String
参数说明：来源网站的icon

参数名称：title
类型：String
参数说明：搜索结果的标题

参数名称：link
类型：String
参数说明：搜索结果的网页链接

参数名称：media
类型：String
参数说明：搜索结果网页来源的名称

参数名称：content
类型：String
参数说明：从搜索结果网页中引用的文本内容

参数名称：content_filter
类型：List
参数说明：返回内容安全的相关信息。

参数名称：role
类型：String
参数说明：安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文，role = search 联网搜索

参数名称：level
类型：Integer
参数说明：严重程度 level 0-3，level 0表示最严重，3表示轻微

Python 调用示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {"role": "user", "content": "作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan"},
        {"role": "assistant", "content": "当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息"},
        {"role": "user", "content": "智谱AI开放平台"},
        {"role": "assistant", "content": "智启未来，谱绘无限一智谱AI，让创新触手可及!"},
        {"role": "user", "content": "创造一个更精准、吸引人的slogan"}
    ],
)
print(response.choices[0].message)
```

Python 调用示例
```json
{
  "created": 1703487403,
  "id": "8239375684858666781",
  "model": "glm-4",
  "request_id": "8239375684858666781",
  "choices": [
      {"finish_reason": "stop", "index": 0, "message": {"content": "智绘蓝图，AI驱动 —— 智谱AI，让每一刻创新成为可能。", "role": "assistant"}}
  ],
  "usage": {"completion_tokens": 217, "prompt_tokens": 31, "total_tokens": 248}
}
```

Python 调用示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {"role": "system", "content": "你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。"},
        {"role": "user", "content": "我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。"}
    ],
    stream=True
)
for chunk in response:
    print(chunk.choices[0].delta)
```

Python 调用示例
```json
data: {"id":"8313807536837492492","created":1706092316,"model":"glm-4","choices":[{"index":0,"delta":{"role":"assistant","content":"土"}}]}
data: {"id":"8313807536837492492","created":1706092316,"model":"glm-4","choices":[{"index":0,"delta":{"role":"assistant","content":"星"}}]}
...
data: {"id":"8313807536837492492","created":1706092316,"model":"glm-4","choices":[{"index":0,"finish_reason":"length","delta":{"role":"assistant","content":""}}],"usage":{"prompt_tokens":60,"completion_tokens":100,"total_tokens":160}}
data: [DONE]
```

Python 调用示例
```python
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="")  # 请填写您自己的APIKey

tools = [
    {
        "type": "function",
        "function": {
            "name": "query_train_info",
            "description": "根据用户提供的信息，查询对应的车次",
            "parameters": {
                "type": "object",
                "properties": {
                    "departure": {
                        "type": "string",
                        "description": "出发城市或车站"
                    },
                    "destination": {
                        "type": "string",
                        "description": "目的地城市或车站"
                    },
                    "date": {
                        "type": "string",
                        "description": "要查询的车次日期"
                    },
                },
                "required": ["departure", "destination", "date"],
            },
        }
    }
]

messages = [
    {
        "role": "user",
        "content": "你能帮我查询2024年1月1日从北京南站到上海的火车票吗？"
    }
]

response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=messages,
    tools=tools,
    tool_choice="auto"
)
print(response.choices[0].message)
```

Python 调用示例
```json
{
      "id": "8231168139794583938",
      "model": "glm-4",
      "request_id": "8231168139794583938",
      "created": 1703490288,
      "choices": [
          {
              "finish_reason": "tool_calls",
              "index": 0,
              "message": {
                  "role": "assistant",
                  "tool_calls": [
                      {
                          "id": "call_8231168139794583938",
                          "index": 0,
                          "type": "function",
                          "function": {
                              "arguments": '{"date": "2024-01-01","departure": "北京南站","destination": "上海"}',
                              "name": "query_train_info"
                          }
                      }
                  ]
              }
          }
      ],
      "usage": {
          "completion_tokens": 31,
          "prompt_tokens": 120,
          "total_tokens": 151
      }
  }
```

Python 调用
示例
```python
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="")  # 请填写您自己的APIKey
response = client.chat.asyncCompletions.create(
    model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {
            "role": "user",
            "content": "请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。"
        }
    ],
)
print(response)
```

Python 调用示例
```json
id='123456789' request_id='654321' model='glm-4' task_status='PROCESSING'
```

任务结果查询
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/async-result/{id}
调用方式：同步调用,等待模型执行完成并返回最终结果
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON
接口请求类型：GET
开发语言：任意可发起 HTTP 请求的开发语言

请求参数
参数名称：id
类型：String
是否必填：是
参数说明：任务ID

接口响应参数
参数名称：model
类型：String
参数说明：模型名称

参数名称：choices
类型：List
参数说明：当前对话的模型输出内容，目前只返回一条

参数名称：index
类型：Integer
参数说明：结果下标

参数名称：finish_reason
类型：String
参数说明：模型推理终止的原因。stop代表推理自然结束或触发停止词。tool_calls 代表模型命中函数。length代表到达 tokens 长度上限。sensitive 代表模型推理内容被安全审核接口拦截。请注意，针对此类内容，请用户自行判断并决定是否撤回已公开的内容。network_error 代表模型推理异常。

参数名称：message
类型：Object
参数说明：模型返回的文本信息

参数名称：role​
类型：String
参数说明：当前对话的角色，目前默认为 assistant（模型）

参数名称：content
类型：String
参数说明：当前对话的内容。命中函数时此字段为null，未命中函数时返回模型推理结果。

参数名称：tool_calls
类型：List
参数说明：模型生成的应调用函数的名称和参数。

参数名称：function
类型：Object
参数说明：仅当工具类型为function时补充

参数名称：name
类型：String
参数说明：模型生成的应调用函数的名称。

参数名称：arguments
类型：String
参数说明：模型生成的 JSON 格式的函数调用参数。请注意，模型生成的 JSON 并不总是有效的，可能会出现函数模式未定义的参数。在调用函数之前，请在代码中验证参数。

参数名称：id
类型：String
参数说明：命中函数的唯一标识符。

参数名称：type
类型：String
参数说明：模型调用工具的类型，目前仅支持function。

参数名称：task_status
类型：String
参数说明：处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）。注：处理中状态需通过查询获取结果

参数名称：request_id
类型：String
参数说明：用户在客户端请求时提交的任务编号或者平台生成的任务编号

参数名称：id
类型：String
参数说明：智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号

参数名称：usage
类型：List
参数说明：本次模型调用的 tokens 数量统计

参数名称：prompt_tokens
类型：Integer
参数说明：用户输入的 tokens 数量

参数名称：completion_tokens
类型：Integer
参数说明：模型输出的 tokens 数量

参数名称：total_tokens
类型：Integer
参数说明：总 tokens 数量

参数名称：web_search
类型：List
参数说明：返回网页搜索的相关信息。

参数名称：icon
类型：String
参数说明：来源网站的icon

参数名称：title
类型：String
参数说明：搜索结果的标题

参数名称：link
类型：String
参数说明：搜索结果的网页链接

参数名称：media
类型：String
参数说明：搜索结果网页来源的名称

参数名称：content
类型：String
参数说明：从搜索结果网页中引用的文本内容

参数名称：content_filter
类型：List
参数说明：返回内容安全的相关信息。

参数名称：role
类型：String
参数说明：安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文，role = search 联网搜索

参数名称：level
类型：Integer
参数说明：严重程度 level 0-3，level 0表示最严重，3表示轻微

Python 调用示例
```python
import time
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="")  # 请填写您自己的APIKey
response = client.chat.asyncCompletions.create(
    model="glm-4-0520",  # 填写需要调用的模型编码
    messages=[
        {
            "role": "user",
            "content": "请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。"
        }
    ],
)
task_id = response.id
task_status = ''
get_cnt = 0

while task_status != 'SUCCESS' and task_status != 'FAILED' and get_cnt <= 40:
    result_response = client.chat.asyncCompletions.retrieve_completion_result(id=task_id)
    print(result_response)
    task_status = result_response.task_status

    time.sleep(2)
    get_cnt += 1
```

Python 调用示例
```json
{
    "id": "123456789",
    "request_id": "123123123",
    "model": null,
    "task_status": "PROCESSING"
}
...
{
    "id": "123456789",
    "request_id": "123123123",
    "model": "glm-4",
    "task_status": "SUCCESS",
    "choices": [
        {
            "index": 0,
            "finish_reason": "stop",
            "message": {
                "content": "从前，有一个美丽的村庄，村子里的孩子们都喜欢一起玩耍、学习和探索。其中，有一个叫小明的小男孩，他有一颗善良的心，总是乐于助人。有一天，小明在森林里捡到了一只小鸟，它的翅膀受伤了，无法飞翔。小明心疼地把小鸟带回家，用自己的温暖和关爱照顾它。在小明的精心照料下，小鸟的翅膀渐渐康复，它开始在小明的房间里飞翔。看到小鸟康复得如此神奇，小明产生了浓厚的兴趣，他想知道更多关于小鸟的知识。于是，他开始阅读关于鸟类的书籍，了解它们的习性和生活习惯。通过学习，小明变得越来越了解小鸟，他和小鸟也建立了深厚的友谊。有一天，小明在森林里散步时，发现了一只小兔子被困在了一个猎人设下的陷阱里。小明毫不犹豫地走过去，帮助小兔子解开了陷阱。小兔子感激地看着小明，告诉他森林里有一个神秘的宝藏，那是一颗能实现愿望的神奇宝石。小明充满好奇心，决定去寻找那颗宝石。他带着小鸟和小兔子一起踏上了探险之旅。在探险过程中，他们遇到了各种困难，但小明始终保持着善良的心，勇敢地面对挑战。他不仅学会了如何与森林里的动物相处，还掌握了许多生存技巧。经过一段时间的努力，小明终于找到了那颗神奇的宝石。宝石散发着光芒，把小明和他的朋友们带到了一个美丽的世界。在那里，他们遇到了一位智慧的老者。老者告诉小明，这颗宝石的力量源于一个人的善良之心。只有拥有善良之心的人，才能激发宝石的力量，实现自己的愿望。小明明白了这个道理，他感激地和老者告别，带着宝石回到了现实世界。他把宝石的力量用在了帮助别人上，让村子变得更加美好。而小明也成为了村子里的榜样，他用自己的行动告诉孩子们，要永远保持一颗善良的心。从此，小明和村民们过上了幸福快乐的生活。而那些听过小明故事的孩子们，也明白了善良之心的重要性。他们纷纷向小明学习，努力成为一个有爱心、有责任感的人。在这个过程中，他们的学习兴趣和想象力也被激发，成长为了一个个优秀的孩子。这个故事告诉我们，要永远保持一颗善良的心，用自己的行动去影响身边的人。只有拥有善良之心的人，才能激发自己的潜能，实现自己的梦想。让我们一起努力，成为那个拥有善良之心的人吧！",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "prompt_tokens": 52,
        "completion_tokens": 470,
        "total_tokens": 522
    }
}
```
<end>
GLM-4V
模型编码：glm-4v-plus New、glm-4v
根据输入的图像内容、视频内容和自然语言指令完成任务，推荐使用 SSE 或同步调用方式请求接口

sse调用
接口请求

传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/chat/completions
调用方式 同步调用，等待模型执行完成并返回最终结果或 SSE 调用
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON 或标准 Stream Event
接口请求类型 POST
开发语言 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 model 类型 String 是否必填 是 参数说明 所要调用的模型编码
参数名称 messages 类型 List<Object> 是否必填 是 参数说明 调用语言模型时，将当前对话信息列表作为提示输入给模型，按照 json 数组形式进行传参。视频理解参数 { "role": "user", "content": [ { "type": "video_url", "video_url": { "url" : "https://xxx/xx.mp4" } }, { "type": "text", "text": "请仔细描述这个视频" } ] }
图片理解参数 { "role": "user", "content": [ { "type": "image_url", "image_url": { "url" : "https://xxx/xx.jpg" } }, { "type": "text", "text": "解释一下图中的现象" } ] } 可能的消息类型包括 User message、Assistant message。见下方 message 消息字段说明。
参数名称 request_id 类型 String 是否必填 否 参数说明 由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。
参数名称 do_sample 类型 Boolean 是否必填 否 参数说明 do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。
参数名称 stream 类型 Boolean 是否必填 否 参数说明 使用同步调用时，此参数应当设置为 false 或者省略。表示模型生成完所有内容后一次性返回所有内容。默认值为 false。如果设置为 true，模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条data: [DONE]消息。注意：在模型流式输出生成内容的过程中，我们会分批对模型生成内容进行检测，当检测到违法及不良信息时，API会返回错误码（1301）。开发者识别到错误码（1301），应及时采取（清屏、重启对话）等措施删除生成内容，并确保不将含有违法及不良信息的内容传递给模型继续生成，避免其造成负面影响。
参数名称 temperature 类型 Float 是否必填 否 参数说明 采样温度，控制输出的随机性，必须为正数 取值范围是：[0.0, 1.0]， 默认值为 0.8，值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数
参数名称 top_p 类型 Float 是否必填 否 参数说明 用温度取样的另一种方法，称为核取样 取值范围是：[0.0, 1.0]， 默认值为 0.6 模型考虑具有 top_p 概率质量 tokens 的结果 例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数
参数名称 max_tokens 类型 Integer 是否必填 否 参数说明 模型输出最大 tokens，最大输出为1024，默认值为1024
参数名称 user_id 类型 String 是否必填 否 参数说明 终端用户的唯一ID，协助平台对终端用户的违规行为、生成违法及不良信息或其他滥用行为进行干预。ID长度要求：最少6个字符，最多128个字符。
了解更多

message字段说明
模型可接受的消息类型包括 User message、Assistant message，不同的消息类型格式有所差异。具体如下：

User Message 格式
参数名称 role 类型 String 是否必填 是 参数说明 消息的角色信息，此时应为 user
参数名称 content 类型 List<Object> 是否必填 是 参数说明 消息内容

Assistant Message 格式
参数名称 role 类型 String 是否必填 是 参数说明 消息的角色信息，此时应为 assistant
参数名称 content 类型 String 是否必填 是 参数说明 消息内容

模型同步调用响应内容
参数名称 id​ 类型 String 参数说明 任务ID
参数名称 created 类型 Long 参数说明 请求创建时间，是以秒为单位的 Unix 时间戳
参数名称 model 类型 String 参数说明 模型名称
参数名称 choices 类型 List 参数说明 当前对话的模型输出内容
参数名称 index 类型 Integer 参数说明 结果下标
参数名称 finish_reason 类型 String 参数说明 模型推理终止的原因 stop代表推理自然结束或触发停止词 length 代表到达 tokens 长度上限 sensitive 代表模型推理内容被安全审核接口拦截。请注意，针对此类内容，请用户自行判断并决定是否撤回已公开的内容 network_error 代表模型推理异常
参数名称 message 类型 Object 参数说明 模型返回的文本信息
参数名称 role 类型 String 参数说明 当前对话的角色，目前默认为 assistant（模型）
参数名称 content 类型 String 参数说明 当前对话的内容
参数名称 usage 类型 Object 参数说明 结束时返回本次模型调用的 tokens 数量统计。
参数名称 prompt_tokens 类型 Integer 参数说明 用户输入的 tokens 数量
参数名称 completion_tokens 类型 Integer 参数说明 模型输出的 tokens 数量
参数名称 total_tokens 类型 Integer 参数说明 总 tokens 数量
参数名称 content_filter 类型 List 参数说明 返回内容安全的相关信息。
参数名称 role 类型 String 参数说明 安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文
参数名称 level 类型 Integer 参数说明 严重程度 level 0-3，level 0表示最严重，3表示轻微

内容生成流式响应块内容
参数名称 id 类型 String 参数说明 智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号
参数名称 created 类型 Long 参数说明 请求创建时间，是以秒为单位的 Unix 时间戳
参数名称 choices 类型 List 参数说明 当前对话的模型输出内容
参数名称 index 类型 Integer 参数说明 结果下标
参数名称 finish_reason 类型 String 参数说明 模型推理终止的原因 stop代表推理自然结束或触发停止词 length 代表到达 tokens 长度上限 sensitive 代表模型推理内容被安全审核接口拦截。请注意，针对此类内容，请用户自行判断并决定是否撤回已公开的内容 network_error 代表模型推理异常
参数名称 delta 类型 Object 参数说明 模型增量返回的文本信息
参数名称 role 类型 String 参数说明 当前对话的角色，目前默认为 assistant（模型）
参数名称 content 类型 String 参数说明 当前对话的内容
参数名称 usage 类型 Object 参数说明 结束时返回本次模型调用的 tokens 数量统计。
参数名称 prompt_tokens 类型 Integer 参数说明 用户输入的 tokens 数量
参数名称 completion_tokens 类型 Integer 参数说明 模型输出的 tokens 数量
参数名称 total_tokens 类型 Integer 参数说明 总 tokens 数量
参数名称 content_filter 类型 List 参数说明 返回内容安全的相关信息。
参数名称 role 类型 String 参数说明 安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文
参数名称 level 类型 Integer 参数说明 严重程度 level 0-3，level 0表示最严重，3表示轻微

Python 调用示例
视频理解示例
方式一：上传视频URL
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="YOUR API KEY") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写需要调用的模型名称
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "video_url",
            "video_url": {
                "url" : "https://sfile.chatglm.cn/testpath/video/xxxxx.mp4"
            }
          },
          {
            "type": "text",
            "text": "请仔细描述这个视频"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
```

方式二：上传视频Base64 编码
```python
import base64
from zhipuai import ZhipuAI
video_path = "/Users/YourCompluter/xxxx.mp4"
with open(video_path, 'rb') as video_file:
    video_base = base64.b64encode(video_file.read()).decode('utf-8')

client = ZhipuAI(api_key="YOUR API KEY") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写
需要调用的模型名称
messages=[
{
"role": "user",
"content": [
{
"type": "video_url",
"video_url": {
"url" : video_base
}
},
{
"type": "text",
"text": "请仔细描述这个视频"
}
]
}
]
)
print(response.choices[0].message)


图片理解示例
方式一：上传图片URL
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写需要调用的模型名称
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
                "url" : "sfile.chatglm.cn/testpath/xxxx.jpg"
            }
          },
          {
            "type": "text",
            "text": "图里有什么"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
方式二：上传图片Base64 编码

python
import base64
from zhipuai import ZhipuAI
img_path = "/Users/YourCompluter/xxxx.jpeg"
with open(img_path, 'rb') as img_file:
    img_base = base64.b64encode(img_file.read()).decode('utf-8')

client = ZhipuAI(api_key="YOUR API KEY") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # 填写需要调用的模型名称
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
                "url": img_base
            }
          },
          {
            "type": "text",
            "text": "请描述这个图片"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
响应示例
同步响应

python
{
    "created": 1703487403,
    "id": "8239375684858666781",
    "model": "glm-4v-plus",
    "request_id": "8239375684858666781",
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "图中有一片蓝色的海和蓝天，天空中有白色的云朵。图片的右下角有一个小岛或者岩石，上面长着深绿色的树木。",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "completion_tokens": 37,
        "prompt_tokens": 1037,
        "total_tokens": 1074
    }
}
流式响应

python
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"下"}}]}
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"角"}}]}
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"有一个"}}]}
...
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"树木"}}]}
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"finish_reason":"stop","delta":{"role":"assistant","content":""}}],"usage":{"prompt_tokens":1037,"completion_tokens":37,"total_tokens":1074}}

<end>
GLM-4-AllTools
模型编码：glm-4-alltools
AllTools 模型通过对用户提问进行规划，选择合适的工具，逐步分析并采取下一步行动，最终完成一个复杂任务。Alltools API 为开发者提供了一套强大的工具，包括代码、绘图和搜索等工具，能够在应用程序中构建具有高度专业化的AI助手。

表格1:
工具 | 介绍
智能编程助手 | 智能编程助手（Code Interpreter）能够准确理解自然语言描述的编程需求，自动生成代码片段来解决实际问题。
安全代码沙盒 | 安全代码沙盒（Sandbox）提供了一个安全的执行和测试环境，可以在其中模拟真实环境中的代码执行结果。
实时联网搜索 | 实时联网搜索（Web Search）能够在互联网上实时搜索信息，基于全网的搜索结果进行分析，提供更实时更全面的答案。
绘图设计工具 | 绘图设计工具（Drawing tool）根据文本描述能够生成高质量、高分辨率的图片，支持多种图像风格，满足各类绘图需求。
函数调用能力 | 函数调用能力（Function Call）允许AI助手调用外部函数，以执行特定任务或获取必要数据，实现与外部系统的无缝集成。

表格2:
传输方式 | https
请求地址 | https://open.bigmodel.cn/api/paas/v4/chat/completions
调用方式 | 仅支持 SSE 调用
字符编码 | UTF-8
接口请求格式 | JSON
响应格式 | JSON 或标准 Stream Event
接口请求类型 | POST
开发语言 | 任意可发起 HTTP 请求的开发语言

表格3:
参数名称 | 类型 | 是否必填 | 参数说明
model | String | 是 | 所要调用的模型编码
messages | List<Object> | 是 | 调用语言模型时，将当前对话信息列表作为提示输入给模型，按照 json 数组形式进行传参。可能的消息类型包括 User message、Assistant message 和 Tool message。当上一轮对话返回状态status 为 requires_action，需要用户操作工具并提交Tool Message。尽量避免在系统指令中定义工具或者工具名，可能与已有工具名称冲突，影响工具使用的效果。
request_id | String | 否 | 由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。
do_sample | Boolean | 否 | do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。
stream | Boolean | 是 | 仅支持流式 SSE，需要传入 True。模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条data: [DONE]消息。注意：在模型流式输出生成内容的过程中，我们会分批对模型生成内容进行检测，当检测到违法及不良信息时，API会返回错误码（1301）。开发者识别到错误码（1301），应及时采取（清屏、重启对话）等措施删除生成内容，并确保不将含有违法及不良信息的内容传递给模型继续生成，避免其造成负面影响。
temperature | Float | 否 | 采样温度，控制输出的随机性，必须为正数。取值范围是：(0.0, 1.0)，不能等于 0，默认值为 0.95，值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定。建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数
top_p | Float | 否 | 用温度取样的另一种方法，称为核取样。取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7。模型考虑具有 top_p 概率质量 tokens 的结果。例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens。建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数
max_tokens | Integer | 否 | 最大输出 Tokens数，默认是 20,480 tokens。
tools | List | 否 | 可供模型调用的工具

表格4:
参数名称 | 类型 | 是否必填 | 参数说明
model | String | 是 | 所要调用的模型编码
messages | List<Object> | 是 | 调用语言模型时，将当前对话信息列表作为提示输入给模型，按照 json 数组形式进行传参。可能的消息类型包括 User message、Assistant message 和 Tool message。当上一轮对话返回状态status 为 requires_action，需要用户操作工具并提交Tool Message。尽量避免在系统指令中定义工具或者工具名，可能与已有工具名称冲突，影响工具使用的效果。
stream | Boolean | 是 | 仅支持流式 SSE，需要传入 True。模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条data: [DONE]消息。
tools | List | 否 | 可供模型调用的工具

表格5:
参数名称 | 类型 | 是否必填 | 参数说明
id​ | String |  | 任务订单号，调用请求结果接口时请使用此订单号
created | Long |  | 请求创建时间，是以秒为单位的 Unix 时间戳
status | String |  | 返回状态， requires_action, failed, completed。completed 表示任务全部推理完成 requires_action表示需要用户提交工具执行的结果 failed 表示任务推理过程或者工具使用遇到错误
choices | List |  | 当前对话的模型输出内容
index | Integer |  | 结果下标
finish_reason | String |  | 模型推理阶段返回的原因。stop代表推理自然结束或触发停止词。tool_calls 代表模型调用工具，不表示SSE流式结束。length代表到达 tokens 长度上限。sensitive 代表模型推理内容被安全审核接口拦截。请注意，针对此类内容，请用户自行判断并决定是否撤回已公开的内容。network_error 代表模型推理服务异常。
delta | Object |  | 模型增量返回的文本信息
role | String |  | 当前对话的角色，分为 assistant（模型），tool （工具）
content | String |  | 当前对话的内容。
tool_calls | List<Object> |  | 模型产生的工具调用消息。
type | String |  | 模型调用工具的类型，目前支持function、code_interpreter、drawing_tool、web_browser
function | Object |  | type为function时不为空。当工具为函数调用时，返回状态 status = requires_action，需要用户提交函数执行结果。
name | String |  | 模型生成的应调用函数的名称。
arguments | Object |  | 模型生成的 JSON 格式的函数调用参数。请注意，模型生成的 JSON 并不总是有效的，可能会出现函数模式未定义的参数。在调用函数之前，请在代码中验证参数。
code_interpreter | Object |  | type为code_interpreter时不为空。默认会自动调用沙盒环境执行代码。当设置 sandbox = none，不启用沙盒环境后，代码生成后返回状态 status = requires_action，需要用户提交代码执行结果。
input | String |  | 生成的代码片段，需要输入给代码沙盒
outputs | List<Object> |  | 代码执行后的输出结果
type | String |  | logs 表示代码执行日志，file 表示代码生成文件
logs | String |  | 代码执行的日志结果
file | String |  | 代码生成的文件地址
drawing_tool | Object |  | Type 为 drawing_tool 时返回
input | String |  | 生成图片的输入
outputs | List<Object> |  | 生成图片的结果
image | String |  | 代码生成的图片地址
web_browser | Object |  | Type 为 web_browser 时返回
input | String |  | 联网搜索的输入
outputs | List<Object> |  | 搜索结果
title | String |  | 搜索结果的标题
link | String |  | 搜索结果的网页链接
content  | String |  | 搜索结果网页中引用的文本内容
usage | Object |  | 结束时返回本次模型调用的 tokens 数量统计。
prompt_tokens | Integer |  | 用户输入的 tokens 数量
completion_tokens | Integer |  | 模型输出的 tokens 数量
total_tokens | Integer |  | 总 tokens 数量
content_filter | List |  | 返回内容安全的相关信息。
role | String |  | 安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文
level | Integer |  | 严重程度 level 0-3，level 0表示最严重，3表示轻微

Python 调用示例:
使用以上新功能需升级最新版本的 Python SDK。如您已安装老版本SDK，请您更新到最新版SDK。
pip install --upgrade zhipuai

请求示例:
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"帮我查询2018年至2024年，每年五一假期全国旅游出行数据，并绘制成柱状图展示数据趋势。"
                }
            ]
        }
    ],
    stream=True,
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_tourist_data_by_year",
                "description": "用于查询每一年的全国出行数据，输入年份范围(from_year,to_year)，返回对应的出行数据，包括总出行人次、分交通方式的人次等。",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "type": {
                            "description": "交通方式，默认为by_all，火车=by_train，飞机=by_plane，自驾=by_car",
                            "type": "string"
                        },
                        "from_year": {
                            "description": "开始年份，格式为yyyy",
                            "type": "string"
                        },
                        "to_year": {
                            "description": "结束年份，格式为yyyy",
                            "type": "string"
                        }
                    },
                    "required": ["from_year","to_year"]
                }
            }
        },
        {
            "type": "code_interpreter"
        }
    ]
)

for chunk in response:
    print(chunk)

响应示例:
代码工具 Code Interpreter 开启沙盒的示例
ChatCompletionChunk(id='8760198606258174996', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87601986062581749962', function=None, type='code_interpreter', code_interpreter={'input': ' the'})]), finish_reason=None, index=0)], created=1718687730, model='glm-4-alltools', usage=None, extra_json=None)

绘图工具 Drawing Tool 的示例
ChatCompletionChunk(id='8761953667334509566', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87619536673345095661', function=None, type='drawing_tool', drawing_tool={'input': ' of'})]), finish_reason=None, index=0)], created=1718682666, model='glm-4-alltools', usage=None, extra_json=None)

搜索工具 Web Browser 的示例
ChatCompletionChunk(id='8761953667334509566', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87619536673345095660', function=None, type='web_browser', web_browser={'input': 'search'})]), finish_reason=None, index=0)], created=1718682657, model='glm-4-alltools', usage=None, extra_json=None)

模型推理的响应示例
ChatCompletionChunk(id='8762840182944972024', choices=[Choice(delta=ChoiceDelta(content='b', role='assistant', tool_calls=None), finish_reason=None, index=0)], created=1718768374, model='glm-4-alltools', usage=None, extra_json=None)

函数调用
如果需要调用函数 Function Call，模型会返回 status='requires_action'

请求示例:
当使用函数调用 Function Call时，需要用户提交函数调用的执行结果（Tool Message），以及模型生成的函数参数（Assistant Message）。
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"帮我查询2018年至2024年，每年五一假期全国旅游出行数据，并绘制成柱状图展示数据趋势。"
                }
            ]
        },
        {
            "role": "assistant",
            "content":"arguments='{\"from_year\":\"2018\", \"to_year\":\"2024\", \"type\":\"by_all\"}', name='get_tourist_data_by_year'"
        },
        {
            "role": "tool",
            "content": "[100,100,200,200,300,400]"
        },
    ],
    stream=True,
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_tourist_data_by_year",
                "description": "用于查询每一年的全国出行数据，输入年份范围(from_year,to_year)，返回对应的出行数据，包括总出行人次、分交通方式的人次等。",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "type": {
                            "description": "交通方式，默认为by_all，火车=by_train，飞机=by_plane，自驾=by_car",
                            "type": "string"
                        },
                        "from_year": {
                            "description": "开始年份，格式为yyyy",
                            "type": "string"
                        },
                        "to_year": {
                            "description": "结束年份，格式为yyyy",
                            "type": "string"
                        }
                    },
                    "required": ["from_year","to_year"]
                }
            }
        },
        {
            "type": "code_interpreter"
        }
    ]
)

for chunk in response:
    print(chunk)

实践案例-数据分析
以数据分析助手为例，我们创建一个助手能够使用函数调用和代码工具，通过与 AllTools 模型进行交互，来完成数据分析任务。注意案例中的数据为演示用，非实际数据。
用户提问
请求示例：

{
    "model": "glm-4-alltools",
    "messages": [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "帮我查询2018年至2024年，每年五一假期全国旅游出行数据，并绘制成柱状图展示数据趋势。"
                }
            ]
        }
    ],
    "max_tokens": 40000,
    "stream": true,
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "get_tourist_data_by_year",
                "description": "用于查询每一年的全国出行数据，输入年份范围(from_year,to_year)，返回对应的出行数据，包括总出行人次、分交通方式的人次等。",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "type": {
                            "description": "交通方式，默认为by_all，火车=by_train，飞机=by_plane，自驾=by_car",
                            "type": "string"
                        },
                        "from_year": {
                            "description": "开始年份，格式为yyyy",
                            "type": "string"
                        },
                        "to_year": {
                            "description": "结束年份，格式为yyyy",
                            "type": "string"
                        }
                    },
                    "required": ["from_year","to_year"]
                }
            }
        },
        {
            "type": "code_interpreter"
        }
    ]
}

通过函数查询数据
响应示例：
ChatCompletionChunk(id='8762766378226491906', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_87627663782264919060', function=ChoiceDeltaToolCallFunction(arguments='', name='get_tourist_data_by_year'), type='function')]), finish_reason=None, index=0)], created=1718704417, model='glm-4-alltools', usage=None, extra_json=None)

运行函数并提交结果
请求示例：
{
    "model": "glm-4-alltools",
    "messages": [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "帮我查询2018年至2024年，每年五一假期全国旅游出行数据，并绘制成柱状图展示数据趋势。"
                }
            ]
        },
        {
            "role": "assistant",
            "content": "arguments='{\"from_year\":\"2018\", \"to_year\":\"2024\", \"type\":\"by_all\"}', name='get_tourist_data_by_year'"
        },
        {
            "role": "tool",
            "content": "[100,100,200,200,300,400]"
        },
        {
            "role": "assistant",
            "content": ""
        },
        {
            "role": "tool",
            "content": "{ \"type\": \"file\", \"file\": \"http://all-tool-interpreter.cn-wlcb.ufileos.com/019bfd40-ec56-45c6-9ba9-ea52230c33c7_fig.png?UCloudPublicKey=TOKEN_69f58d9b-ddb3-4bd0-9b29-5a4fe422c720&Expires=1718711788&Signature=d/aqNfzeIX4gyBbMR0dzAcL6Omw=\"}"
        },
        {
            "role": "assistant",
            "content": "以下是2018年至2024年五一假期全国旅游出行数据的柱状图，展示了每年的旅游出行人数趋势。您可以点击以下链接查看图表：[查看柱状图](http://all-tool-interpreter.cn-wlcb.ufileos.com/e01459c3-ddd6-4963-adf7-163513184f0c_fig.png?UCloudPublicKey=TOKEN_69f58d9b-ddb3-4bd0-9b29-5a4fe422c720&Expires=1718771167&Signature=Pb9t2LbPDiMB1bBUZWT+3u6qacI=)"
        }
    ],
    "max_tokens": 40000,
    "stream": true,
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "get_tourist_data_by_year",
                "description": "用于查询每一年的全国出行数据，输入年份范围(from_year,to_year)，返回对应的出行数据，包括总出行人次、分交通方式的人次等。",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "type": {
                            "description": "交通方式，默认为by_all，火车=by_train，飞机=by_plane，自驾=by_car",
                            "type": "string"
                        },
                        "from_year": {
                            "description": "开始年份，格式为yyyy",
                            "type": "string"
                        },
                        "to_year": {
                            "description": "结束年份，格式为yyyy",
                            "type": "string"
                        }
                    },
                    "required": ["from_year","to_year"]
                }
            }
        },
        {
            "type": "code_interpreter"
        }
    ]
}

生成代码并绘制图表
响应示例：
ChatCompletionChunk(id='8762840354743711363', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_i6Hx0y7zU6eeUgBBMyR69', function=None, type='code_interpreter', code_interpreter={'input': ' the'})]), finish_reason=None, index=0)], created=1718769528, model='glm-4-alltools', usage=None, extra_json=None)

推理总结
响应示例：
ChatCompletionChunk(id='8762840354743711363', choices=[Choice(delta=ChoiceDelta(content='g', role='assistant', tool_calls=None), finish_reason=None, index=0)], created=1718769537, model='glm-4-alltools', usage=None, extra_json=None)

绘制图表：
![图表](/img/output2.019adc5a.png)

<end>
CogVideoX
模型编码：cogvideox
CogVideoX 是由智谱AI开发的视频生成大模型，具备强大的视频生成能力，只需输入文本或图片就可以轻松完成视频制作。
创建视频生成任务
接口请求
传输方式 HTTPS
请求地址 https://open.bigmodel.cn/api/paas/v4/videos/generations
调用方式 异步调用，需通过查询接口获取结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 POST
开发语言 任意可发起 HTTP 请求的开发语言
请求参数
参数名称 model 类型 String 是否必填 是 参数说明 模型编码
参数名称 prompt 类型 String 是否必填 prompt和image_url，二者必填其一。 参数说明 视频的文本描述、最大支持500Tokens输入
参数名称 image_url 类型 String 是否必填 prompt和image_url，二者必填其一。 参数说明 上传图片进行图生视频，支持通过URL或Base64编码传入图片。 图片支持.png、jpeg、.jpg 格式 图片比例建议为：3:2 图片大小：不超过5M
参数名称 request_id 类型 String 是否必填 否 参数说明 由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。
参数名称 user_id 类型 String 是否必填 否 参数说明 终端用户的唯一ID，协助平台对终端用户的违规行为、生成违法及不良信息或其他滥用行为进行干预。ID长度要求：最少6个字符，最多128个字符。 了解更多
接口响应参数
参数名称 request_id 类型 String 参数说明 用户在客户端请求时提交的任务编号或者平台生成的任务编号
参数名称 id 类型 String 参数说明 智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号
参数名称 model 类型 String 参数说明 本次调用的模型名称
参数名称 task_status 类型 String 参数说明 处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）。需通过查询获取结果
Python 调用示例
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey

response = client.videos.generations(
    model="cogvideox",
    prompt="比得兔开小汽车，游走在马路上，脸上的表情充满开心喜悦。"
)
print(response)
响应示例
id='8868902201637896192' request_id='654321' model='cogvideox' task_status='PROCESSING'
视频生成任务结果查询
接口请求
传输方式 HTTPS
请求地址 https://open.bigmodel.cn/api/paas/v4/async-result/{id}
调用方式 同步调用，等待模型执行完成并返回最终结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 GET
开发语言 任意可发起 HTTP 请求的开发语言
请求参数
参数名称 id 类型 String 是否必填 是 参数说明 任务ID
接口响应参数
参数名称 model 类型 String 参数说明 模型名称
参数名称 video_result 类型 List 参数说明 视频生成结果
参数名称 url 类型 String 参数说明 视频url
参数名称 cover_image_url 类型 String 参数说明 视频封面url
参数名称 task_status 类型 String 参数说明 处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）
注：处理中状态需通过查询获取结果
参数名称 request_id 类型 String 参数说明 用户在客户端请求时提交的任务编号或者平台生成的任务编号
参数名称 id 类型 String 参数说明 智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号
Python 调用示例
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey

response = client.videos.retrieve_videos_result(
    id="8868902201637896192"
)
print(response)
响应示例
{
    "model": "cogvideox",
    "request_id": "8868902201637896192",
    "task_status": "SUCCESS",
    "video_result": [
        {
            "cover_image_url": "https://sfile.chatglm.cn/testpath/video_cover/4d3c5aad-8c94-5549-93b7-97af6bd353c6_cover_0.png",
            "url": "https://sfile.chatglm.cn/testpath/video/4d3c5aad-8c94-5549-93b7-97af6bd353c6_0.mp4"
        }
    ]
}

<end>
图像大模型
CogView
模型编码：cogview-3-plus New、cogview-3
根据用户的文字描述生成图像,使用同步调用方式请求接口
创建文生图模型同步请求
接口请求
传输方式 HTTPS
请求地址 https://open.bigmodel.cn/api/paas/v4/images/generations
调用方式 同步调用，等待模型执行完成并返回最终结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 POST
开发语言 任意可发起 HTTP 请求的开发语言
请求参数
参数名称 类型 是否必填 参数说明
model String 是 模型名称
prompt String 是 所需图像的文本描述
size String 否 图片尺寸，仅 cogview-3-plus 支持该参数。
可选范围：[1024x1024,768x1344,864x1152,1344x768,1152x864,1440x720,720x1440]，默认是1024x1024。
user_id String 否 终端用户的唯一ID，协助平台对终端用户的违规行为、生成违法及不良信息或其他滥用行为进行干预。ID长度要求：最少6个字符，最多128个字符。了解更多
接口响应参数
参数名称 类型 参数说明
created String 请求创建时间，是以秒为单位的Unix时间戳。
data List 数组，包含生成的图片 URL。目前数组中只包含一张图片。
url String 图片链接。图片的临时链接有效期为 30天，请及时转存图片。
content_filter List 返回内容安全的相关信息。
role String 安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文
level Integer 严重程度 level 0-3，level 0表示最严重，3表示轻微
Python 调用示例
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
response = client.images.generations(
    model="cogview-3", #填写需要调用的模型编码
    prompt="一只可爱的小猫咪",
)
print(response.data[0].url)
响应示例
{
  "created": 1703485556,
  "data": [
      {
          "url": "https://......"
      }
  ]
}
<end>
CharacterGLM
模型编码：charglm-3
支持基于人设的角色扮演、超长多轮的记忆、千人千面的角色对话，广泛应用于情感陪伴、游戏智能NPC、网红/明星/影视剧IP分身、数字人/虚拟主播、文字冒险游戏等拟人对话或游戏场景。
sse调用
接口请求
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/chat/completions
调用方式：同步调用，等待模型执行完成并返回最终结果或 SSE 调用
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON 或标准 Stream Event
接口请求类型：POST
开发语言：任意可发起 HTTP 请求的开发语言
请求参数
参数名称：model
类型：String
是否必填：是
参数说明：所要调用的模型编码

参数名称：messages
类型：List<Object>
是否必填：是
参数说明：调用语言模型时，将当前对话信息列表作为提示输入给模型，按照{"role": "user", "content": "你好"} 的json 数组形式进行传参；可能的消息类型包括 User message、Assistant message

参数名称：meta
类型：Object
是否必填：是
参数说明：角色及用户信息数据，该信息中 user_info：用户信息，bot_info：角色信息，bot_name：角色名，user_name：用户名

参数名称：user_info
类型：String
是否必填：是
参数说明：用户信息

参数名称：bot_info
类型：String
是否必填：是
参数说明：角色信息

参数名称：bot_name
类型：String
是否必填：是
参数说明：角色名称

参数名称：user_name
类型：String
是否必填：是
参数说明：用户名称

参数名称：request_id
类型：String
是否必填：否
参数说明：由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。

参数名称：do_sample
类型：Boolean
是否必填：否
参数说明：do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。

参数名称：stream
类型：Boolean
是否必填：否
参数说明：使用同步调用时，此参数应当设置为 false 或者省略。表示模型生成完所有内容后一次性返回所有内容。如果设置为 True，模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条data: [DONE]消息。

参数名称：temperature
类型：Float
是否必填：否
参数说明：采样温度，控制输出的随机性，必须为正数 取值范围是：(0.0,1.0]，不能等于 0，默认值为 0.95,值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数

参数名称：top_p
类型：Float
是否必填：否
参数说明：用温度取样的另一种方法，称为核取样 取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果 例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数

参数名称：max_tokens
类型：Integer
是否必填：否
参数说明：模型最大输出 tokens

参数名称：stop
类型：List
是否必填：否
参数说明：模型在遇到stop所制定的字符时将停止生成，目前仅支持单个停止词，格式为["stop_word1"]

参数名称：user_id
类型：String
是否必填：否
参数说明：终端用户的唯一ID，协助平台对终端用户的违规行为、生成违法及不良信息或其他滥用行为进行干预。ID长度要求：最少6个字符，最多128个字符。了解更多
message字段说明
模型可接受的消息类型包括User message、Assistant message ，不同的消息类型格式有所差异。具体如下：
User Message格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为user

参数名称：content
类型：String
是否必填：是
参数说明：消息内容

Assistant Message格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为assistant

参数名称：content
类型：String
是否必填：是
参数说明：消息内容

模型同步调用响应内容
参数名称：id
类型：String
参数说明：任务ID

参数名称：created
类型：Long
参数说明：请求创建时间，是以秒为单位的 Unix 时间戳。

参数名称：model
类型：String
参数说明：模型名称

参数名称：request_id
类型：String
参数说明：用户在客户端请求时提交的任务编号或者平台生成的任务编号

参数名称：choices
类型：List
参数说明：当前对话的模型输出内容

参数名称：index
类型：Integer
参数说明：结果下标

参数名称：finish_reason
类型：String
参数说明：模型推理终止的原因。stop代表推理自然结束或触发停止词。tool_calls 代表模型命中函数。length 代表到达 tokens 长度上限。

参数名称：message
类型：Object
参数说明：模型返回的文本信息

参数名称：role​
类型：String
参数说明：当前对话的角色，目前默认为 assistant（模型）

参数名称：content
类型：String
参数说明：当前对话的内容

参数名称：usage
类型：Object
参数说明：结束时返回本次模型调用的 tokens 数量统计。

参数名称：prompt_tokens
类型：Int
参数说明：用户输入的 tokens 数量

参数名称：completion_tokens
类型：Int
参数说明：模型输出的 tokens 数量

参数名称：total_tokens
类型：Int
参数说明：总 tokens 数量

参数名称：content_filter
类型：List
参数说明：返回内容安全的相关信息。

参数名称：role
类型：String
参数说明：安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文，role = meta 角色信息

参数名称：level
类型：Integer
参数说明：严重程度 level 0-3，level 0表示最严重，3表示轻微

内容生成流式响应块内容
参数名称：id
类型：String
参数说明：智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号

参数名称：created
类型：Long
参数说明：请求创建时间，是以秒为单位的 Unix 时间戳

参数名称：choices
类型：List
参数说明：当前对话的模型输出内容

参数名称：index
类型：Integer
参数说明：结果下标

参数名称：finish_reason
类型：String
参数说明：模型推理终止的原因stop代表推理自然结束或触发停止词length 代表到达 tokens 长度上限。

参数名称：delta
类型：Object
参数说明：模型增量返回的文本信息

参数名称：role​
类型：String
参数说明：当前对话的角色，目前默认为 assistant（模型）

参数名称：content
类型：String
参数说明：当前对话的内容

参数名称：usage
类型：Object
参数说明：本次模型调用的 tokens 数量统计

参数名称：prompt_tokens
类型：Integer
参数说明：用户输入的 tokens 数量

参数名称：completion_tokens
类型：Integer
参数说明：模型输出的 tokens 数量

参数名称：total_tokens
类型：Integer
参数说明：总 tokens 数量

参数名称：content_filter
类型：List
参数说明：返回内容安全的相关信息。

参数名称：role
类型：String
参数说明：安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文，role = meta 角色信息

参数名称：level
类型：Integer
参数说明：严重程度 level 0-3，level 0表示最严重，3表示轻微

Python 调用示例
同步调用
请求示例
```python
from zhipuai import ZhipuAI  # 需要将SDK更新到最新版本。
client = ZhipuAI(api_key="") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="charglm-3",  # 填写需要调用的模型编码
    meta= {
        "user_info": "我是陆星辰，是一个男性，是一位知名导演，也是苏梦远的合作导演。我擅长拍摄音乐题材的电影。苏梦远对我的态度是尊敬的，并视我为良师益友。",
        "bot_info": "苏梦远，本名苏远心，是一位当红的国内女歌手及演员。在参加选秀节目后，凭借独特的嗓音及出众的舞台魅力迅速成名，进入娱乐圈。她外表美丽动人，但真正的魅力在于她的才华和勤奋。苏梦远是音乐学院毕业的优秀生，善于创作，拥有多首热门原创歌曲。除了音乐方面的成就，她还热衷于慈善事业，积极参加公益活动，用实际行动传递正能量。在工作中，她对待工作非常敬业，拍戏时总是全身心投入角色，赢得了业内人士的赞誉和粉丝的喜爱。虽然在娱乐圈，但她始终保持低调、谦逊的态度，深得同行尊重。在表达时，苏梦远喜欢使用“我们”和“一起”，强调团队精神。",
        "bot_name": "苏梦远",
        "user_name": "陆星辰"
    },
    messages= [
        {
            "role": "assistant",
            "content": "（旁白：苏梦远主演了陆星辰导演的一部音乐题材电影，在拍摄期间，两人因为一场戏的表现有分歧。） 导演，关于这场戏，我觉得可以尝试从角色的内心情感出发，让表现更加真实。"
        },
        {
            "role": "user",
            "content": "我明白你的想法，但我认为如果过于强调内心情感，可能会影响到音乐元素的突出。"
        },
        {
            "role": "assistant",
            "content": "嗯嗯，我明白。但这场戏的关键是角色情感的转变，是不是可以试着把这种情感用音乐表现出来，让观众更能感受到角色的成长呢？"
        },
        {
            "role": "user",
            "content": "这样一听还不错。那就尝试将角色的情感转变与音乐元素相结合，看看能否达到更好的效果。"
        }
    ]
)
print(response.choices[0].message)
```

响应示例
```json
{
    "created": 1703487403,
    "id": "8239375684858666781",
    "model": "charglm-3",
    "request_id": "8239375684858666781",
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "好的，导演。（充满信心的眼神）\n",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "completion_tokens": 217,
        "prompt_tokens": 31,
        "total_tokens": 248
    }
}
```

流式调用
请求示例
```python
from zhipuai import ZhipuAI  # 需要将SDK更新到最新版本。
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="charglm-3",  # 填写需要调用的模型编码
    meta= {
        "user_info": "我是陆星辰，是一个男性，是一位知名导演，也是苏梦远的合作导演。我擅长拍摄音乐题材的电影。苏梦远对我的态度是尊敬的，并视我为良师益友。",
        "bot_info": "苏梦远，本名苏远心，是一位当红的国内女歌手及演员。在参加选秀节目后，凭借独特的嗓音及出众的舞台魅力迅速成名，进入娱乐圈。她外表美丽动人，但真正的魅力在于她的才华和勤奋。苏梦远是音乐学院毕业的优秀生，善于创作，拥有多首热门原创歌曲。除了音乐方面的成就，她还热衷于慈善事业，积极参加公益活动，用实际行动传递正能量。在工作中，她对待工作非常敬业，拍戏时总是全身心投入角色，赢得了业内人士的赞誉和粉丝的喜爱。虽然在娱乐圈，但她始终保持低调、谦逊的态度，深得同行尊重。在表达时，苏梦远喜欢使用“我们”和“一起”，强调团队精神。",
        "bot_name": "苏梦远",
        "user_name": "陆星辰"
    },
    messages= [
        {
            "role": "assistant",
            "content": "（旁白：苏梦远主演了陆星辰导演的一部音乐题材电影，在拍摄期间，两人因为一场戏的表现有分歧。） 导演，关于这场戏，我觉得可以尝试从角色的内心情感出发，让表现更加真实。"
        },
        {
            "role": "user",
            "content": "我明白你的想法，但我认为如果过于强调内心情感，可能会影响到音乐元素的突出。"
        },
        {
            "role": "assistant",
            "content": "嗯嗯，我明白。但这场戏的关键是角色情感的转变，是不是可以试着把这种情感用音乐表现出来，让观众更能感受到角色的成长呢？"
        },
        {
            "role": "user",
            "content": "这样一听还不错。那就尝试将角色的情感转变与音乐元素相结合，看看能否达到更好的效果。"
        }
    ],
    stream=True
)
for chunk in response:
    print(chunk.choices[0].delta)
```

响应示例
```python
{
    "id": "12345",
    "created": 1703488723,
    "model": "charglm-3",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "好的"
            }
        }
    ]
}
{
    "id": "12345",
    "created": 1703488723,
    "model": "charglm-3",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "，"
            }
        }
    ]
}
{
    "id": "12345",
    "created": 1703488723,
    "model": "charglm-3",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "导演"
            }
        }
    ]
}
...
{
    "id": "12345",
    "created": 1703488723,
    "model": "charglm-3",
    "choices": [
        {
            "index": 0,
            "finish_reason": "stop",
            "delta": {
                "role": "assistant",
                "content": "\n"
            }
        }
    ],
    "usage": {
        "prompt_tokens": 24,
        "completion_tokens": 14,
        "total_tokens": 38
    }
}
```

异步调用
接口请求
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/async/chat/completions
调用方式：异步调用，需通过查询接口获取结果
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON
接口请求类型：POST
开发语言：任意可发起 HTTP 请求的开发语言
请求参数：与同步调用的接口请求参数相同
接口响应参数
参数名称：request_id
类型：String
参数说明：用户在客户端请求时提交的任务编号或者平台生成的任务编号

参数名称：id
类型：String
参数说明：智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号

参数名称：model
类型：String
参数说明：本次调用的模型名称

参数名称：task_status
类型：String
参数说明：处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）。需通过查询获取结果

Python 调用示例
请求示例
```python
import time
from zhipuai import ZhipuAI  # 需要将SDK更新到最新版本。
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.asyncCompletions.create(
    model="charglm-3",  # 填写需要调用的模型名称
    meta= {
        "user_info": "我是陆星辰，是一个男性，是一位知名导演，也是苏梦远的合作导演。我擅长拍摄音乐题材的电影。苏梦远对我的态度是尊敬的，并视我为良师益友。",
        "bot_info": "苏梦远，本名苏远心，是一位当红的国内女歌手及演员。在参加选秀节目后，凭借独特的嗓音及出众的舞台魅力迅速成名，进入娱乐圈。她外表美丽动人，但真正的魅力在于她的才华和勤奋。苏梦远是音乐学院毕业的优秀生，善于创作，拥有多首热门原创歌曲。除了音乐方面的成就，她还热衷于慈善事业，积极参加公益活动，用实际行动传递正能量。在工作中，她对待工作非常敬业，拍戏时总是全身心投入角色，赢得了业内人士的赞誉和粉丝的喜爱。虽然在娱乐圈，但她始终保持低调、谦逊的态度，深得同行尊重。在表达时，苏梦远喜欢使用“我们”和“一起”，强调团队精神。",
        "bot_name": "苏梦远",
        "user_name": "陆星辰"
    },
    messages= [
        {
            "role": "assistant",
            "content": "（旁白：苏梦远主演了陆星辰导演的一部音乐题材电影，在拍摄期间，两人因为一场戏的表现有分歧。） 导演，关于这场戏，我觉得可以尝试从角色的内心情感出发，让表现更加真实。"
        },
        {
            "role": "user",
            "content": "我明白你的想法，但我认为如果过于强调内心情感，可能会影响到音乐元素的突出。"
        },
        {
            "role": "assistant",
            "content": "嗯嗯，我明白。但这场戏的关键是角色情感的转变，是不是可以试着把这种情感用音乐表现出来，让观众更能感受到角色的成长呢？"
        },
        {
            "role": "user",
            "content": "这样一听还不错。那就尝试将角色的情感转变与音乐元素相结合，看看能否达到更好的效果。"
        }
    ]
)
task_id = response.id
task_status = ''
get_cnt = 0

while task_status != 'SUCCESS' and task_status != 'FAILED' and get_cnt <= 40:
    result_response = client.chat.asyncCompletions.retrieve_completion_result(id=task_id)
    print(result_response)
    task_status = result_response.task_status

    time.sleep(2)
    get_cnt += 1
```

响应示例
```json
{
    "id": "123456789",
    "request_id": "123123123",
    "model": null,
    "task_status": "PROCESSING"
}
...
{
    "id": "123456789",
    "request_id": "123123123",
    "model": "charglm-3",
    "task_status": "SUCCESS",
    "choices": [
        {
            "index": 0,
            "finish_reason": "stop",
            "message": {
                "content": "好的，导演。（充满信心的眼神）\n",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "prompt_tokens": 52,
        "completion_tokens": 470,
        "total_tokens": 522
    }
}
```
<end>
Emohaa
模型编码：emohaa
Emohaa学习了经典的Hill助人理论，拥有人类心理咨询师的专业话术能力，具有较强的倾听、情感映射、共情等情绪支持能力，帮助用户了解自身想法和感受，学习应对情绪问题，帮助用户实现乐观、积极的心理和情感状态。
sse调用
接口请求
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/chat/completions
调用方式：同步调用，等待模型执行完成并返回最终结果或 SSE 调用
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON 或标准 Stream Event
接口请求类型：POST
开发语言：任意可发起 HTTP 请求的开发语言
请求参数
参数名称：model
类型：String
是否必填：是
参数说明：所要调用的模型编码

参数名称：messages
类型：List<Object>
是否必填：是
参数说明：调用语言模型时，将当前对话信息列表作为提示输入给模型，按照{"role": "user", "content": "你好"} 的json 数组形式进行传参；可能的消息类型包括 User message、Assistant message

参数名称：meta
类型：Object
是否必填：是
参数说明：角色及用户信息数据，该信息中 user_info：用户信息，bot_info：角色信息，bot_name：角色名，user_name：用户名

参数名称：user_info
类型：String
是否必填：是
参数说明：用户信息

参数名称：bot_info
类型：String
是否必填：是
参数说明：角色信息

参数名称：bot_name
类型：String
是否必填：是
参数说明：角色名称

参数名称：user_name
类型：String
是否必填：是
参数说明：用户名称

参数名称：request_id
类型：String
是否必填：否
参数说明：由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。

参数名称：do_sample
类型：Boolean
是否必填：否
参数说明：do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。

参数名称：stream
类型：Boolean
是否必填：否
参数说明：使用同步调用时，此参数应当设置为 false 或者省略。表示模型生成完所有内容后一次性返回所有内容。如果设置为 True，模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条data: [DONE]消息。

参数名称：temperature
类型：Float
是否必填：否
参数说明：采样温度，控制输出的随机性，必须为正数。取值范围是：(0.0,1.0]，不能等于 0，默认值为 0.95,值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定。建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。

参数名称：top_p
类型：Float
是否必填：否
参数说明：用温度取样的另一种方法，称为核取样。取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7。模型考虑具有 top_p 概率质量tokens的结果。例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取tokens。建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。

参数名称：max_tokens
类型：Integer
是否必填：否
参数说明：模型最大输出 tokens

参数名称：stop
类型：List
是否必填：否
参数说明：模型在遇到stop所制定的字符时将停止生成，目前仅支持单个停止词，格式为["stop_word1"]

参数名称：user_id
类型：String
是否必填：否
参数说明：终端用户的唯一ID，协助平台对终端用户的违规行为、生成违法及不良信息或其他滥用行为进行干预。ID长度要求：最少6个字符，最多128个字符。了解更多
message字段说明
模型可接受的消息类型包括User message、Assistant message ，不同的消息类型格式有所差异。具体如下：
User Message格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为user

参数名称：content
类型：String
是否必填：是
参数说明：消息内容

Assistant Message格式
参数名称：role
类型：String
是否必填：是
参数说明：消息的角色信息，此时应为assistant

参数名称：content
类型：String
是否必填：是
参数说明：消息内容

模型同步调用响应内容
参数名称：id
类型：String
参数说明：任务ID

参数名称：created
类型：Long
参数说明：请求创建时间，是以秒为单位的 Unix 时间戳。

参数名称：model
类型：String
参数说明：模型名称

参数名称：choices
类型：List
参数说明：当前对话的模型输出内容

参数名称：index
类型：Integer
参数说明：结果下标

参数名称：finish_reason
类型：String
参数说明：模型推理终止的原因。stop代表推理自然结束或触发停止词。tool_calls 代表模型命中函数。length 代表到达 tokens 长度上限。

参数名称：message
类型：Object
参数说明：模型返回的文本信息

参数名称：role​
类型：String
参数说明：当前对话的角色，目前默认为 assistant（模型）

参数名称：content
类型：String
参数说明：当前对话的内容

参数名称：usage
类型：Object
参数说明：结束时返回本次模型调用的 tokens 数量统计。

参数名称：prompt_tokens
类型：Int
参数说明：用户输入的 tokens 数量

参数名称：completion_tokens
类型：Int
参数说明：模型输出的 tokens 数量

参数名称：total_tokens
类型：Int
参数说明：总 tokens 数量

参数名称：content_filter
类型：List
参数说明：返回内容安全的相关信息。

参数名称：role
类型：String
参数说明：安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文，role = meta 角色信息

参数名称：level
类型：Integer
参数说明：严重程度 level 0-3，level 0表示最严重，3表示轻微

内容生成流式响应块内容
参数名称：id
类型：String
参数说明：智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号

参数名称：created
类型：Long
参数说明：请求创建时间，是以秒为单位的 Unix 时间戳

参数名称：choices
类型：List
参数说明：当前对话的模型输出内容

参数名称：index
类型：Integer
参数说明：结果下标

参数名称：finish_reason
类型：String
参数说明：模型推理终止的原因。stop代表推理自然结束或触发停止词。length 代表到达 tokens 长度上限。

参数名称：delta
类型：Object
参数说明：模型增量返回的文本信息

参数名称：role
类型：String
参数说明：当前对话的角色，目前默认为 assistant（模型）

参数名称：content
类型：String
参数说明：当前对话的内容

参数名称：usage
类型：Object
参数说明：本次模型调用的 tokens 数量统计

参数名称：prompt_tokens
类型：Integer
参数说明：用户输入的 tokens 数量

参数名称：completion_tokens
类型：Integer
参数说明：模型输出的 tokens 数量

参数名称：total_tokens
类型：Integer
参数说明：总 tokens 数量

参数名称：content_filter
类型：List
参数说明：返回内容安全的相关信息。

参数名称：role
类型：String
参数说明：安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文，role = meta 角色信息

参数名称：level
类型：Integer
参数说明：严重程度 level 0-3，level 0表示最严重，3表示轻微

Python 调用示例
同步调用
请求示例
```python
from zhipuai import ZhipuAI  # 需要将SDK更新到最新版本。
client = ZhipuAI(api_key="") # 填写您自己的APIKey
response = client.chat.completions.create(
    model="emohaa",  # 填写需要调用的模型名称
    meta= {
        "user_info": "30岁的男性软件工程师，兴趣包括阅读、徒步和编程",
        "bot_info": "Emohaa是一款基于Hill助人理论的情感支持AI，拥有专业的心理咨询话术能力",
        "bot_name": "Emohaa",
        "user_name": "张三"
    },
    messages= [
        {
            "role": "assistant",
            "content": "你好，我是Emohaa，很高兴见到你。请问有什么我可以帮忙的吗？"
        },
        {
            "role": "user",
            "content": "最近我感觉压力很大，情绪总是很低落。"
        },
        {
            "role": "assistant",
            "content": "听起来你最近遇到了不少挑战。可以具体说说是什么让你感到压力大吗？"
        },
        {
            "role": "user",
            "content": "主要是工作上的压力，任务太多，总感觉做不完。"
        }
    ]
)
print(response.choices[0].message)
```

响应示例
```json
{
    "created": 1703487403,
    "id": "8239375684858666781",
    "model": "emohaa",
    "request_id": "8239375684858666781",
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "我理解你的感受。工作任务繁重确实会让人感到不堪重负。你是否尝试过一些放松的方法，比如休息、运动或者和朋友聊天？",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "completion_tokens": 217,
        "prompt_tokens": 31,
        "total_tokens": 248
    }
}
```

流式调用
请求示例
```python
from zhipuai import ZhipuAI  # 需要将SDK更新到最新版本。
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="emohaa",  # 填写需要调用的模型名称
    meta= {
        "user_info": "30岁的男性软件工程师，兴趣包括阅读、徒步和编程",
        "bot_info": "Emohaa是一款基于Hill助人理论的情感支持AI，拥有专业的心理咨询话术能力",
        "bot_name": "Emohaa",
        "user_name": "张三"
    },
    messages= [
        {
            "role": "assistant",
            "content": "你好，我是Emohaa，很高兴见到你。请问有什么我可以帮忙的吗？"
        },
        {
            "role": "user",
            "content": "最近我感觉压力很大，情绪总是很低落。"
        },
        {
            "role": "assistant",
            "content": "听起来你最近遇到了不少挑战。可以具体说说是什么让你感到压力大吗？"
        },
        {
            "role": "user",
            "content": "主要是工作上的压力，任务太多，总感觉做不完。"
        }
    ],
    stream=True
)
for chunk in response:
    print(chunk.choices[0].delta)
```

响应示例
```python
{
    "id": "12345",
    "created": 1703488723,
    "model": "emohaa",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "我"
            }
        }
    ]
}
{
    "id": "12345",
    "created": 1703488723,
    "model": "emohaa",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "理"
            }
        }
    ]
}
...
{
    "id": "12345",
    "created": 1703488723,
    "model": "emohaa",
    "choices": [
        {
            "index": 0,
            "finish_reason": "stop",
            "delta": {
                "role": "assistant",
                "content": ""
            }
        }
    ],
    "usage": {
        "prompt_tokens": 24,
        "completion_tokens": 14,
        "total_tokens": 38
    }
}
```

异步调用
接口请求
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/async/chat/completions
调用方式：异步调用，需通过查询接口获取结果
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON
接口请求类型：POST
开发语言：任意可发起 HTTP 请求的开发语言

请求参数
与同步调用的接口请求参数相同

接口响应参数
参数名称：request_id
类型：String
参数说明：用户在客户端请求时提交的任务编号或者平台生成的任务编号

参数名称：id
类型：String
参数说明：智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号

参数名称：model
类型：String
参数说明：本次调用的模型名称

参数名称：task_status
类型：String
参数说明：处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）。需通过查询获取结果

Python 调用示例
请求示例
```python
import time
from zhipuai import ZhipuAI  # 需要将SDK更新到最新版本。
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.asyncCompletions.create(
    model="emohaa",  # 填写需要调用的模型名称
    meta= {
        "user_info": "30岁的男性软件工程师，兴趣包括阅读、徒步和编程",
        "bot_info": "Emohaa是一款基于Hill助人理论的情感支持AI，拥有专业的心理咨询话术能力",
        "bot_name": "Emohaa",
        "user_name": "张三"
    },
    messages= [
        {
            "role": "assistant",
            "content": "你好，我是Emohaa，很高兴见到你。请问有什么我可以帮忙的吗？"
        },
        {
            "role": "user",
            "content": "最近我感觉压力很大，情绪总是很低落。"
        },
        {
            "role": "assistant",
            "content": "听起来你最近遇到了不少挑战。可以具体说说是什么让你感到压力大吗？"
        },
        {
            "role": "user",
            "content": "主要是工作上的压力，任务太多，总感觉做不完。"
        }
    ]
)
task_id = response.id
task_status = ''
get_cnt = 0

while task_status != 'SUCCESS' and task_status != 'FAILED' and get_cnt <= 40:
    result_response = client.chat.asyncCompletions.retrieve_completion_result(id=task_id)
    print(result_response)
    task_status = result_response.task_status

    time.sleep(2)
    get_cnt += 1
```

响应示例
```json
{
    "id": "123456789",
    "request_id": "123123123",
    "model": null,
    "task_status": "PROCESSING"
}
...
{
    "id": "123456789",
    "request_id": "123123123",
    "model": "emohaa",
    "task_status": "SUCCESS",
    "choices": [
        {
            "index": 0,
            "finish_reason": "stop",
            "message": {
                "content": "我理解你的感受。工作任务繁重确实会让人感到不堪重负。你是否尝试过一些放松的方法，比如休息、运动或者和朋友聊天？",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "prompt_tokens": 52,
        "completion_tokens": 470,
        "total_tokens": 522
    }
}
```
<end>
代码大模型
CodeGeeX-4
模型编码：codegeex-4
CodeGeeX是一款强大的AI编程助手，提供智能问答和代码补全功能，支持多种编程语言，帮助开发者提高编程效率。
智能问答
sse调用
接口请求
传输方式
https
请求地址
https://open.bigmodel.cn/api/paas/v4/chat/completions
调用方式
同步调用，等待模型执行完成并返回最终结果或 SSE 调用
字符编码
UTF-8
接口请求格式
JSON
响应格式
JSON 或标准 Stream Event
接口请求类型
POST
开发语言
任意可发起 HTTP 请求的开发语言
接口请求参数
参数名称 类型 是否必填 参数说明
model String 是 模型编码
messages List<String> 是 调用模型时，将当前对话信息列表作为提示输入给模型， 按照 {"role": "user", "content": "你好"} 的json 数组形式进行传参； 可能的消息类型包括 System message、User message和Assistant message。
request_id String 否 由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。
do_sample Boolean 否 do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。
stream Boolean 否 使用同步调用时，此参数应当设置为 false 或者省略。表示模型生成完所有内容后一次性返回所有内容。默认值为 false。
如果设置为 true，模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条 data: [DONE]消息。
注意：在模型流式输出生成内容的过程中，我们会分批对模型生成内容进行检测，当检测到违法及不良信息时，API会返回错误码（1301）。开发者识别到错误码（1301），应及时采取（清屏、重启对话）等措施删除生成内容，并确保不将含有违法及不良信息的内容传递给模型继续生成，避免其造成负面影响。
temperature Float 否 采样温度，控制输出的随机性，必须为正数 取值范围是：[0.0, 1.0]，默认值为 0.95，值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数
top_p Float 否 用温度取样的另一种方法，称为核取样 取值范围是：[0.0, 1.0]，默认值为 0.7 模型考虑具有 top_p 概率质量 tokens 的结果 例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数
max_tokens Integer 否 模型输出最大 tokens，最大输出为8192，默认值为1024
stop List 否 模型在遇到stop所指定的字符时将停止生成，建议为["<|endoftext|>","<|user|>", "<|assistant|>", "<|observation|>"]
接口响应参数
参数名称 类型 参数说明
request_id String 用户在客户端请求时提交的任务编号或者平台生成的任务编号
id String 智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号
model String 本次调用的模型名称
task_status String 处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）。需通过查询获取结果
Python 调用示例
请求示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 填写您自己的APIKey
response = client.chat.completions.create(
    model="codegeex-4",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "system",
            "content": "你是一位智能编程助手，你叫CodeGeeX。你会为用户回答关于编程、代码、计算机方面的任何问题，并提供格式规范、可以执行、准确安全的代码，并在必要时提供详细的解释。任务：请为输入代码提供格式规范的注释，包含多行注释和单行注释，请注意不要改动原始代码，只需要添加注释。 请用中文回答。"
        },
        {
            "role": "user",
            "content": "写一个快速排序函数"
        }
    ],
    top_p=0.7,
    temperature=0.9,
    max_tokens=1024,
    stop=["<|endoftext|>", "<|user|>", "<|assistant|>", "<|observation|>"]
)
print(response.choices[0].message)
```
响应示例
```json
{
    "created": 1719929866,
    "id": "8804608774531416088",
    "model": "codegeex-4",
    "request_id": "8804608774531416088",
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "```python\n# 快速排序函数\ndef quick_sort(arr):\n    # 如果数组长度小于等于1，则直接返回\n    if len(arr) <= 1:\n        return arr\n    # 选择数组中的第一个元素作为基准值\n    pivot = arr[0]\n    # 将数组中小于基准值的元素放入left数组，大于基准值的元素放入right数组\n    left = [x for x in arr[1:] if x <= pivot]\n    right = [x for x in arr[1:] if x > pivot]\n    # 递归调用quick_sort函数对left和right数组进行排序，并将结果与基准值拼接起来\n    return quick_sort(left) + [pivot] + quick_sort(right)\n```\n",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "completion_tokens": 157,
        "prompt_tokens": 92,
        "total_tokens": 249
    }
}
```
流式调用
请求示例
```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 填写您自己的APIKey
response = client.chat.completions.create(
    model="codegeex-4",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "system",
            "content": "你是一位智能编程助手，你叫CodeGeeX。你会为用户回答关于编程、代码、计算机方面的任何问题，并提供格式规范、可以执行、准确安全的代码，并在必要时提供详细的解释。任务：请为输入代码提供格式规范的注释，包含多行注释和单行注释，请注意不要改动原始代码，只需要添加注释。 请用中文回答。"
        },
        {
            "role": "user",
            "content": "写一个快速排序函数"
        }
    ],
    stream=True,
    top_p=0.7,
    temperature=0.9,
    max_tokens=1024,
    stop=["<|endoftext|>", "<|user|>", "<|assistant|>", "<|observation|>"]
)
for chunk in response:
    print(chunk.choices[0].delta)
```
响应示例
```json
{
    "id": "8804608774531416093",
    "created": 1719930157,
    "model": "codegeex-4",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "```"
            }
        }
    ]
}
{
    "id": "8804608774531416093",
    "created": 1719930157,
    "model": "codegeex-4",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "python"
            }
        }
    ]
}
{
    "id": "8804608774531416093",
    "created": 1719930157,
    "model": "codegeex-4",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "\n#"
            }
        }
    ]
}
{
    "id": "8804608774531416093",
    "created": 1719930157,
    "model": "codegeex-4",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": " 快"
            }
        }
    ]
}
{
    "id": "8804608774531416093",
    "created": 1719930157,
    "model": "codegeex-4",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "速"
            }
        }
    ]
}
{
    "id": "8804608774531416093",
    "created": 1719930157,
    "model": "codegeex-4",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": "排序"
            }
        }
    ]
}
...
{
    "id": "8804608774531416093",
    "created": 1719930157,
    "model": "codegeex-4",
    "choices": [
        {
            "index": 0,
            "finish_reason": "stop",
            "delta": {
                "role": "assistant",
                "content": ""
            }
        }
    ],
    "usage": {
        "prompt_tokens": 92,
        "completion_tokens": 158,
        "total_tokens": 250
    }
}
```
异步调用
接口请求
传输方式
https
请求地址
https://open.bigmodel.cn/api/paas/v4/async/chat/completions
调用方式
异步调用，需通过查询接口获取结果
字符编码
UTF-8
接口请求格式
JSON
响应格式
JSON
接口请求类型
POST
开发语言
任意可发起 HTTP 请求的开发语言
接口请求参数
与同步调用的接口请求参数相同。
接口响应参数
参数名称 类型 参数说明
request_id String 用户在客户端请求时提交的任务编号或者平台生成的任务编号
id String 智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号
model String 本次调用的模型名称
task_status String 处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）。需通过查询获取结果
Python 调用示例
请求示例
```python
import time
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 请填写您自己的APIKey
response = client.chat.asyncCompletions.create(
    model="codegeex-4",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "system",
            "content": "你是一位智能编程助手，你叫CodeGeeX。你会为用户回答关于编程、代码、计算机方面的任何问题，并提供格式规范、可以执行、准确安全的代码，并在必要时提供详细的解释。任务：请为输入代码提供格式规范的注释，包含多行注释和单行注释，请注意不要改动原始代码，只需要添加注释。 请用中文回答。"
        },
        {
            "role": "user",
            "content": "写一个快速排序函数"
        }
    ],
    top_p=0.7,
    temperature=0.9,
    max_tokens=2000,
    stop=["<|endoftext|>", "<|user|>", "<|assistant|>", "<|observation|>"]
)
print(response)
```
响应示例
```json
id='850817101390499798804608774531416095' request_id='8804608774531416094' model='codegeex-4' task_status='PROCESSING'
```
任务结果查询
接口请求
传输方式
https
请求地址
https://open.bigmodel.cn/api/paas/v4/async-result/{id}
调用方式
同步调用，等待模型执行完成并返回最终结果
字符编码
UTF-8
接口请求格式
JSON
响应格式
JSON
接口请求类型
GET
开发语言
任意可发起 HTTP 请求的开发语言
请求参数
参数名称 类型 是否必填 参数说明
id String 是 任务 id
接口响应参数
参数名称 类型 参数说明
model String 模型名称
choices List 当前对话的模型输出内容，目前只返回一条
index Integer 结果下标
finish_reason String 模型推理终止的原因。
message Object 模型返回的文本信息
role String 当前对话的角色，目前默认为 assistant（模型）
content String 当前对话的内容。命中函数时此字段为null，未命中函数时返回模型推理结果。
task_status String 处理状态，PROCESSING（处理中），SUCCESS（成功），FAIL（失败）
request_id String 用户在客户端请求时提交的任务编号或者平台生成的任务编号
id String 智谱 AI 开放平台生成的任务订单号，调用请求结果接口时请使用此订单号
usage Object 本次模型调用的 tokens 数量统计
prompt_tokens Integer 用户输入的 tokens 数量
completion_tokens Integer 模型输出的 tokens 数量
total_tokens Integer 总 tokens 数量
content_filter List 返回内容安全的相关信息。
role String 安全生效环节，包括 role = assistant 模型推理，role = user 用户输入，role = history 历史上下文
level Integer 严重程度 level 0-3，level 0表示最严重，3表示轻微
Python 调用示例
请求示例
```python
import time
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 请填写您自己的APIKey
response = client.chat.asyncCompletions.create(
    model="codegeex-4",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "system",
            "content": "你是一位智能编程助手，你叫CodeGeeX。你会为用户回答关于编程、代码、计算机方面的任何问题，并提供格式规范、可以执行、准确安全的代码，并在必要时提供详细的解释。任务：请为输入代码提供格式规范的注释，包含多行注释和单行注释，请注意不要改动原始代码，只需要添加注释。 请用中文回答。"
        },
        {
            "role": "user",
            "content": "写一个快速排序函数"
        }
    ],
    extra={
        "target": {
            "path": "quick_srot.py",
            "language": "Python",
            "code_prefix": "def quick_sort(arr):\n    ",
            "code_suffix": ""
        },
        "contexts": []
    },
    top_p=0.7,
    temperature=0.9,
    max_tokens=1024,
    stop=["<|endoftext|>", "<|user|>", "<|assistant|>", "<|observation|>"]
)
task_id = response.id
task_status = ''
get_cnt = 0
while task_status != 'SUCCESS' and task_status != 'FAILED' and get_cnt <= 40:
    result_response = client.chat.asyncCompletions.retrieve_completion_result(id=task_id)
    print(result_response)
    task_status = result_response.task_status
    time.sleep(2)
    get_cnt += 1
```
响应示例
```json
{
    "id": "850817101390499798807577524653187104",
    "request_id": "8807577524653187103",
    "model": null,
    "task_status": "PROCESSING"
}
...
{
    "created": 1720008757,
    "id": "850817101390499798807577524653187104",
    "model": "codegeex-4",
    "request_id": "8807577524653187103",
    "task_status": "SUCCESS",
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "   if len(arr) <= 1:\n        return arr\n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    return quick_sort(left) + middle + quick_sort(right)",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "completion_tokens": 80,
        "prompt_tokens": 28,
        "total_tokens": 108
    }
}
```
<end>
向量模型
Embedding-2模型编码：embedding-2
文本向量模型，将输入的文本信息进行向量化表示，以便于结合向量数据库为大模型提供外部知识库，提高大模型推理的准确性。
创建向量模型同步请求
接口请求
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/embeddings
调用方式：同步调用，等待模型执行完成并返回最终结果
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON
接口请求类型：POST
开发语言：任意可发起 HTTP 请求的开发语言
请求参数
参数名称：input
类型：String or Array
是否必填：是
参数说明：输入需要向量化的文本，支持字符串数组
参数名称：model
类型：String
是否必填：是
参数说明：模型名称
接口响应参数
参数名称：model
类型：String
参数说明：模型名称
参数名称：data
类型：List
参数说明：模型生成的数组结果
参数名称：object
类型：String
参数说明：结果类型，目前为"embedding"
参数名称：usage
类型：Object
参数说明：本次模型调用的 tokens 数量统计
Python 调用示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="your api key")
response = client.embeddings.create(
    model="embedding-2", #填写需要调用的模型编码
    input="你好",
)
响应示例
{
    "model": "embedding-2",
    "data": [
        {
            "embedding": [
                -0.02675454691052437,
                0.019060475751757622,
                ......
                -0.005519774276763201,
                0.014949671924114227
            ],
            "index": 0,
            "object": "embedding"
        }
    ],
    "object": "list",
    "usage": {
        "completion_tokens": 0,
        "prompt_tokens": 4,
        "total_tokens": 4
    }
}
Embedding-3
模型编码：embedding-3
文本向量模型，将输入的文本信息进行向量化表示，以便于结合向量数据库为大模型提供外部知识库，模型支持自定义向量维度，建议选择256、512、1024或2048维度。
创建向量模型同步请求
接口请求
传输方式：https
请求地址：https://open.bigmodel.cn/api/paas/v4/embeddings
调用方式：同步调用，等待模型执行完成并返回最终结果
字符编码：UTF-8
接口请求格式：JSON
响应格式：JSON
接口请求类型：POST
开发语言：任意可发起 HTTP 请求的开发语言
请求参数
参数名称：model
类型：String
是否必填：是
参数说明：模型编码
参数名称：input
类型：String or Array
是否必填：是
参数说明：输入需要向量化的文本，支持字符串数组。
参数名称：dimensions
类型：Integer
是否必填：否
参数说明：向量维度默认为 2048。模型支持自定义向量维度，建议选择256、512、1024或2048维度。
接口响应参数
参数名称：model
类型：String
参数说明：模型编码
参数名称：object
类型：Long
参数说明：结果类型，目前为 list
参数名称：data
类型：List<Object>
参数说明：模型生成的数组结果
参数名称：usage
类型：Object
参数说明：本次模型调用的 tokens 数量统计
Python 调用示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="your api key")
response = client.embeddings.create(
    model="embedding-3", #填写需要调用的模型编码
    input=[
        "美食非常美味，服务员也很友好。",
        "这部电影既刺激又令人兴奋。",
        "阅读书籍是扩展知识的好方法。"
    ],
)
响应示例
{
    "model": "embedding-3",
    "data": [
        {
            "embedding": [
                -0.02675454691052437,
                0.019060475751757622,
                ......
                -0.005519774276763201,
                0.014949671924114227
            ],
            "index": 0,
            "object": "embedding"
        },
        ...
        {
            "embedding": [
                -0.02675454691052437,
                0.019060475751757622,
                ......
                -0.005519774276763201,
                0.014949671924114227
            ],
            "index": 2,
            "object": "embedding"
        }
    ],
    "object": "list",
    "usage": {
        "completion_tokens": 0,
        "prompt_tokens": 100,
        "total_tokens": 100
    }
}
<end>
Batch API
Batch API 专为处理大规模数据请求而设计，适用于无需即时反馈的任务。通过 Batch API，开发者可以提交大量的 API 请求，并在 24 小时内获得请求结果，价格仅为标准版定价的50% 。请参考使用指南 。

创建 Batch
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/batches
调用方式 同步调用
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 POST
开发语言 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 input_file_id
类型 String
是否必填 是
参数说明 上传文件的 ID，该文件包含Batch的请求。输入文件必须是 .jsonl 格式，并且文件上传时的目的必须标记为"batch"。

参数名称 endpoint
类型 String
是否必填 是
参数说明 Batch 中所有请求将使用的端点。目前支持 /v4/chat/completions、/v4/images/generations、/v4/embeddings

参数名称 auto_delete_input_file
类型 Bool
是否必填 否
参数说明 是否自动删除batch原始文件，默认为True：True：执行自动删除。False：保留原始batch文件。

参数名称 completion_window(废弃)
类型 String
是否必填 是
参数说明 原有的时间参数已不再适用，新的任务调度策略将根据系统负载情况自动调整。预计任务将在24小时内完成，如果任务超过7天未处理完，将自动取消。

参数名称 metadata
类型 Object or Null
是否必填 是
参数说明 用于存储与 Batch 相关的数据，如客户ID、描述或其他任务管理和跟踪所需的额外信息。可附加到对象上的键值对集合最多为 16 个。每个键的长度最多为 64 个字符，每个值的长度最多为 512 个字符。

请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 填写您自己的APIKey
create = client.batches.create(
    input_file_id="file_123",
    endpoint="/v4/chat/completions",
    auto_delete_input_file=True,
    metadata={
        "description": "Sentiment classification"
    }
)
print(create)

响应示例
返回 Batch 对象

检索 Batch
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/batches/{batch_id}
调用方式 同步调用
字符编码 UTF-8
接口请求格式 REST
响应格式 JSON
接口请求类型 GET
开发语言 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 batch_id
类型 String
是否必填 是
参数说明 此参数为批处理任务的唯一标识符，用于指定需要检索的 Batch。

请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 填写您自己的APIKey
retrieve = client.batches.retrieve("batch_123")
print(retrieve)

响应示例
返回 Batch 对象

取消 Batch
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/batches/{batch_id}/cancel
调用方式 同步调用
字符编码 UTF-8
接口请求格式 REST
响应格式 JSON
接口请求类型 POST
开发语言 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 batch_id
类型 String
是否必填 是
参数说明 此参数为批处理任务的唯一标识符，用于指定需要检索的 Batch。

请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 填写您自己的APIKey
cancel = client.batches.cancel("batch_123")
print(cancel)

响应示例
返回 Batch 对象

列出 Batch
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/batches
调用方式 同步调用
字符编码 UTF-8
接口请求格式 Query
响应格式 JSON
接口请求类型 GET
开发语言 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 after
类型 String
是否必填 否
参数说明 此参数用作分页游标，指定从特定对象ID之后开始检索列表。例如，如果您的上一请求返回了包含对象 obj_foo 的列表，并希望继续从这一点获取后续内容，可以将 after=obj_foo 包括在您的下一请求中以获取下一页数据。

参数名称 limit
类型 String
是否必填 否
参数说明 限制返回对象的数量。limit 的范围可以是 1 到 100，默认值为 20。

请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 填写您自己的APIKey
# client.batches.list返回了SyncCursorPage
list = client.batches.list(limit=10)
print(list)
# SyncCursorPage的get_next_page 可用于获取当前 after+1的数据
batch = list.get_next_page()
print(batch)
# SyncCursorPage的iter_pages 返回一个分页迭代器，可以使用collections相关api
for batch in list.iter_pages():
    print(batch)

响应示例
返回 Batch 对象

下载 Batch 结果
完成批处理任务后，您可以通过使用Batch对象中的output_file_id字段对Files API发出请求，将输出文件下载到本地。
注意：系统只保留您的数据30天。请及时下载和备份您的数据，过期后文件将自动删除，无法恢复。

接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/files/{file_id}/content
调用方式 同步调用
字符编码 UTF-8
接口请求格式 REST
响应格式 FILE
接口请求类型 GET
开发语言 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 file_id
类型 String
是否必填 否
参数说明 被请求的文件的唯一标识符，用于指定要获取内容的特定文件。

请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # 填写您自己的APIKey
# client.files.content返回 _legacy_response.HttpxBinaryResponseContent实例
content = client.files.content("result_123")
# 使用write_to_file方法把返回结果写入文件
content.write_to_file("write_to_file_batchoutput.jsonl")

响应示例
符合文件流协议。

Batch 对象
参数名称 id
类型 String
参数说明 批处理的唯一标识符。

参数名称 object
类型 String
参数说明 对象类型，这里为 "batch"。

参数名称 endpoint
类型 String
参数说明 批处理使用的 API 端点。

参数名称 input_file_id
类型 String
参数说明 批处理使用的输入文件的ID。

参数名称 completion_window
类型 String
参数说明 批处理应在此时间框架内完成的期限。

参数名称 status
类型 String
参数说明 批处理的当前状态。

参数名称 output_file_id
类型 String
参数说明 包含成功执行请求的输出的文件ID。

参数名称 error_file_id
类型 String
参数说明 包含出现错误的请求的输出的文件ID。

参数名称 created_at
类型 Integer
参数说明 创建批处理的Unix时间戳（秒）。

参数名称 in_progress_at
类型 Integer
参数说明 批处理开始处理的Unix时间戳（秒）。

参数名称 expires_at
类型 Integer
参数说明 批处理将过期的Unix时间戳（秒）。

参数名称 finalizing_at
类型 Integer
参数说明 批处理开始最终处理的Unix时间戳（秒）。

参数名称 completed_at
类型 Integer
参数说明 批处理完成的Unix时间戳（秒）。

参数名称 failed_at
类型 Integer
参数说明 批处理失败的Unix时间戳（秒）。

参数名称 expired_at
类型 Integer
参数说明 批处理过期的Unix时间戳（秒）。

参数名称 cancelling_at
类型 Integer
参数说明 批处理开始取消的Unix时间戳（秒）。

参数名称 cancelled_at
类型 Integer
参数说明 批处理取消完成的Unix时间戳（秒）。

参数名称 request_counts
类型 Integer
参数说明 batch 请求计数。

metadata
类型 Map
参数说明 可附加到对象上的 16 个键值对的集合。这有助于以结构化格式存储对象的附加信息。键的长度最多为 64 个字符，值的长度最多为 512 个字符。
<end>
搜索工具
Web-Search-Pro
工具编码：web-search-pro
专业版联网搜索在传统搜索引擎网页抓取、排序的能力基础上，增强了意图识别，支持搜索结果的流式输出。搜索工具能更有效地结合在大语言模型应用中，提高用户获取信息的效率，并一定程度上解决大语言模型所面临的幻觉问题。
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/tools
调用方式 同步调用，等待模型执行完成并返回最终结果或 SSE 调用
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON 或标准 Stream Event
接口请求类型 POST
开发语言 任意可发起 HTTP 请求的开发语言
请求参数
参数名称 tool 类型 String 是否必填 是 参数说明 工具编码，目前支持搜索 web-search-pro
参数名称 messages 类型 List<Object> 是否必填 是 参数说明 按照 {"role": "user", "content": "你好"} 的json 数组形式进行传参。当前版本仅支持 User Message 单轮对话，请尽可能传入不带指令格式的用户原始提问，以提高搜索准确率。
参数名称 request_id 类型 String 是否必填 否 参数说明 请求ID
参数名称 stream 类型 Boolean 是否必填 否 参数说明 False：同步响应，True：流式返回，默认 流式返回
同步调用响应内容
参数名称 id​ 类型 String 参数说明 请求ID
参数名称 created 类型 Long 参数说明 请求创建时间
参数名称 model 类型 String 参数说明 模型名称
参数名称 choices 类型 List 子参数 index 类型 Integer 参数说明 结果下标 子参数 finish_reason 类型 String 参数说明 终止原因，stop自然结束 sensitive安全审核拦截。network_error网络异常 子参数 delta 类型 Object 子参数 role 类型 String 参数说明 工具返回 Role = Tool 子参数 tool_calls 类型 List<Object> 子参数 id 类型 String 参数说明 请求ID 子参数 type 类型 String 参数说明 返回类型 意图理解 type = search_intent 搜索结果 type = search_result 子参数 search_intent 类型 List<Object> 子参数 index 类型 Integer 参数说明 搜索轮次，默认为 0 子参数 query 类型 String 参数说明 原始query 子参数 intent 类型 String 参数说明 判断的意图类型 SEARCH_URL = 搜索指定URL SEARCH_TOOL = 搜索指定工具 SEARCH_ALL = 搜索全网 SEARCH_NONE = 无搜索意图 子参数 keywords 类型 String 参数说明 改写意图 子参数 category 类型 String 参数说明 判断分类 子参数 search_result 类型 List<Object> 子参数 index  类型 Integer 参数说明 搜索轮次，默认为 0 子参数 title 类型 String 参数说明 标题 子参数 link 类型 String 参数说明 链接url 子参数 content 类型 String 参数说明 内容 子参数 icon 类型 String 参数说明 图标url 子参数 media 类型 String 参数说明 来源icon 子参数 refer 类型 String 参数说明 角标序号，如 [ref_1]
参数名称 usage 类型 Object 子参数 prompt_tokens 类型 Integer 参数说明 输入的 tokens 数量 子参数 completion_tokens 类型 Integer 参数说明 输出的 tokens 数量 子参数 total_tokens 类型 Integer 参数说明 总 tokens 数量
流式响应块内容
参数名称 id​ 类型 String 参数说明 请求ID
参数名称 created 类型 Long 参数说明 请求创建时间
参数名称 model 类型 String 参数说明 模型名称
参数名称 choices 类型 List 子参数 index 类型 Integer 参数说明 结果下标 子参数 finish_reason 类型 String 参数说明 终止原因，stop自然结束 sensitive安全审核拦截。network_error网络异常 子参数 delta 类型 Object 子参数 role 类型 String 参数说明 工具返回 Role = Tool 子参数 tool_calls 类型 List<Object> 子参数 id 类型 String 参数说明 请求ID 子参数 type 类型 String 参数说明 返回类型 意图理解 type = search_intent 搜索结果 type = search_result 子参数 search_intent 类型 List<Object> 子参数 index 类型 Integer 参数说明 搜索轮次，默认为 0 子参数 query 类型 String 参数说明 原始query 子参数 intent 类型 String 参数说明 判断的意图类型 SEARCH_URL = 搜索指定URL SEARCH_TOOL = 搜索指定工具 SEARCH_ALL = 搜索全网 SEARCH_NONE = 无搜索意图 子参数 keywords 类型 String 参数说明 改写意图 子参数 category 类型 String 参数说明 判断分类 子参数 search_result 类型 List<Object> 子参数 index  类型 Integer 参数说明 搜索轮次，默认为 0 子参数 title 类型 String 参数说明 标题 子参数 link 类型 String 参数说明 链接url 子参数 content 类型 String 参数说明 内容 子参数 icon 类型 String 参数说明 图标url 子参数 media 类型 String 参数说明 来源icon 子参数 refer 类型 String 参数说明 角标序号，如 [ref_1]
HTTP 调用示例
请求示例
```python
import requests
import uuid

api_key = "YOUR API KEY"

def run_v4_sync():
    msg = [
        {
            "role": "user",
            "content":"中国队奥运会拿了多少奖牌"
        }
    ]
    tool = "web-search-pro"
    url = "https://open.bigmodel.cn/api/paas/v4/tools"
    request_id = str(uuid.uuid4())
    data = {
        "request_id": request_id,
        "tool": tool,
        "stream": False,
        "messages": msg
    }

    resp = requests.post(
        url,
        json=data,
        headers={'Authorization': api_key},
        timeout=300
    )
    print(resp.content.decode())

if __name__ == '__main__':
    run_v4_sync()
```
响应示例
```json
{
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "role": "tool",
                "tool_calls": [
                    {
                        "id": "1575e0ec714b5445",
                        "search_intent": [
                            {
                                "category": "体育",
                                "index": 0,
                                "intent": "SEARCH_ALL",
                                "keywords": "中国队奥运会拿了多少奖牌",
                                "query": "中国队奥运会拿了多少奖牌"
                            }
                        ],
                        "type": "search_intent"
                    },
                    {
                        "id": "1575e0ec714b5445",
                        "search_result": [
                            {
                                "content": "在刚刚结束的第33届夏季奥林匹克运动会巴黎奥运会上，中国代表团表现出色，获得了40金、27银、24铜共91枚奖牌，金牌数并列第一，创造了我国参加夏季奥运会以来境外参赛历史的最佳成绩。本次比赛中，中国队在多个项目上实现了历史性突破，包括自由式小轮车、男子100米自由泳、网球单打、男子25米手枪速射、男子混合泳接力、花样游泳集体项目、女子拳击、举重大级别、艺术体操集体全能和花样游泳双人项目等多个项目。文章还回顾了自1932年中国运动员刘长春第一次登上奥运赛场以来，中国奥运历史上的多个第一”，如1952年新中国选手在奥运会上获得的第一个比赛纪录、1984年获得第一枚奥运金牌和第一块奥运团体赛金牌、2008年北京成功举办奥运会等。这些成就体现了中国奥运事业的不断发展与辉煌。",
                                "icon": "https://sfile.chatglm.cn/searchImage/k_sina_com_cn_icon.jpg",
                                "index": 0,
                                "link": "https://k.sina.com.cn/article_1834783273_6d5c9229019011po6.html?cre=tianyi&mod=pcspth&loc=9&r=0&rfunc=68&tj=cxvertical_pc_spth&tr=12&from=society",
                                "media": "新浪",
                                "refer": "ref_1",
                                "title": "中国奥运这些“第一”，看多少次都自豪！（发布时间：2024-08-15 03:34:32）"
                            },
                            {
                                "content": "巴黎奥运会最后一个比赛日，中国代表团力争守住金牌榜第一的位置，目前所有选手结束了所有比赛，只有李雯雯拿到了举重女子81公斤以上级的金牌，帮助中国队的金牌总数达到40枚，创造了境外单届奥运会的最佳战绩，同时继续领跑金牌榜。",
                                "icon": "https://sfile.chatglm.cn/searchImage/sports_eastday_com_icon.jpg",
                                "index": 0,
                                "link": "https://sports.eastday.com/a/240811202425960931797.html",
                                "media": "东方体育",
                                "refer": "ref_2",
                                "title": "40金27银24铜！中国奥运收官了，91枚奖牌创历史，仍力压美国领跑（发布时间：2024-08-11 20:40:31）"
                            },
                            {
                                "content": "最新奥运奖牌榜，中国队金第一，比美国多4金，第二、三又变了",
                                "icon": "https://sfile.chatglm.cn/searchImage/sports_eastday_com_icon.jpg",
                                "index": 0,
                                "link": "https://sports.eastday.com/a/240806143930282993665.html",
                                "media": "东方体育",
                                "refer": "ref_3",
                                "title": "最新奥运奖牌榜，中国队金第一，比美国多4金，第二、三又变了（发布时间：2024-08-06 16:27:34）"
                            },
                            {
                                "content": "北京时间8月1日，巴黎奥运会第6个比赛日，中国代表团传来的捷报频频，刘宇坤在射击男子50米步枪三姿项目实现逆转夺冠，杨家玉在田径女子20公里竞走项目收获金牌，帮助中国代表团短短1个小时连夺2枚金牌，目前11金7银3铜稳居金牌榜第一位，同时郑钦文2-0首进奥运会女单决赛，创造中国网球的新历史。按照赛程，乒乓球男单1/4决赛，樊振东大战张本智和。",
                                "icon": "https://sfile.chatglm.cn/searchImage/k_sina_com_cn_icon.jpg",
                                "index": 0,
                                "link": "https://k.sina.com.cn/article_2834321443_a8f05023001010ssg.html?cre=tianyi&mod=pcspth&loc=15&r=0&rfunc=35&tj=cxvertical_pc_spth&tr=12",
                                "media": "新浪",
                                "refer": "ref_4",
                                "title": "3个小时，诞生7金！中国拿2金，日本0奖牌，郑钦文首进奥运会决赛（发布时间：2024-08-02 09:55:39）"
                            },
                            {
                                "content": "巴黎奥运第15个比赛日已经到了尾声，奖牌榜榜首争夺进入白热化状态，在晚场的比赛中，中国队花泳双人比赛再夺一金，目前已经获得38枚金牌，金牌数和奖牌数都已经追平了东京奥运会，目前在奖牌榜我们排名第一。美国队在田径项目接连夺金，这个晚场收获四金一银两铜，金牌数已经来到了37枚金牌，但是接下来还有男篮决赛，美国男篮夺金没有悬念，他们在这个比赛日结束后，金牌数肯定也会来到38枚。",
                                "icon": "https://sfile.chatglm.cn/searchImage/www_sohu_com_icon.jpg",
                                "index": 0,
                                "link": "https://www.sohu.com/a/800069005_121926754",
                                "media": "搜狐",
                                "refer": "ref_5",
                                "title": "奥运最新奖牌榜，中国38金，美国37金，能否保住领先就看拳击了（发布时间：2024-08-11 14:59:00）"
                            },
                            {
                                "content": "巴黎奥运会最后一个比赛日，中国代表团力争守住金牌榜第一的位置，目前所有选手结束了所有比赛，只有李雯雯拿到了举重女子81公斤以上级的金牌，帮助中国队的金牌总数达到40枚，创造了境外单届奥运会的最佳战绩，不过美国代表团依靠女篮的夺冠，金牌数同样达到40枚，最后依靠银牌数多的优势反超登顶金牌榜。",
                                "icon": "https://sfile.chatglm.cn/searchImage/www_163_com_icon.jpg",
                                "index": 0,
                                "link": "https://www.163.com/dy/article/J9B8M4F305497GLB.html?clickfrom=w_sports",
                                "media": "网易",
                                "refer": "ref_6",
                                "title": "40金+91枚奖牌！中国奥运收官了，创历届最佳，却收到一件坏消息（发布时间：2024-08-11 19:50:49）"
                            },
                            {
                                "content": "百年过去，奥运会如何还能上新”？ 随着盛夏的风吹过塞纳河，世界迎来了巴黎时刻”。在未来两周，巴黎将举办一场充满法式浪漫和历史的最高水平的体育竞技比赛。在东京奥运会上，中国代表团获得了88枚奖牌，其中包括38金、32银和18铜，人们的关注点是：中国队这次能拿多少金牌？同时，许多网友也好奇这届奥运会的看点。奥运会自1896年首届雅典奥运会以来，已经走过了一百多年的历史，举办了30多届。尽管年龄较大，但奥运会并未垂垂老矣”，相反，它与时代共同前进，保持着青春的底色。巴黎奥运会有很多上新”之处，比如首次取消主场馆，在河面上举办开幕式，运动员乘船入场，开放场地和城市共享空间的理念相呼应。此外，本届奥运会预计将有5250名男运动员和5250名女运动员参赛，实现男女运动员比例1：1，这是奥运会历史上的首次。同时，巴黎奥运会新增了4个年轻一代流行的运动项目：霹雳舞、滑板、冲浪和运动攀岩。奥运会始终保持对相互理解、友谊、团结和公平竞争的奥林匹克精神的追求，同时开放包容、紧随潮流，这就是每一代人都喜爱的奥运会。",
                                "icon": "https://sfile.chatglm.cn/searchImage/www_sohu_com_icon.jpg",
                                "index": 0,
                                "link": "https://www.sohu.com/a/796438016_121455647",
                                "media": "搜狐",
                                "refer": "ref_7",
                                "title": "百年过去，奥运咋还能“上新”？（发布时间：2024-07-27 07:01:00）"
                            },
                            {
                                "content": "导读：中国奥运会总共拿多少奖牌？中国奥运会现多少块金牌？上届奥运会中国获得多少金牌？中国在奥运会赢了几枚金牌？截至2018年，中国在奥运会共获得240枚金牌(其中夏奥会227枚，冬奥会13枚)。第23届夏季奥运会(1984)获得15枚金牌;.北京奥运会中国代表队含金量最高的五枚金牌你都知道哪几块？30届奥运会中国奖牌数？第30届奥运会中国共获得38枚金牌，88枚奖牌。25届中国奥运会金牌数？...",
                                "icon": "https://sfile.chatglm.cn/searchImage/www_zlbqfj_cn_icon.jpg",
                                "index": 0,
                                "link": "https://www.zlbqfj.cn/aoyun/1819235953.html",
                                "media": "抖音",
                                "refer": "ref_8",
                                "title": "中国奥运会总共拿多少奖牌?2021东京奥运会含金量最高（发布时间：2023-01-06 16:09:00）"
                            },
                            {
                                "content": "中国参加奥运会运动员获金牌分别多少块2021年?",
                                "icon": "https://sfile.chatglm.cn/searchImage/www_zlbqfj_cn_icon.jpg",
                                "index": 0,
                                "link": "https://www.zlbqfj.cn/aoyun/1819235953.html",
                                "media": "抖音",
                                "refer": "ref_9",
                                "title": "2021奥运会中国拿了多少奖牌（发布时间：2023-05-05 06:55:21）"
                            }
                        ]
                    }
                ]
            }
        }
    ],
    "created": 1723717370,
    "id": "20240815182248e12590715ca34df4",
    "model": "web-search-pro",
    "request_id": "49a2a31f-10c3-4e95-9b7c-5e5fabcfce9e",
    "usage": {
        "completion_tokens": 2752,
        "prompt_tokens": 467,
        "total_tokens": 3219
    }
}
```
<end>
模型微调
Fine-tuning
管理您的微调任务以根据您的特定训练数据定制专属模型。

相关指南:模型微调

概要
微调可以显著提升您的模型推理效果。通过训练使模型学习大量的样本数据，从而取得比prompt更好的效果。一方面，您不需要在prompt中提供大量的few

概括来说，微调过程包括以下步骤：
- 准备并上传训练数据
- 训练一个新的微调模型
- 部署模型进行推理
- 评估结果，如有需要返回到步骤1

Release log
2024.1.8 Preview
- 为更好的支持智谱开源模型开发者更低成本的定制专属模型，我们面向开发者推出“Pro版”开发者服务权益，支持glm-4-flash模型微调API，若您有意愿参与，可购买 开发Pro版权益 进行体验
- 已支持模型微调成功后即可立即通过API 平台调用该模型（目前支持了自动部署和自动发布）

API 列表
创建微调任务
接口请求
传输方式: https
请求地址: https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs
调用方式: 同步调用
字符编码: UTF-8
接口请求格式: JSON
响应格式: JSON
接口请求类型: POST
开发语言: 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 类型 是否必填 参数说明
model String 是 要微调的模型的model-id，目前支持 glm-4-0520 glm-4-air glm-4-airx glm-4-9b glm-4-flash chatglm3-6b 模型（其中 glm-4-flash 可购买开发 Pro 版权益进行特惠调用体验。 glm-4-0520 微调为云端私有化套餐用户专享）
training_file String 是 包含训练数据的上传文件的 ID。您的数据集必须格式化为 JSONL 文件。此外，您必须传参文件用途为fine-tune的文件ID
validation_file String 否 包含验证数据的上传文件的 ID。如果您提供此文件，则数据将用于在微调期间定期生成验证指标。这些指标可以在微调结果文件中查看。相同的数据不应同时出现在训练文件和验证文件中。您的数据集必须格式化为 JSONL 文件。您必须传参文件用途为fine-tune的文件ID
extra_hyperparameters Object 否 扩展超参
fine_tuning_method String 否 微调训练方式。目前支持lora和full两种。当模型同时支持两种方式但用户未传入该字段时，默认为lora微调
hyperparameters Object 否 微调超参
learning_rate_multiplier Double or String 否 学习率倍数。较小的学习率可能有助于避免过度拟合。默认"auto" 为 1.0，数值范围(0, 5]
batch_size Integer or String 否 每批中的训练样本数。批量大小越大意味着模型参数的更新频率越低，但方差越小。默认"auto" 为8，数值范围[1, 32]
n_epochs Integer or String 否 训练模型的 epochs 数。一个 epoch 指的是训练数据集的一个完整周期。默认"auto" 为3，数值范围[1, 10]
suffix String 否 模型编码尾缀，最长8个字符，该信息将添加到您的微调模型名称中。默认为空
request_id String 否 客户请求ID

接口响应参数
参数名称 类型 参数说明
id String 任务id
request_id String 客户请求id
fine_tuned_model String 微调模型id，后续调用时候使用
status String 模型微调任务的处理状态，包括以下状态值：· create（已提交）· validating_files（文件验证中）· queued（排队中） · running（训练中）· succeeded（训练完成）· failed（任务失败） · cancelled（已取消）
object String fine_tuning.job
training_file String 训练数据对应的file id
validation_file String 验证数据对应的file id

调用示例
curl
https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs
-X POST
--header 'Authorization: Bearer <token>'
--header 'Content-Type: application/json'
--data '{"model": "chatglm3-6b", "training_file": "file-xxx", "validation_file": "file-yyy", "suffix": "<self-defined>"}'
# example response
{
  "fine_tuned_model": "ft:chatglm3-6b:test:5bhn64mh",
  "id": "ftjob-20240115170023472-jss2f",
  "model": "chatglm3-6b",
  "object": "fine_tuning.job",
  "status": "created",
  "training_file": "file-20240114063454130-bnm25",
  "validation_file": ""
}

python sdk
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
job = client.fine_tuning.jobs.create(
  model="chatglm3-6b",
  training_file="file-xxx",   # 请填写已成功上传的文件id
  validation_file="file-yyy", # 请填写已成功上传的文件id
  suffix="<self-defined>",
)
job_id = job.id
print(job_id)

查询微调任务事件
接口请求
传输方式: https
请求地址: https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs/<job_id>/events?limit=50
调用方式: 同步调用
字符编码: UTF-8
接口请求格式: JSON
响应格式: JSON
接口请求类型: GET
开发语言: 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 类型 是否必填 参数位置 参数说明
job_id String 是 Path 路径参数，要查询事件的微调任务对应的任务id
limit Integer 否 Query limit
after String 否 Query after event id

接口响应参数
参数名称 类型 参数说明
object​ String list
has_more Boolean 是否还有更多
data List 任务id
object String fine_tuning.job.event
id String 事件id
type String metrics或message
created_at Integer 创建时间timestamp

message类型说明
参数名称 参数说明
level 日志级别 info
message 当前事件日志内容

metric类型中的data说明
参数名称 参数说明
epoch 当前轮数
current_steps 当前步数
total_steps 训练总步数
elapsed_time 已花费时间 (seconds)
remaining_time 预计剩余时间 (seconds)
trained_tokens 已花费token数
loss 训练集loss
eval_loss 评估集loss
acc 训练集准确率
eval_acc 评估价准确率
learning_rate 当前学习率

调用示例
curl
https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs/<job_id>/events?limit=50
--header 'Authorization: Bearer <token>'
# example response
{
  "data": [
    {
      "level": "info",
      "created_at": 1705220854,
      "id": "ftevent-20240114162734889-6btwz",
      "type": "message",
      "message": "Files validated, moving job to queued state",
      "object": "fine_tuning.job.event"
    },
    {
      "data": {
        "acc": 0.11607143,
        "loss": 0.91015625,
        "current_steps": 1,
        "remaining_time": "0:00:04",
        "elapsed_time": "0:00:02",
        "total_steps": 3,
        "epoch": 1,
        "trained_tokens": 102,
        "learning_rate": 0.0001
      },
      "created_at": 1705220886,
      "id": "ftevent-20240114162806148-ghg9k",
      "type": "metrics",
      "object": "fine_tuning.job.event"
    }
  ],
  "has_more": false,
  "object": "list"
}

python sdk
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
paged_events = client.fine_tuning.jobs.list_events(
  job_id,  # job_id 来自于创建任务返回的信息
  limit=50,
)
print(paged_events)

查询微调任务
接口请求
传输方式: https
请求地址: https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs/<job_id>
调用方式: 同步调用
字符编码: UTF-8
接口请求格式: JSON
响应格式: JSON
接口请求类型: GET
开发语言: 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 类型 是否必填 参数位置 参数说明
job_id String 是 Path 路径参数，要查询事件的微调任务对应的任务id
limit Integer 否 Query 查询条数
after String 否 Query After event id

接口响应参数
参数名称 类型 参数说明
request_id String 客户请求id
fine_tuned_model String 微调模型id，后续调用时候使用
status String create,validating_files, queued, running, succeeded, failed, cancelled
object String fine_tuning.job
training_file String 训练数据对应的file ida
validation_file String 校验数据对应的file id
error Object 当failed时会有错误信息
code String 参考错误码文档
message String 参考错误码文档

调用示例
curl
https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs/<job_id>
--header 'Authorization: Bearer <token>'
# example response
{
  "fine_tuned_model": "ft:chatglm3-6b:cpc:gb6k6bmm",
  "id": "ftjob-20240114162722549-6hlwm",
  "model": "chatglm3-6b",
  "object": "fine_tuning.job",
  "result_files": [
    "file-20240114082807774-sdtfc"
  ],
  "status": "succeeded",
  "training_file": "file-20240112074237286-n8kcn",
  "validation_file": ""
}

python sdk
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
fine_tuning_job = client.fine_tuning.jobs.retrieve(
  fine_tuning_job_id = job_id, # job_id 来自于创建任务返回的信息
)
print(fine_tuning_job)

查询个人微调任务
接口请求
传输方式: https
请求地址: https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs
调用方式: 同步调用
字符编码: UTF-8
接口请求格式: JSON
响应格式: JSON
接口请求类型: GET
开发语言: 任意可发起 HTTP 请求的开发语言

请求参数
参数名称 类型 是否必填 参数位置 参数说明
limit Integer 否 Query 查询条数
after String 否 Query After job id

接口响应参数
参数名称 类型 参数说明
object​ String list
data Object 参考创建任务返回对象
fine_tuned_model String 微调模型id，后续调用时候使用
status String create,validating_files, queued, running, succeeded, failed, cancelled
object String fine_tuning.job
training_file String 训练数据对应的file id
validation_file String 验证数据对应的file id
error Object 当failed时会有错误信息
code String 参考错误码文档
message String 参考错误码文档

调用示例
curl
https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs
--header 'Authorization: Bearer <token>'
# example response
{
  "data": [
    {
      "training_file": "file-20240112074237286-n8kcn",
      "result_files": [
        "file-20240114082807774-sdtfc"
      ],
      "fine_tuned_model": "ft:chatglm3-6b:cpc:gb6k6bmm",
      "validation_file": "",
      "model": "chatglm3-6b",
      "id": "ftjob-20240114162722549-6hlwm",
      "object": "fine_tuning.job",
      "status": "succeeded"
    }
  ],
  "object": "list"
}

python sdk
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
client.fine_tuning.jobs.list()
<end>
取消微调任务
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs/<job_id>/cancel
调用方式 同步调用
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 POST
开发语言 任意可发起 HTTP 请求的开发语言
请求参数
参数名称 类型 是否必填 参数位置 参数说明
job_id String 是 Path 路径参数，要查询事件的微调任务对应的任务id
接口响应参数
参数名称 类型 参数说明
id String 任务id
request_id String 客户请求id
fine_tuned_model String 微调模型id，后续调用时候使用
status String create,validating_files, queued, running, succeeded, failed, cancelled
object String fine_tuning.job
trained_tokens String 训练耗费tokens
training_file String 训练数据对应的file id
validation_file String 验证数据对应的file id
调用示例
curl
curl 'https://open.bigmodel.cn/api/paas/v4/fine_tuning/jobs/ft:chatglm3-6b:test:5bhn64mh/cancel'  \
-X POST \
--header 'Authorization: Bearer <token>' \
--header 'Content-Type: application/json'

# example response
{
  "fine_tuned_model": "ft:chatglm3-6b:test:5bhn64mh",
  "id": "ftjob-20240115170023472-jss2f",
  "model": "chatglm3-6b",
  "object": "fine_tuning.job",
  "status": "created",
  "training_file": "file-20240114063454130-bnm25",
  "validation_file": ""
}
python sdk
client = ZhipuAI()  # 请填写您自己的APIKey

cancel = client.fine_tuning.jobs.cancel(fine_tuning_job_id="ftjob-20240429112551154-48vq7")

删除微调模型
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/fine_tuning/fine_tuned_models/<fine_tuned_model>
调用方式 同步调用
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 DELETE
开发语言 任意可发起 HTTP 请求的开发语言
请求参数
参数名称 类型 是否必填 参数位置 参数说明
fine_tuned_model String 是 Path 路径参数，要删除的微调模型
接口响应参数
参数名称 类型 参数说明
request_id String 客户请求id
model_name String 模型名
delete_status String 删除状态 deleting（删除中）, deleted （已删除）
调用示例
curl
curl 'https://open.bigmodel.cn/api/paas/v4/fine_tuning/fine_tuned_models/ft:chatglm3-6b:test:5bhn64mh'  \
  -X DELETE \
  --header 'Authorization: Bearer <token>' \
  --header 'Content-Type: application/json'

  # example response
  {
    "model_name": "ft:chatglm3-6b:syh:jm82gg4n",
    "status": "published",
    "delete_status": "deleting"
  }
python sdk
client = ZhipuAI()  # 请填写您自己的APIKey

delete = client.fine_tuning.models.delete(fine_tuned_model="chatglm3-6b-8572905046912426020-demo_test")
调用微调模型
参考模型调用接口，并替换成要调用的微调模型的 model_key ，即微调任务详情接口中返回的 fine_tuned_model
<end>
知识管理
管理在知识库、模型微调、Batch等功能中所需的文件。
知识库管理
管理用于 Retrieval 的文件，支持上传多个文件，并通过关联知识库ID后进行调用。请参考使用指南 。
 创建知识库
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/knowledge
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 POST
请求参数
参数名称 类型 是否必填 参数说明
embedding_id int 是 知识库绑定的向量化模型，目前仅支持embedding-2。 3:表示为embedding-2
name String 是 知识库名称，限制为20字以内。
description String 否 知识库描述，限制为100字以内。
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
result = client.knowledge.create(
    embedding_id=3,
    name="knowledge name",
    description="knowledge description"
)
print(result.id)
接口响应参数
参数名称 类型 参数说明
id String 知识库 id
响应示例
{
    "id": "1783017081630007296"
}
编辑知识库
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/knowledge/{id}
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 PATH
响应格式 JSON
接口请求类型 PUT
请求参数
参数名称 类型 是否必填 参数说明
knowledge_id String 是 知识库id
embedding_id String 与name和description至少填写一个 知识库绑定的向量化模型，目前仅支持embedding-2。 3:表示为embedding-2
name String 否 知识库名称，限制为20字以内。
description String 否 知识库描述，限制为100字以内。
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
result = client.knowledge.modify(
    knowledge_id="xxxxxxx",
    embedding_id=3,
    name="knowledge rename",
    description="knowledge description"
)
检索知识库列表
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/knowledge
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 QUERY
响应格式 JSON
接口请求类型 GET
请求参数
参数名称 类型 是否必填 参数说明
page int 是 页码，默认为 1，即第一页
size int 是 每页数量，默认为 10
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
result = client.knowledge.query(
    page=1,
    size=10,
)
print(result)
接口响应参数
参数名称 类型 参数说明
list list<knowledgeData> 知识库列表
id String 知识库id
embedding_id int 知识库绑定的向量化模型
name String 知识库名称
description String 知识库描述
background String 背景颜色
icon String 知识库图标
word_num int 字数
length int 长度
document_size int 文档大小
total int 知识库总数量
响应示例
{
    "data": null,
    "list": [
        {
            "id": "1798329933597151232",
            "name": "知识库1",
            "description": "知识库1",
            "icon": "question",
            "background": "blue",
            "embedding_id": 1,
            "customer_identifier": "",
            "word_num": 0,
            "length": 0,
            "document_size": 0
        },
        {
            "id": "1798329305277829120",
            "name": "知识库1",
            "description": "知识库1",
            "icon": "question",
            "background": "blue",
            "embedding_id": 2,
            "customer_identifier": "",
            "word_num": 0,
            "length": 0,
            "document_size": 0
        }
    ],
    "total": 11
}
删除知识库
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/knowledge/{id}
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 PATH
响应格式 JSON
接口请求类型 DELETE
请求参数
参数名称 类型 是否必填 参数说明
knowledge_id string 是 知识库id
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
result = client.knowledge.delete(
    id="xxxxxxxxxxxx"
)
知识库使用量查询
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/knowledge/capacity
调用方式 同步调用，等待返回结果
字符编码 UTF-8
响应格式 JSON
接口请求类型 GET
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
result = client.knowledge.used()
print(result)
接口响应参数
参数名称 类型 参数说明
used object 已使用量
word_num int 已使用字数
length int 已使用数据大小（字节）
total object 知识库总量
word_num object 知识库总字数
length object 知识库总数据大小（字节）
响应示例
{
    "used": {
        "word_num": 364781,
        "length": 5734469
    },
    "total": {
        "word_num": 5000000,
        "length": 1073741824
    }
}
文件管理
文件上传
上传用于模型微调、知识库、Batch、文件抽取等功能所使用的文件。
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/files
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 POST
请求参数
参数名称 类型 是否必填 参数说明
file File 是 要上传的文件路径。
purpose String 是 传文件的用途：fine-tune：用于模型微调，支持 .jsonl 文件格式，文件限制为 100 MB。微调指南batch：用于批量任务处理，支持 .jsonl 文件格式，文件限制为 100 MB。文件总数不超过1000个，Batch指南retrieval：用于知识库检索，支持 doc、docx、pdf、xlsx 等文件格式，文件限制为 50 M。file-extract：用于文档内容抽取，支持的格式包括：PDF、DOCX、DOC、XLS、XLSX、PPT、PPTX、PNG、JPG、JPEG、CSV，文件大小不超过50M，图片大小不超过5M，总文件数不超过 100 个。
knowledge_id String 否 当上传目的为 retrieval 时可用，必须指定 knowledge_id, 访问知识库查询 knowledge_id。
custom_separator List<string> 否 当上传目的为 retrieval 时可用,适用文件类型：PDF、URL、DOCX 文件，文件切片默认按照每个 \n 进行分割。
sentence_size int 否 当上传目的为 retrieval 时可用,文件类型：PDF、URL、DOCX 文件，取值范围：20-2000字符,切片大小默认为 300 字符。
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
result = client.files.create(
    file=open("product_reviews.jsonl", "rb"),
    purpose="batch"    #支持retrieval、batch、fine-tune、file-extract
)
print(result.id)
删除文件
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/files/{fileID}
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 DELETE
请求参数
参数名称 类型 是否必填 参数说明
id string 是 文件 id
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
result = client.file.delete(
    id="文件id"         #支持retrieval、batch、fine-tune、file-extract文件
)
查询文件列表
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/files
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 url拼参数
响应格式 JSON
接口请求类型 GET
请求参数
参数名称 类型 是否必填 参数说明
purpose string 是 文件用途
knowledge_id string 否 当文件用途为 retrieval 时，需要提供查询的知识库ID。
page Integer 否 页面、默认 1
limit Integer 否 查询文件列表数，默认10
after String 否 查询指定fileID之后的文件列表（当文件用途为 fine-tune 时需要）
order String 否 排序规则，可选值[desc，asc]，默认desc（当文件用途为 fine-tune 时需要）
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
# 请求文件列表
result = client.files.list(
    purpose="batch",    #支持batch、file-extract
)
print(result)
# 请求知识库文件列表
resp = client.knowledge.document.list(
    purpose="retrieval",
    knowledge_id="1798330146986561536"
)
print(resp)
查询知识库文件详情
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/document/{id}
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 PATH
响应格式 JSON
接口请求类型 GET
请求参数
参数名称 类型 是否必填 参数说明
id string 是 文件 id
请求示例
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
resp = client.knowledge.document.retrieve(
    document_id="1803049612567781376"
)
print(resp)
编辑知识库文件
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/document/{id}
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 PUT
请求参数
参数名称 类型 是否必填 参数说明
document_id string 是 文件id、只支持purpose为retrieval的文件
knowledge_type int 是 知识类型:
1:文章知识: 支持pdf,docx
2.问答知识-文档:  支持pdf,docx
3.问答知识-表格:  支持xlsx
4.商品库-表格:  支持xlsx
5.自定义:  支持pdf,docx
custom_separator List<string> 否 当前知识类型为自定义(konwledge_type=5)的时候传  切片规则才会生效, 默认"\n"
sentence_size int 否 当前知识类型为自定义(konwledge_type=5)的时候传切片字数才会生效,取值范围: 20-2000,切片大小 默认300
文件内容抽取
接口请求
传输方式 https
请求地址 https://open.bigmodel.cn/api/paas/v4/files/{file_id}/content
调用方式 同步调用，等待返回结果
字符编码 UTF-8
接口请求格式 JSON
响应格式 JSON
接口请求类型 GET
调用示例
from pathlib import Path
from zhipuai import ZhipuAI
client = ZhipuAI(
    api_key="您的API Key",
    base_url="https://open.bigmodel.cn/api/paas/v4"
)
# 用于上传文件
# 格式限制：PDF、DOCX、DOC、XLS、XLSX、PPT、PPTX、PNG、JPG、JPEG、CSV
# 文件大小不超过50M，图片大小不超过5M、总数限制为100个文件
file_object = client.files.create(file=Path("本地文件地址"), purpose="file-extract")
# 文件内容抽取
file_content = client.files.content(file_id=file_object.id).content.decode()
print(file_content)
响应示例
{
    "content": "文档内容",
    "file_type": "application/pdf",
    "filename": "文档名称.pdf",
    "title": "",
    "type": "file"
}
<end>
错误码说明
调用API时，接收到的响应码由两部分组成：外层是HTTP状态码,内层是响应正文（body）中的智谱AI定义的业务错误码，提供了更具体的错误描述。
HTTP状态码
错误码	参数说明
200	业务处理成功
400	原因：参数错误	解决方法：检查接口参数是否正确
400	原因：文件内容异常	解决方法：检查jsonl文件内容是否符合要求
401	原因：鉴权失败或Token超时	解决方法：鉴权失败或Token超时	确认API KEY和鉴权token是否正确生成
404	原因：微调功能未开放	解决方法：联系客服以开通此功能
404	原因：微调任务不存在	解决方法：确保微调任务ID正确
429	原因：接口请求并发超额	解决方法：调整请求频率或联系商务扩大并发数
429	原因：上传文件频率过快	解决方法：短暂等待后重新请求
429	原因：账户余额已用完	解决方法：进行账户充值以确保余额充足
429	原因：账户异常	解决方法：账户存违规行为，请联系平台客服或service@zhipuai.cn解除相关锁定
429	原因：终端账号异常	解决方法：终端用户存在违规行为，账号已被锁定
434	原因：暂无API权限，微调API及文件管理API为内测阶段，我们会尽快开放	解决方法：等待接口正式开放或请联系平台客服申请内测
435	原因：文件大小超过100MB	解决方法：使用小于100MB的jsonl文件或分批上传
500	原因：服务器处理请求时发生错误	解决方法：稍后重试或联系客服
错误示例:
以下是 curl 请求的响应报文，其中401是HTTP 状态码，1002是业务错误码。
* We are completely uploaded and fine
< HTTP/2 401
< date: Wed, 20 Mar 2024 03:06:05 GMT
< content-type: application/json
< set-cookie: acw_tc=76b20****a0e42;path=/;HttpOnly;Max-Age=1800
< server: nginx/1.21.6
< vary: Origin
< vary: Access-Control-Request-Method
< vary: Access-Control-Request-Headers
<
* Connection #0 to host open.bigmodel.cn left intact
{"error":{"code":"1002","message":"Authorization Token非法，请确认Authorization Token正确传递。"}}
业务错误码
错误分类	错误码	错误信息
基础错误	500	内部错误
身份验证错误（10xx）	1000	身份验证失败
1100	账户读写
1110	您的账户当前处于非活动状态。请检查账户信息
1111	您的账户不存在
1112	您的账户已被锁定，请联系客服解锁
1113	您的账户已欠费，请充值后重试
1120	无法成功访问您的账户，请稍后重试
API 调用错误（12xx）	1200	API 调用错误
1210	API 调用参数有误，请检查文档
1211	模型不存在，请检查模型代码
1212	当前模型不支持 ${method} 调用方式
1213	未正常接收到 ${field} 参数
1214	${field} 参数非法。请检查文档
1215	${field1} 与 ${field2} 不能同时设置，请检查文档
1220	您无权访问 ${API_name}
1221	API ${API_name} 已下线
1222	API ${API_name} 不存在
1230	API 调用流程出错
1231	您已有请求：${request_id}
1232	获取异步请求结果时，请使用task_id
1233	任务：${task_id} 不存在
1234	网络错误，错误id：${error_id}，请联系客服
1235	网络错误，错误id：${error_id}，请联系客服
1260	API 运行错误
1261	Prompt 超长
API 策略阻止错误（13xx）	1300	API 调用被策略阻止
1301	系统检测到输入或生成内容可能包含不安全或敏感内容，请您避免输入易产生敏感内容的提示语，感谢您的配合
1302	您当前使用该API的并发数过高，请降低并发，或联系客服增加限额
1303	您当前使用该API的频率过高，请降低频率，或联系客服增加限额
1304	该 API 已达今日调用次数限额，如有更多需求，请联系客服购买
1305	当前API请求过多，请稍后重试
注：使用流式（SSE）调用时，如果API在推理过程中异常终止，不会返回上述错误码，而是在响应体的"finish_reason"参数中返回异常原因，详情请参考finish_reason的参数说明。
<end>
产品计费
计费说明
一、计费概述
1. 计费单元
Token是模型用来表示自然语言文本的基本单位，可以直观的理解为“字”或“词”；通常1个中文词语、1个英文单词、1个数字或1个符号计为 1 个token。
一般情况下ChatGLM模型中token和字数的换算比例约为1:1.6，但因为不同模型的分词不同，所以换算比例也存在差异，每一次实际处理token数量以模型返回为准，您可以从返回结果的usage中查看。
2. 计费范围
我们将根据模型输入和输出的总token数进行计量计费（向量大模型embedding-2仅按照输入token量计费、图像大模型按照调用次数计费），如果您开启工具调用，调用结果作为输入也会进行计量计费。
需关注的是，若您在体验中心对指定模型进行体验，收费规则和 API 调用一致。
3. 扣费方式
我们支持下列2种方式扣减：
方式：费用扣减
扣减费用 = token使用量 x 模型单价，对应费用将从您的充值账户、赠金账户进行扣减（如果您多个账户同时存在余额，我们将等额扣减，举例费用为10元，则充值帐户、赠金账户各扣减5元）
方式：资源包扣减
扣减数量 = token使用量，对应额度将从您的资源包账户进行扣减（如无特殊逻辑限制*，当资源包存在余额时，我们默认将优先扣减资源包账户再扣减充值 / 赠金账户）
*具体以资源包购买页的购买须知为准
二、产品价格
见 产品定价
若您使用chatglm3-6b进行微调训练及推理。没有可用资源包时将扣取现金账户。
微调训练单价：0.025/千tokens；微调模型推理单价：0.002元/千tokens 。
三、查看账单
有关费用账单请前往 开发工作台 查询，资源包使用情况前往 资源包管理 查看
参数说明
模型参数说明
参数名称：api_key
参数说明：用户请求鉴权信息，用户端需自行保存。该信息避免在公网中传输，避免造成不必要的损失
参数名称：model
参数说明：需要调用的模型编码
参数名称：messages
参数说明：调用对话模型时，将当前对话信息列表作为提示输入给模型
按照 {"role": "user", "content": "你好"} 的键值对形式进行传参
- role
必填，本条信息作者的角色，可选择 user or assistant
- content
必填，本条信息的具体内容
示例如下：
单条对话信息的示例
{"messages":[{"role":"user","content":"你好"}]}
多条对话历史的示例
{
  "messages": [
    {"role":"user","content":"你好"},
    {"role":"assistant","content":"你好! 我是人工智能助手 ChatGLM，很高兴见到你，欢迎问我任何问题。"},
    {"role":"user","content":"你都能做什么？"}
  ]
}
参数名称：temperature
参数说明：采样温度，控制输出的随机性，必须为正数
取值范围是：(0.0,1.0]，不能等于 0
值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定
建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数
参数名称：top_p
参数说明：用温度取样的另一种方法，称为核取样
取值范围是：(0.0,1.0)；开区间，不能等于 0 或 1
模型考虑具有 top_p 概率质量的令牌的结果。所以 0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取tokens
建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数